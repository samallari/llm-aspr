{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "a979eac8102310fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T07:45:12.556084Z",
     "start_time": "2025-11-23T07:45:12.552196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ],
   "id": "3f509c4b6e0f299f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T07:45:14.684764Z",
     "start_time": "2025-11-23T07:45:14.264941Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "DATA_PATH = Path(\"../data/processed/iclr2024.json\")\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "RANDOM_SEED = 42\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data & Inspect",
   "id": "22d2bbce1c085c1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:32:55.916514Z",
     "start_time": "2025-11-23T06:32:55.549244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_jsonl(path: Path):\n",
    "    records = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            records.append(json.loads(line))\n",
    "    return records\n",
    "\n",
    "records = load_jsonl(DATA_PATH)\n",
    "len(records), records[0]\n"
   ],
   "id": "f0eab4a79c118001",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7404,\n",
       " {'venue': 'ICLR.cc',\n",
       "  'year': '2024',\n",
       "  'paper_id': 'cXs5md5wAq',\n",
       "  'title': 'Modelling Microbial Communities with Graph Neural Networks',\n",
       "  'abstract': 'Understanding the interactions and interplay of microorganisms is a great challenge with many applications in medical and environmental settings. In this work, we model bacterial communities directly from their genomes using graph neural networks (GNNs). GNNs leverage the inductive bias induced by the set nature of bacteria, enforcing permutation invariance and granting combinatorial generalization. We propose to learn the dynamics implicitly by directly predicting community relative abundance profiles at steady state, thus escaping the need for growth curves. On two real-world datasets, we show for the first time generalization to unseen bacteria and different community structures. \\nTo investigate the prediction results more deeply, we created a simulation for flexible data generation and analyze effects of bacteria interaction strength, community size, and training data amount.',\n",
       "  'decision': 'Reject',\n",
       "  'label': 0,\n",
       "  'reviews': [{'summary': 'The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.',\n",
       "    'strengths': 'Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.',\n",
       "    'weaknesses': 'The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as “By using k graph convolutional layers after one another we can achieve k-hop information propagation” rather misleading. \\n\\nOverall, the proposed method - applying GNN model in a straightforward way to a very small, fully-connected graph - is poorly justified and weak on novelty.',\n",
       "    'questions': 'What is the rationale for using a GNN on a very simple graph?\\n\\nWhat is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).',\n",
       "    'rating': '3: reject, not good enough',\n",
       "    'confidence': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'},\n",
       "   {'summary': 'The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.',\n",
       "    'strengths': 'The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.',\n",
       "    'weaknesses': '1. The methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \\n\\n2. The main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\\n\\n3. For simulations, the GLV equations along with initial conditions and parameters $\\\\mu_i, K_i, a_{i,j}$ drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\\n\\n4. Given the GLV equations, the steady state solutions can be found by solving a system of $|S|$ linear algebraic equations:\\n    \\\\begin{equation}\\n        \\\\sum_{j=1}^{|S|}a_{i,j}n_j = K_i.\\n    \\\\end{equation}\\nThe steady state is entirely determined by the parameters $a_{i,j}$ and $K_i$. The authors use a vector composed of $[\\\\mu_i, K_i, \\\\nu_i^s, \\\\nu_i^r, random]$ (where $a_{i,j} \\\\approx \\\\nu_i^s. \\\\nu_j^r$) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components $[K_i, \\\\nu_i^s, \\\\nu_i^r]$ determine the steady state solution.\\n\\n5. The parameter $a_{i,j}$ (broken into two vectors $\\\\nu_i^s, \\\\nu_j^r$ to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\\n\\n6. A proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive $\\\\nu$ vectors. The claim of interpretability seems to be questionable. \\n    \\n7. The authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated \"\\\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}\" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\\n\\n8. The authors need to provide details on how the node (genome) attributes were obtained, especially $\\\\nu$\\'s, as in real-world data, the ground-truth interaction $a_{ij}$ is not available.',\n",
       "    'questions': '1. How the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \\n\\n2. How scalable is the GNN-based implementation with respect to the number of microbial species?',\n",
       "    'rating': '3: reject, not good enough',\n",
       "    'confidence': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "   {'summary': 'The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.',\n",
       "    'strengths': \"I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:\\n* The authors' comparative approach between models is commendable.\\n* The paper addresses a clinically relevant topic, shedding light on bacterial interactions.\\n* The authors' transparency regarding the challenges in scaling the mod\",\n",
       "    'weaknesses': \"While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:\\n* Motivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia “1010 to 1011 cells per gram of intestinal content” seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.\\n* Sample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I’m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn’t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.\\n* Clarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can’t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.\\n* Simulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.\\nRegarding the conclusion I’m a little confused as to why it doesn’t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?\",\n",
       "    'questions': 'See weaknesses. \\n\\nMy main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.',\n",
       "    'rating': '6: marginally above the acceptance threshold',\n",
       "    'confidence': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "   {'summary': 'The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.',\n",
       "    'strengths': '- Novel problem setup and the first use of GNN to tackle this problem. \\n- The use of GNN matches with the data well since it is modeling a dynamic system. \\n- Very interesting set of experiments and they are extensive. \\n- The presentation is nice and clear.\\n- Nice simulation data construction and results.',\n",
       "    'weaknesses': '- Methodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.',\n",
       "    'questions': 'Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\\n\\nHave the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \\n\\nModeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html',\n",
       "    'rating': '6: marginally above the acceptance threshold',\n",
       "    'confidence': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:33:37.230225Z",
     "start_time": "2025-11-23T06:33:37.190807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = []\n",
    "\n",
    "for r in records:\n",
    "    title = (r.get(\"title\") or \"\").strip()\n",
    "    abstract = (r.get(\"abstract\") or \"\").strip()\n",
    "    label = r.get(\"label\")\n",
    "\n",
    "    # Skip if something critical is missing\n",
    "    if not title or not abstract:\n",
    "        continue\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "    text = f\"{title} {abstract}\".strip()\n",
    "    examples.append({\"text\": text, \"label\": int(label)})\n",
    "\n",
    "len(examples)\n"
   ],
   "id": "c0b0e6315d8b20ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7404"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:33:58.421592Z",
     "start_time": "2025-11-23T06:33:58.414677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "\n",
    "label_counts = collections.Counter(e[\"label\"] for e in examples)\n",
    "label_counts, {k: v / len(examples) for k, v in label_counts.items()}"
   ],
   "id": "e3ab73d0ee996b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 5143, 1: 2261}), {0: 0.69462452728255, 1: 0.30537547271745})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare Training Data",
   "id": "1c6ef2b51d7b2911"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:34:14.231240Z",
     "start_time": "2025-11-23T06:34:14.170204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_splits(examples, test_size=0.2, val_size=0.2, seed=RANDOM_SEED):\n",
    "    texts = [e[\"text\"] for e in examples]\n",
    "    labels = [e[\"label\"] for e in examples]\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        texts, labels,\n",
    "        test_size=test_size,\n",
    "        random_state=seed,\n",
    "        stratify=labels,\n",
    "    )\n",
    "\n",
    "    val_ratio = val_size / (1.0 - test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=1 - val_ratio,\n",
    "        random_state=seed,\n",
    "        stratify=y_temp,\n",
    "    )\n",
    "\n",
    "    def to_hf(texts, labels):\n",
    "        return Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "\n",
    "    return (\n",
    "        to_hf(X_train, y_train),\n",
    "        to_hf(X_val, y_val),\n",
    "        to_hf(X_test, y_test),\n",
    "    )\n",
    "\n",
    "train_ds, val_ds, test_ds = make_splits(examples)\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ],
   "id": "643dea43dbb0e6d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923, 370, 1111)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:35:55.199555Z",
     "start_time": "2025-11-23T06:35:50.729086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "\n",
    "tokenized_train = train_ds.map(tokenize, batched=True)\n",
    "tokenized_val = val_ds.map(tokenize, batched=True)\n",
    "tokenized_test = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "for ds in [tokenized_train, tokenized_val, tokenized_test]:\n",
    "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ],
   "id": "7e4790705861f298",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a56479b71411475b95e1dd343da1c5cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "368c59efb75b44dcade85f00d4ddc858"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da13a0819948402dab04c66da57c38e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcd2011da63240938c4fa9ec8e3607ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5923 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9cabe740c074cd0a2fb9de0463d6eab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/370 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ab6f61432ce47809d7e09e067352146"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1111 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a768852b06ec47a4b43d2b7bbadc324e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build Model",
   "id": "bd90c9766cd56fa3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:37:46.854949Z",
     "start_time": "2025-11-23T06:36:22.489934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # softmax for positive class (label=1)\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    probs = exp_logits[:, 1] / exp_logits.sum(axis=1)\n",
    "\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "    }\n",
    "    try:\n",
    "        metrics[\"auroc\"] = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        metrics[\"auroc\"] = float(\"nan\")\n",
    "    return metrics"
   ],
   "id": "4a464017ddd6268e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bea463f1319f477fbbb4843cd30bac3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
