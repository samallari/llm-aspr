{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5754630"
      },
      "source": [
        "# Qwen2.5 Classifier for Acceptance Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fea0e5df"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df2dad68"
      },
      "source": [
        "!pip install transformers datasets accelerate bitsandbytes -q"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7045d4f3",
        "outputId": "4ff4f7bc-33ff-473d-8ce8-e371272b2178"
      },
      "source": [
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "from datasets import load_dataset"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e0c8463"
      },
      "source": [
        "## Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192c1784",
        "outputId": "9d0b53b6-5be0-4cbe-eb32-74728a39e340"
      },
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(\"smallari/openreview-acceptance-classification-RAW\")\n",
        "\n",
        "# Display dataset structure\n",
        "print(\"Dataset structure:\", dataset)\n",
        "print(\"\\nFirst example from raw split:\", dataset['raw'][0])\n",
        "original_count = len(dataset['raw'])\n",
        "\n",
        "# Remove entries with empty reviews\n",
        "filtered_dataset = dataset.filter(lambda x: len(x['reviews']) > 0)\n",
        "\n",
        "# Calculate filtered size\n",
        "filtered_count = len(filtered_dataset['raw'])\n",
        "\n",
        "print(f\"\\nOriginal raw set size: {original_count}\")\n",
        "print(f\"Filtered raw set size: {filtered_count}\")\n",
        "print(f\"Removed {original_count - filtered_count} entries.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset structure: DatasetDict({\n",
            "    raw: Dataset({\n",
            "        features: ['venue', 'year', 'paper_id', 'title', 'abstract', 'decision', 'label', 'reviews'],\n",
            "        num_rows: 7404\n",
            "    })\n",
            "})\n",
            "\n",
            "First example from raw split: {'venue': 'ICLR.cc', 'year': '2024', 'paper_id': 'cXs5md5wAq', 'title': 'Modelling Microbial Communities with Graph Neural Networks', 'abstract': 'Understanding the interactions and interplay of microorganisms is a great challenge with many applications in medical and environmental settings. In this work, we model bacterial communities directly from their genomes using graph neural networks (GNNs). GNNs leverage the inductive bias induced by the set nature of bacteria, enforcing permutation invariance and granting combinatorial generalization. We propose to learn the dynamics implicitly by directly predicting community relative abundance profiles at steady state, thus escaping the need for growth curves. On two real-world datasets, we show for the first time generalization to unseen bacteria and different community structures. \\nTo investigate the prediction results more deeply, we created a simulation for flexible data generation and analyze effects of bacteria interaction strength, community size, and training data amount.', 'decision': 'Reject', 'label': 0, 'reviews': [{'confidence': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.', 'questions': 'What is the rationale for using a GNN on a very simple graph?\\n\\nWhat is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).', 'rating': '3: reject, not good enough', 'strengths': 'Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.', 'summary': 'The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.', 'weaknesses': 'The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as “By using k graph convolutional layers after one another we can achieve k-hop information propagation” rather misleading. \\n\\nOverall, the proposed method - applying GNN model in a straightforward way to a very small, fully-connected graph - is poorly justified and weak on novelty.'}, {'confidence': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.', 'questions': '1. How the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \\n\\n2. How scalable is the GNN-based implementation with respect to the number of microbial species?', 'rating': '3: reject, not good enough', 'strengths': 'The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.', 'summary': 'The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.', 'weaknesses': '1. The methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \\n\\n2. The main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\\n\\n3. For simulations, the GLV equations along with initial conditions and parameters $\\\\mu_i, K_i, a_{i,j}$ drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\\n\\n4. Given the GLV equations, the steady state solutions can be found by solving a system of $|S|$ linear algebraic equations:\\n    \\\\begin{equation}\\n        \\\\sum_{j=1}^{|S|}a_{i,j}n_j = K_i.\\n    \\\\end{equation}\\nThe steady state is entirely determined by the parameters $a_{i,j}$ and $K_i$. The authors use a vector composed of $[\\\\mu_i, K_i, \\\\nu_i^s, \\\\nu_i^r, random]$ (where $a_{i,j} \\\\approx \\\\nu_i^s. \\\\nu_j^r$) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components $[K_i, \\\\nu_i^s, \\\\nu_i^r]$ determine the steady state solution.\\n\\n5. The parameter $a_{i,j}$ (broken into two vectors $\\\\nu_i^s, \\\\nu_j^r$ to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\\n\\n6. A proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive $\\\\nu$ vectors. The claim of interpretability seems to be questionable. \\n    \\n7. The authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated \"\\\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}\" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\\n\\n8. The authors need to provide details on how the node (genome) attributes were obtained, especially $\\\\nu$\\'s, as in real-world data, the ground-truth interaction $a_{ij}$ is not available.'}, {'confidence': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.', 'questions': 'See weaknesses. \\n\\nMy main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.', 'rating': '6: marginally above the acceptance threshold', 'strengths': \"I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:\\n* The authors' comparative approach between models is commendable.\\n* The paper addresses a clinically relevant topic, shedding light on bacterial interactions.\\n* The authors' transparency regarding the challenges in scaling the mod\", 'summary': 'The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.', 'weaknesses': \"While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:\\n* Motivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia “1010 to 1011 cells per gram of intestinal content” seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.\\n* Sample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I’m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn’t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.\\n* Clarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can’t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.\\n* Simulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.\\nRegarding the conclusion I’m a little confused as to why it doesn’t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?\"}, {'confidence': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.', 'questions': 'Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\\n\\nHave the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \\n\\nModeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html', 'rating': '6: marginally above the acceptance threshold', 'strengths': '- Novel problem setup and the first use of GNN to tackle this problem. \\n- The use of GNN matches with the data well since it is modeling a dynamic system. \\n- Very interesting set of experiments and they are extensive. \\n- The presentation is nice and clear.\\n- Nice simulation data construction and results.', 'summary': 'The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.', 'weaknesses': '- Methodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.'}]}\n",
            "\n",
            "Original raw set size: 7404\n",
            "Filtered raw set size: 7262\n",
            "Removed 142 entries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a1b4c20"
      },
      "source": [
        "## Prompt Engineering\n",
        "\n",
        "Generate structured chat prompts for zero-shot and few-shot classification.\n",
        "\n",
        "We use 'system' and 'user' roles in the prompt to structure the conversation and provide clear instructions to the language model, reflecting the data that instruction-tuned models like Qwen and LLaMa are pre-trained on.\n",
        "\n",
        "### System Role\n",
        "The `system` role is used to set the overall behavior, persona, or instructions for the AI. It tells the model how it should respond. In our case, `\"You are an expert reviewer. Predict whether the paper was accepted or rejected based on the following reviews. Output only 'Accept' or 'Reject'.\"` establishes the model's persona (expert reviewer), the task (predict acceptance/rejection), and the desired output format ('Accept' or 'Reject').\n",
        "\n",
        "### User Role\n",
        "The `user` role represents the input or query from the human. It's where we provide the actual content the model needs to process, such as the paper's title, abstract, and reviews. The model is expected to generate a response based on this specific input, adhering to the guidelines set by the system prompt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8517e74"
      },
      "source": [
        "def format_data(entry):\n",
        "    \"\"\"Formats data into a readable string for the model.\"\"\"\n",
        "    submission_text = f\"Title: {entry['title']}\\nAbstract: {entry['abstract']}\\n\\nReviews:\\n\"\n",
        "    for i, review in enumerate(entry['reviews']):\n",
        "        submission_text += f\"Review {i+1}:\\n\"\n",
        "        submission_text += f\"Summary: {review.get('summary', 'N/A')}\\n\"\n",
        "        submission_text += f\"Strengths: {review.get('strengths', 'N/A')}\\n\"\n",
        "        submission_text += f\"Weaknesses: {review.get('weaknesses', 'N/A')}\\n\"\n",
        "        submission_text += f\"Questions: {review.get('questions', 'N/A')}\\n\"\n",
        "        # submission_text += f\"Rating: {review.get('rating', 'N/A')}\\n\"\n",
        "        # submission_text += f\"Confidence: {review.get('confidence', 'N/A')}\\n\"\n",
        "        submission_text += \"\\n\"\n",
        "    return submission_text.strip()\n",
        "\n",
        "def create_prompt(entry, few_shot_entries=None):\n",
        "    \"\"\"\n",
        "    Creates a structured chat prompt for the model.\n",
        "    :param entry: A single entry from the dataset.\n",
        "    :param shots: Optional list of shots to include in the prompt.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert reviewer. Predict whether the paper was accepted or rejected based on the following reviews. Output only 'Accept' or 'Reject'.\"}\n",
        "    ]\n",
        "\n",
        "    if few_shot_entries:\n",
        "        for shot in few_shot_entries:\n",
        "            user_content = format_data(shot)\n",
        "            assistant_content = shot['decision']\n",
        "            messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
        "\n",
        "    # Target entry\n",
        "    user_content = format_data(entry)\n",
        "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "\n",
        "    return messages"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Prompts"
      ],
      "metadata": {
        "id": "kJM55SV6C13r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grab samples\n",
        "samples = [filtered_dataset['raw'][i] for i in range(3)]\n",
        "target_sample = samples[0]\n",
        "few_shot_samples = samples[1:3]\n",
        "\n",
        "# Generate zero-shot example\n",
        "zero_shot_prompt = create_prompt(target_sample)\n",
        "print(\"=== ZERO-SHOT PROMPT EXAMPLE ===\")\n",
        "for msg in zero_shot_prompt:\n",
        "    print(f\"Role: {msg['role']}\")\n",
        "    print(f\"Content Preview: {msg['content']}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Generate and print 2-shot example\n",
        "two_shot_prompt = create_prompt(target_sample, few_shot_entries=few_shot_samples)\n",
        "print(\"=== TWO-SHOT PROMPT EXAMPLE ===\")\n",
        "for msg in two_shot_prompt:\n",
        "    print(f\"Role: {msg['role']}\")\n",
        "    print(f\"Content Preview: {msg['content'][:100]}...\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Frj2RXKC0HQ",
        "outputId": "d14ac2ee-b0c2-4c2b-ba8b-2a5c6c8ca24e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ZERO-SHOT PROMPT EXAMPLE ===\n",
            "Role: system\n",
            "Content Preview: You are an expert reviewer. Predict whether the paper was accepted or rejected based on the following reviews. Output only 'Accept' or 'Reject'.\n",
            "--------------------\n",
            "Role: user\n",
            "Content Preview: Title: Modelling Microbial Communities with Graph Neural Networks\n",
            "Abstract: Understanding the interactions and interplay of microorganisms is a great challenge with many applications in medical and environmental settings. In this work, we model bacterial communities directly from their genomes using graph neural networks (GNNs). GNNs leverage the inductive bias induced by the set nature of bacteria, enforcing permutation invariance and granting combinatorial generalization. We propose to learn the dynamics implicitly by directly predicting community relative abundance profiles at steady state, thus escaping the need for growth curves. On two real-world datasets, we show for the first time generalization to unseen bacteria and different community structures. \n",
            "To investigate the prediction results more deeply, we created a simulation for flexible data generation and analyze effects of bacteria interaction strength, community size, and training data amount.\n",
            "\n",
            "Reviews:\n",
            "Review 1:\n",
            "Summary: The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.\n",
            "Strengths: Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.\n",
            "Weaknesses: The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as “By using k graph convolutional layers after one another we can achieve k-hop information propagation” rather misleading. \n",
            "\n",
            "Overall, the proposed method - applying GNN model in a straightforward way to a very small, fully-connected graph - is poorly justified and weak on novelty.\n",
            "Questions: What is the rationale for using a GNN on a very simple graph?\n",
            "\n",
            "What is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).\n",
            "\n",
            "Review 2:\n",
            "Summary: The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.\n",
            "Strengths: The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.\n",
            "Weaknesses: 1. The methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \n",
            "\n",
            "2. The main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\n",
            "\n",
            "3. For simulations, the GLV equations along with initial conditions and parameters $\\mu_i, K_i, a_{i,j}$ drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\n",
            "\n",
            "4. Given the GLV equations, the steady state solutions can be found by solving a system of $|S|$ linear algebraic equations:\n",
            "    \\begin{equation}\n",
            "        \\sum_{j=1}^{|S|}a_{i,j}n_j = K_i.\n",
            "    \\end{equation}\n",
            "The steady state is entirely determined by the parameters $a_{i,j}$ and $K_i$. The authors use a vector composed of $[\\mu_i, K_i, \\nu_i^s, \\nu_i^r, random]$ (where $a_{i,j} \\approx \\nu_i^s. \\nu_j^r$) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components $[K_i, \\nu_i^s, \\nu_i^r]$ determine the steady state solution.\n",
            "\n",
            "5. The parameter $a_{i,j}$ (broken into two vectors $\\nu_i^s, \\nu_j^r$ to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\n",
            "\n",
            "6. A proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive $\\nu$ vectors. The claim of interpretability seems to be questionable. \n",
            "    \n",
            "7. The authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated \"\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}\" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\n",
            "\n",
            "8. The authors need to provide details on how the node (genome) attributes were obtained, especially $\\nu$'s, as in real-world data, the ground-truth interaction $a_{ij}$ is not available.\n",
            "Questions: 1. How the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \n",
            "\n",
            "2. How scalable is the GNN-based implementation with respect to the number of microbial species?\n",
            "\n",
            "Review 3:\n",
            "Summary: The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.\n",
            "Strengths: I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:\n",
            "* The authors' comparative approach between models is commendable.\n",
            "* The paper addresses a clinically relevant topic, shedding light on bacterial interactions.\n",
            "* The authors' transparency regarding the challenges in scaling the mod\n",
            "Weaknesses: While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:\n",
            "* Motivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia “1010 to 1011 cells per gram of intestinal content” seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.\n",
            "* Sample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I’m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn’t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.\n",
            "* Clarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can’t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.\n",
            "* Simulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.\n",
            "Regarding the conclusion I’m a little confused as to why it doesn’t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?\n",
            "Questions: See weaknesses. \n",
            "\n",
            "My main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.\n",
            "\n",
            "Review 4:\n",
            "Summary: The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.\n",
            "Strengths: - Novel problem setup and the first use of GNN to tackle this problem. \n",
            "- The use of GNN matches with the data well since it is modeling a dynamic system. \n",
            "- Very interesting set of experiments and they are extensive. \n",
            "- The presentation is nice and clear.\n",
            "- Nice simulation data construction and results.\n",
            "Weaknesses: - Methodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.\n",
            "Questions: Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\n",
            "\n",
            "Have the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \n",
            "\n",
            "Modeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html\n",
            "--------------------\n",
            "\n",
            "\n",
            "=== TWO-SHOT PROMPT EXAMPLE ===\n",
            "Role: system\n",
            "Content Preview: You are an expert reviewer. Predict whether the paper was accepted or rejected based on the followin...\n",
            "--------------------\n",
            "Role: user\n",
            "Content Preview: Title: TabR: Tabular Deep Learning Meets Nearest Neighbors\n",
            "Abstract: Deep learning (DL) models for t...\n",
            "--------------------\n",
            "Role: assistant\n",
            "Content Preview: Accept (poster)...\n",
            "--------------------\n",
            "Role: user\n",
            "Content Preview: Title: Neural Evolutionary Kernel Method: A Knowledge-Based Learning Architechture for Evolutionary ...\n",
            "--------------------\n",
            "Role: assistant\n",
            "Content Preview: Reject...\n",
            "--------------------\n",
            "Role: user\n",
            "Content Preview: Title: Modelling Microbial Communities with Graph Neural Networks\n",
            "Abstract: Understanding the intera...\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef9fa280"
      },
      "source": [
        "## Model Evaluation Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0c86148"
      },
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate_model(model_id, dataset, num_test_samples=20, shots=0):\n",
        "    # print(f\"Loading model: {model_id}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=\"auto\",\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Access the 'raw' split\n",
        "    data = dataset['raw']\n",
        "\n",
        "    # select few-shot and test entries ensuring no overlap\n",
        "    few_shot_entries = [data[i] for i in range(shots)]\n",
        "    test_entries = [data[i] for i in range(shots, shots + num_test_samples)]\n",
        "\n",
        "    correct_predictions = 0\n",
        "    all_results = [] # List to store all results for analysis\n",
        "\n",
        "    # print(f\"Starting evaluation (Shots: {shots}, Test Samples: {num_test_samples})...\")\n",
        "\n",
        "    for idx, entry in tqdm(enumerate(test_entries), total=num_test_samples, desc=\"Evaluating samples\"):\n",
        "        # Create prompt\n",
        "        messages = create_prompt(entry, few_shot_entries)\n",
        "\n",
        "        # Prepare input\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        # Generate response\n",
        "        generated_ids = model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=10,\n",
        "            do_sample=False  # Deterministic for reproducibility\n",
        "        )\n",
        "\n",
        "        # Decode output\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "\n",
        "        # Determine ground truth (Label 1 = Accept, Label 0 = Reject)\n",
        "        ground_truth = \"Accept\" if entry['label'] == 1 else \"Reject\"\n",
        "\n",
        "        # Store results for analysis\n",
        "        all_results.append({\n",
        "            \"input_text\": text,\n",
        "            \"model_response\": response,\n",
        "            \"ground_truth\": ground_truth,\n",
        "            \"is_correct\": (ground_truth.lower() in response.lower())\n",
        "        })\n",
        "\n",
        "        # Check prediction\n",
        "        # We check if the ground truth keyword is present in the response (case-insensitive)\n",
        "        if ground_truth.lower() in response.lower():\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / num_test_samples\n",
        "\n",
        "    # Clean up to free memory\n",
        "    del model\n",
        "    del tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return shots, accuracy, all_results"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "U23zT6QqIsAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ZERO SHOT EVALUATION\n",
        "model_id = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
        "print(\"=== ZERO-SHOT EVALUATIONS ===\")\n",
        "# shots0, acc_shots0, results_shots0 = evaluate_model(model_id, filtered_dataset, num_test_samples=20, shots=0)\n",
        "shots0, acc_shots0, results_shots0 = evaluate_model(model_id, filtered_dataset, filtered_count, shots=0)\n",
        "print(f\"{model_id}: {shots0} SHOT ACCURACY: {acc_shots0:.2%}\\n\")\n",
        "\n",
        "# FEW SHOT EVALUATION\n",
        "# print(\"=== FEW-SHOTS EVALUATION ===\")\n",
        "# shots1, acc_shots1, results_shots1 = evaluate_model(model_id, filtered_dataset, num_test_samples=20, shots=1)\n",
        "# shots2, acc_shots2, results_shots2 = evaluate_model(model_id, filtered_dataset, num_test_samples=20, shots=2)\n",
        "# shots3, acc_shots3, results_shots3 = evaluate_model(model_id, filtered_dataset, num_test_samples=20, shots=3)\n",
        "# print(f\"{model_id}: {shots1} SHOT ACCURACY: {acc_shots1:.2%}\\n\")\n",
        "# print(f\"{model_id}: {shots2} SHOT ACCURACY: {acc_shots2:.2%}\\n\")\n",
        "# print(f\"{model_id}: {shots3} SHOT ACCURACY: {acc_shots3:.2%}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "ec87b579ecf448588fd88af4f5e9f6e1",
            "404ae89faea64cfaa6c7ad942f45a8c3",
            "10969592322c43189b9f4197d872113f",
            "c2fe4f1ebc5b4e95b388618e4effa96a",
            "6cabe5cd27da4d359bf6f7f3a9353d24",
            "558b025cc9344f2aad565e28d1994f58",
            "aab2fdddcfc240bbaaa2e18dea7dd8bb",
            "06cd09c747a147babed023725681f55a",
            "6e21c819bfb14161b759fe8b2a210ea7",
            "9d0fcc2ac6304a8980b92158b1b270df",
            "99517b078326412082af5be17be26ecd"
          ]
        },
        "id": "2pN9lbVv_82N",
        "outputId": "8d4bed73-f60f-4a8d-ee36-920527f876a9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ZERO-SHOT EVALUATIONS ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating samples:   0%|          | 0/7262 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec87b579ecf448588fd88af4f5e9f6e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen/Qwen2.5-1.5B-Instruct: 0 SHOT ACCURACY: 70.89%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab05aa37",
        "outputId": "2b7ea3fa-7512-462b-cedd-e33b98acaed9"
      },
      "source": [
        "# You can now analyze results_zero_shot and results_few_shot lists.\n",
        "# For example, to see the first zero-shot result:\n",
        "print(\"\\n=== FIRST ZERO-SHOT RESULT ===\")\n",
        "print(\"=== Input Text ===\\n\", results_shots0[0]['input_text'], \"\\n\")\n",
        "print(\"=== Model Response ===\\n\", results_shots0[0]['model_response'], \"\\n\")\n",
        "print(\"=== Ground Truth ===\\n\",results_shots0[0]['ground_truth'], \"\\n\")\n",
        "\n",
        "# print(\"\\nZero-shot Evaluation Details:\")\n",
        "# for i, result in enumerate(results_shots0[:10]):\n",
        "#     print(f\"\\nSample {i+1}:\")\n",
        "#     print(f\"  Model Response: {result['model_response']}\")\n",
        "#     print(f\"  Ground Truth: {result['ground_truth']}\")\n",
        "#     print(f\"  Correct: {result['is_correct']}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FIRST ZERO-SHOT RESULT ===\n",
            "=== Input Text ===\n",
            " <|im_start|>system\n",
            "You are an expert reviewer. Predict whether the paper was accepted or rejected based on the following reviews. Output only 'Accept' or 'Reject'.<|im_end|>\n",
            "<|im_start|>user\n",
            "Title: Modelling Microbial Communities with Graph Neural Networks\n",
            "Abstract: Understanding the interactions and interplay of microorganisms is a great challenge with many applications in medical and environmental settings. In this work, we model bacterial communities directly from their genomes using graph neural networks (GNNs). GNNs leverage the inductive bias induced by the set nature of bacteria, enforcing permutation invariance and granting combinatorial generalization. We propose to learn the dynamics implicitly by directly predicting community relative abundance profiles at steady state, thus escaping the need for growth curves. On two real-world datasets, we show for the first time generalization to unseen bacteria and different community structures. \n",
            "To investigate the prediction results more deeply, we created a simulation for flexible data generation and analyze effects of bacteria interaction strength, community size, and training data amount.\n",
            "\n",
            "Reviews:\n",
            "Review 1:\n",
            "Summary: The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.\n",
            "Strengths: Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.\n",
            "Weaknesses: The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as “By using k graph convolutional layers after one another we can achieve k-hop information propagation” rather misleading. \n",
            "\n",
            "Overall, the proposed method - applying GNN model in a straightforward way to a very small, fully-connected graph - is poorly justified and weak on novelty.\n",
            "Questions: What is the rationale for using a GNN on a very simple graph?\n",
            "\n",
            "What is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).\n",
            "\n",
            "Review 2:\n",
            "Summary: The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.\n",
            "Strengths: The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.\n",
            "Weaknesses: 1. The methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \n",
            "\n",
            "2. The main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\n",
            "\n",
            "3. For simulations, the GLV equations along with initial conditions and parameters $\\mu_i, K_i, a_{i,j}$ drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\n",
            "\n",
            "4. Given the GLV equations, the steady state solutions can be found by solving a system of $|S|$ linear algebraic equations:\n",
            "    \\begin{equation}\n",
            "        \\sum_{j=1}^{|S|}a_{i,j}n_j = K_i.\n",
            "    \\end{equation}\n",
            "The steady state is entirely determined by the parameters $a_{i,j}$ and $K_i$. The authors use a vector composed of $[\\mu_i, K_i, \\nu_i^s, \\nu_i^r, random]$ (where $a_{i,j} \\approx \\nu_i^s. \\nu_j^r$) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components $[K_i, \\nu_i^s, \\nu_i^r]$ determine the steady state solution.\n",
            "\n",
            "5. The parameter $a_{i,j}$ (broken into two vectors $\\nu_i^s, \\nu_j^r$ to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\n",
            "\n",
            "6. A proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive $\\nu$ vectors. The claim of interpretability seems to be questionable. \n",
            "    \n",
            "7. The authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated \"\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}\" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\n",
            "\n",
            "8. The authors need to provide details on how the node (genome) attributes were obtained, especially $\\nu$'s, as in real-world data, the ground-truth interaction $a_{ij}$ is not available.\n",
            "Questions: 1. How the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \n",
            "\n",
            "2. How scalable is the GNN-based implementation with respect to the number of microbial species?\n",
            "\n",
            "Review 3:\n",
            "Summary: The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.\n",
            "Strengths: I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:\n",
            "* The authors' comparative approach between models is commendable.\n",
            "* The paper addresses a clinically relevant topic, shedding light on bacterial interactions.\n",
            "* The authors' transparency regarding the challenges in scaling the mod\n",
            "Weaknesses: While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:\n",
            "* Motivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia “1010 to 1011 cells per gram of intestinal content” seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.\n",
            "* Sample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I’m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn’t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.\n",
            "* Clarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can’t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.\n",
            "* Simulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.\n",
            "Regarding the conclusion I’m a little confused as to why it doesn’t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?\n",
            "Questions: See weaknesses. \n",
            "\n",
            "My main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.\n",
            "\n",
            "Review 4:\n",
            "Summary: The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.\n",
            "Strengths: - Novel problem setup and the first use of GNN to tackle this problem. \n",
            "- The use of GNN matches with the data well since it is modeling a dynamic system. \n",
            "- Very interesting set of experiments and they are extensive. \n",
            "- The presentation is nice and clear.\n",
            "- Nice simulation data construction and results.\n",
            "Weaknesses: - Methodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.\n",
            "Questions: Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\n",
            "\n",
            "Have the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \n",
            "\n",
            "Modeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html<|im_end|>\n",
            "<|im_start|>assistant\n",
            " \n",
            "\n",
            "=== Model Response ===\n",
            " Reject \n",
            "\n",
            "=== Ground Truth ===\n",
            " Reject \n",
            "\n"
          ]
        }
      ]
    }
  ]
}