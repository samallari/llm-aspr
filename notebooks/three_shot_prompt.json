[
  [
    {
      "role": "user",
      "content": "Title:  Modelling Microbial Communities with Graph Neural Networks\nAbstract:  Understanding the interactions and interplay of microorganisms is a great challenge with many applications in medical and environmental settings. In this work, we model bacterial communities directly from their genomes using graph neural networks (GNNs). GNNs leverage the inductive bias induced by the set nature of bacteria, enforcing permutation invariance and granting combinatorial generalization. We propose to learn the dynamics implicitly by directly predicting community relative abundance profiles at steady state, thus escaping the need for growth curves. On two real-world datasets, we show for the first time generalization to unseen bacteria and different community structures.   To investigate the prediction results more deeply, we created a simulation for flexible data generation and analyze effects of bacteria interaction strength, community size, and training data amount.\nReviews:   \nReview 1:\nSummary:  The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.  \nStrengths:  Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.  \nWeaknesses:  The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as \u201cBy using k graph convolutional layers after one another we can achieve k-hop information propagation\u201d rather misleading. \n\nOverall, the proposed method \\- applying GNN model in a straightforward way to a very small, fully-connected graph \\- is poorly justified and weak on novelty.  \nQuestions:  What is the rationale for using a GNN on a very simple graph?\n\nWhat is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).  \nReview 2:\nSummary:  The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.  \nStrengths:  The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.  \nWeaknesses:  1\\. The methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \n\n2\\. The main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\n\n3\\. For simulations, the GLV equations along with initial conditions and parameters $\\mu_i, K_i, a_{i,j}$ drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\n\n4\\. Given the GLV equations, the steady state solutions can be found by solving a system of $|S|$ linear algebraic equations:  \n    \\begin{equation}  \n        \\sum_{j=1}^{|S|}a_{i,j}n_j = K_i.  \n    \\end{equation}  \nThe steady state is entirely determined by the parameters $a_{i,j}$ and $K_i$. The authors use a vector composed of $[\\mu_i, K_i, \\nu_i^s, \\nu_i^r, random]$ (where $a_{i,j} \\approx \\nu_i^s. \\nu_j^r$) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components $[K_i, \\nu_i^s, \\nu_i^r]$ determine the steady state solution.\n\n5\\. The parameter $a_{i,j}$ (broken into two vectors $\\nu_i^s, \\nu_j^r$ to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\n\n6\\. A proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive $\\nu$ vectors. The claim of interpretability seems to be questionable.   \n      \n7\\. The authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated \"\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}\" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\n\n8\\. The authors need to provide details on how the node (genome) attributes were obtained, especially $\\nu$'s, as in real-world data, the ground-truth interaction $a_{ij}$ is not available.  \nQuestions:  1\\. How the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \n\n2\\. How scalable is the GNN-based implementation with respect to the number of microbial species?  \nReview 3:\nSummary:  The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.  \nStrengths:  I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:  \n* The authors' comparative approach between models is commendable.  \n* The paper addresses a clinically relevant topic, shedding light on bacterial interactions.  \n* The authors' transparency regarding the challenges in scaling the mod  \nWeaknesses:  While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:  \n* Motivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia \u201c1010 to 1011 cells per gram of intestinal content\u201d seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.  \n* Sample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I\u2019m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn\u2019t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.  \n* Clarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can\u2019t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.  \n* Simulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.  \nRegarding the conclusion I\u2019m a little confused as to why it doesn\u2019t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?  \nQuestions:  See weaknesses. \n\nMy main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.  \nReview 4:\nSummary:  The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.  \nStrengths:  - Novel problem setup and the first use of GNN to tackle this problem.   \n- The use of GNN matches with the data well since it is modeling a dynamic system.   \n- Very interesting set of experiments and they are extensive.   \n- The presentation is nice and clear.  \n- Nice simulation data construction and results.  \nWeaknesses:  - Methodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.  \nQuestions:  Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\n\nHave the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \n\nModeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html"
    },
    {
      "role": "assistant",
      "content": "<reasoning>\n**1. Review Analysis**\n\n  * **Review 1 (Negative):** Acknowledges the importance of the problem but identifies significant issues with the method's justification. Points out that the graph is fully connected (relegated to Supplementary Info), which contradicts the paper's narrative about graph topology and k-hop propagation. Deems novelty weak.\n  * **Review 2 (Negative/Mixed):** Extensive technical critique. Points out that the methodological contribution is limited to applying existing GNNs. Raises critical concerns about the simulation design\u2014specifically that interaction terms ($a_{ij}$) are embedded in the genome vectors, which contradicts biological reality (interactions are extrinsic). Also questions the clarity of the permutation invariance argument.\n  * **Review 3 (Negative/Mixed):** Focuses on domain relevance. Argues that the sample sizes (n=26) are too small to support the broad claims about medical applications (e.g., gut microbiome). Concerns about overfitting due to the inclusion of DNA data and data scarcity.\n  * **Review 4 (Positive/Mixed):** Appreciates the novel problem setup and application of GNNs. Finds the experiments interesting. However, acknowledges limited methodological novelty and suggests the paper might be better suited for a journal, implying it may not fit the conference criteria for novelty/impact.\n\n**2. Key Strengths**\n\n  * **Problem Domain:** All reviewers agree that modeling microbial communities is a high-impact area with significant medical and environmental relevance.\n  * **Application Novelty:** This is identified as the first use of GNNs for this specific biological problem, moving away from purely mechanistic models (GLV) or simple MLPs.\n  * **Benchmarking:** The authors created a simulation framework to generate data, which addresses the data scarcity issue in the field (though the validity of this simulation is contested).\n\n**3. Critical Weaknesses & Severity**\n\n  * **Methodological Justification (Fatal):** Review 1 highlights a critical disconnect: the authors use GNNs designed for complex topologies, but apply them to a fully connected graph (small clusters of bacteria). This makes the GNN machinery (like message passing) computationally heavy without the structural benefits usually associated with sparse graphs. The justification for using GNNs over other permutation-invariant architectures (like Deep Sets or Transformers) is weak.\n  * **Simulation Validity (Fatal):** Review 2 points out a fundamental flaw in the simulation data generation. The authors appear to derive node features (genomes) from interaction parameters ($a_{ij}$). In reality, interactions are emergent or extrinsic, not purely intrinsic to a single genome. This suggests the synthetic experiments may be solving a \"leaked\" problem where the answer is embedded in the input features, undermining the claims of generalization.\n  * **Scalability & Real-world Gap:** Review 3 notes the massive gap between the experimental setting (small sets) and the motivating applications (huge gut microbiomes), casting doubt on the practical utility of the proposed method.\n\n**4. Conflict Resolution**\n\n  * Review 4 suggests acceptance based on \"novel problem setup,\" while Reviews 1, 2, and 3 identify technical and methodological flaws.\n  * Review 2's mathematical critique regarding the GLV equation and feature construction is grounded and specific. The authors' approach to simulation seems to violate the separation of intrinsic (genome) and extrinsic (interaction) variables. This outweighs Review 4's general praise for the \"interestingness\" of the topic.\n  * Review 1's observation about the \"fully connected graph\" effectively neutralizes the primary architectural claim of the paper. If the graph is fully connected, the GNN is essentially functioning as a set processor, and the \"graph\" aspect is nominal.\n\n**5. Final Verdict Formulation**\nWhile the application area is promising, the paper suffers from two major flaws that prevent acceptance. First, the methodological choice of GNNs is poorly justified for fully connected graphs, with misleading claims about topology in the main text. Second, and more critically, the simulation\u2014which forms a core part of the experimental validation\u2014appears to rely on circular logic where interaction parameters are embedded into the node features, failing to model the true difficulty of predicting community dynamics from intrinsic genome data alone.\n\n</reasoning>\n<decision>\nREJECT\n</decision>"
    }
  ],
  [
    {
      "role": "user",
      "content": "Title:  TabR: Tabular Deep Learning Meets Nearest Neighbors\nAbstract:  Deep learning (DL) models for tabular data problems (e.g. classification, regression) are currently receiving increasingly more attention from researchers.  \nHowever, despite the recent efforts, the non-DL algorithms based on gradient-boosted decision trees (GBDT) remain a strong go-to solution for these problems.  \nOne of the research directions aimed at improving the position of tabular DL involves designing so-called retrieval-augmented models.  \nFor a target object, such models retrieve other objects (e.g. the nearest neighbors) from the available training data and use their features and labels to make a better prediction.\n\nIn this work, we present TabR \\-- essentially, a feed-forward network with a custom k-Nearest-Neighbors-like component in the middle.  \nOn a set of public benchmarks with datasets up to several million objects, TabR marks a big step forward for tabular DL: it demonstrates the best average performance among tabular DL models, becomes the new state-of-the-art on several datasets, and even outperforms GBDT models on the recently proposed \"GBDT-friendly\" benchmark (see Figure 1).  \nAmong the important findings and technical details powering TabR, the main ones lie in the attention-like mechanism that is responsible for retrieving the nearest neighbors and extracting valuable signal from them.  \nIn addition to the higher performance, TabR is simple and significantly more efficient compared to prior retrieval-based tabular DL models.  \nReviews:   \nReview 1:\nSummary:  This paper considers the problem of making predictions on tabular data. The authors propose a retrieval-augmented approach where a predictor takes the representation not of the table being predicted but also the representation of the nearest neighbors from a training dataset. The encoding representations and the predictors are training together and use straightforward architecture architectures. The main result is that a combination of the carefully crafted techniques outperforms GBDT on an ensemble of tasks. The training time is higher than GBDT but not unreasonable, and better compared to prior deep learning methods. The prediction times are better  \nStrengths:  1\\. The results seem to be a significant advance over prior work in tabular data predictions. In particular, the first deep learning model to outperform GBDT on an ensemble of datasets.  \n2\\. The experiments and analysis are quite extensive. Multiple datasets of different kinds of data, analysis of training and prediction times.  \n3\\. Clear articulation of which techniques helped. the techniques are overall not too complex.  \nWeaknesses:  A comparison of the inference and query complexity between the methods is lacking.  \nQuestions:  1\\. Inference time and compexity \\-- are the studies based on normalized inference time between models? If not, could you comment more? How does the inference complexity depend on the size of the table data?\n\n2\\. Could a different selection of datasets prove that the tabR is not superior to GBDT? In other words, are these datasets highly representative?\n\n3\\. Is it not surprising that Step-1 (adding context labels) did not help that much? One would guess that this is a big component of signal in retrieval augmentation.\n\n4\\. Not a question, but the methodology here reminds one of extreme classification and specifically this paper. https://arxiv.org/abs/2207.04452  \nReview 2:\nSummary:  This work proposes a retrieval-augmented deep learning architecture for tabular regression/classification. The model passes $x$, the row to be classified/predicted, as well as additional retrieval context rows, through a learned encoder. TabR then retrieves the rows most similar to the encoded form of $x$, where similarity is defined as the Euclidean distance between the encoded versions of two rows, mapped through a linear layer. The top retrieval candidates and their respective labels are then sent through some more learned transformations before being aggregated and combined with the encoded form of the row to be classified/regressed. This combined embedding goes through more MLP layers to result in the output.\n\nThe paper goes through variants of the architecture and how each respective change impacts performance. It then compares against other deep learning-based models as well as gradient boosted decision trees. In both default-hyperparameter and tuned-hyperparameter settings, TabR performs well.  \nStrengths:  1\\. The extensive amount of open-sourcing and experiment reproducibility is greatly appreciated.  \n1\\. Strong results relative to both deep learning and boosted tree methods, and TabR-S's relatively strong performance relative to out-of-the-box boosted tree libraries suggests this isn't just excessive parameter tweaking and overfitting via architecture search.  \n1\\. Easy to read, with key pieces of information generally emphasized appropriately.  \nWeaknesses:  1\\. Paper doesn't go into detail describing differences with prior deep learning-based tabular methods. What might explain the performance differences? Ex. \"prior work, where several layers with multi-head attention between objects and features are often used\" but was this what led to retrieval's low benefit in the past?  \n1\\. Insufficient discussion of categorical variables. Is accuracy or training time particularly affected by their relative abundance relative to numerical features?  \n1\\. The steps of Section 3.2 seem rather arbitrary. Some of the detail could be compressed to make room for more intuition why the final architecture makes more sense (content from A.1.1). Description of architectural changes that didn't work would also be very insightful.  \n1\\. Paper describes training times in A.4, but I believe a summary of this is important enough to warrant inclusion in the main paper. Something like a mention of the geometric mean (over the datasets) of the ratio between TabR's training time to a gradient boosted methods, described in the conclusion, would be sufficient. While the ratio is likely >1, it is better to acknowledge this weakness than to hide it.  \nQuestions:  See weaknesses. Also, what is $I_{cand}$? Is it all rows of the table that labels have been provided for? It's mentioned in page 3 that \"we use the same set of candidates for all input objects\" but what it the set of candidates exactly?  \nReview 3:\nSummary:  The paper introduces TabR, a retrieval-augmented tabular deep learning model that outperforms gradient-boosted decision trees (GBDT) on various datasets. TabR incorporates a novel retrieval module that is similar to the attention mechanism, which helps the model achieve the best average performance among tabular deep learning models and is more efficient compared to prior retrieval-based models.  \nStrengths:  1\\. TabR demonstrates superior performance compared to GBDT and other retrieval-based tabular deep learning models on multiple datasets.  \n2\\. The new similarity module in TabR has a reasonable intuitive motivation, allowing it to find and exploit natural hints in the data for better predictions.  \nWeaknesses:  1\\. Some aspects are not clear, see the questions section.  \nQuestions:  1\\.  What's the reason for choosing m to be 96? How does m affect the performance of TabR?  \n2\\.  What's the inference efficiency of TabR and how does it compare with other baselines (e.g., GBDT)?  \n3\\.  Is TabR applicable to categorical features? It seems like the paper only considers continuous features.  \nReview 4:\nSummary:  The authors meticulously designed a supervised deep learning model for tabular data prediction, which operates in a retrieval-like manner. It outperformed tree-based models on middle-scale datasets, as well as other retrieval-based deep learning tabular learning models. To achieve this, they introduced a k-Nearest-Neighbors-like idea in model design.  \nStrengths:  - As emphasized by the authors, their method has managed to outperform tree based models like xgboost on middle-scale datasets.\n\n- Overall, the presentation is clear, and the experiments are comprehensive. The details are clear and the model is highly reproducible.\n\n- This model is the best-performing retrieval based model.  \nWeaknesses:  - The motivations behind the module designs are not entirely clear. It appears that the authors made meticulous module (equation) optimization based on its performance on some datasets empirically. Then: \n\n(1) Why does employing the L2 distance, instand of the dot product, lead to improved performance (as shown in Eq. 3)? \n\n(2) Why is the T function required to use LinearWithoutBias? \n\n(3) We are uncertain about the robustness of the designed modules. If the dataset characteristics are changed, is it likely that the performance rankings will change significantly? The performances only on middle-sized datasets cannot show the robustness.\n\n...\n\nI suggest that providing a theoretical analysis or intuitive motivation would enhance the reader's understanding of those details.\n\n- Some sota DL approaches are not compared, such as T2G-Former (an improved version of FTT)[1], TabPFN [2], and TANGOS [3]. Especially, TabFPN is relatively similar to TabR. These papers are current SOTA, and may outperforms tree based models.\n\n[1] T2G-Former: Organizing tabular features into relation graphs promotes heterogeneous feature interaction\n\n[2] TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second\n\n[3] TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization\n\n- The major comparison lies among middle-scale datasets, accompanied with some results on few other datasets shown in Table 3. In scenarios involving sparse, medium, and dense data-distributed datasets (which typically occur in small, medium-sized, and large-sized datasets, respectively), I suppose that there exists a variance in the nearest neighbor retrieval pattern. Hence, conducting tests solely on medium-sized datasets may not suffice. Furthermore, the issue of inefficiency when dealing with large-scaled datasets appears to have hindered the authors from proving the method's effectiveness in large-scaled datasets.\n\n- The method proposed by the authors appears to have achieved slight performance advantages on certain datasets (although some SOTA are not compared). However, due to the lacks of explanation for the model details that are designed empirically, it seems unnecessary and risky to apply this method in real-world scenarios (for example, it's unclear whether L2 distance may fail when uninformative features are present; or, for instance, when a table has a feature with values [f_1, f_2, f_3, ..., f_n], and we take the logarithm of these values [log f_1, log f_2, log f_3, ..., log f_n] or their reciprocals, the method may perform poorly in such cases).\nQuestions:  - In Section 3.1, you mentioned \"continuous (i.e., continuous) features.\" Could this be a typographical error?\n\n- I am curious if the L2 design is sensitive to uninformative features? You can offer some analysis or conduct experiments by adding some gaussian noise columns (uninformative features are commonly seen in tabular datasets) and observe the change of performances. Some transformation like logarithm may impact the results.\n\n- Some questions in weakness."
    },
    {
      "role": "assistant",
      "content": "<reasoning>\n**1. Review Analysis**\n\n  * **Review 1 (Strong Positive):** Highlights the significance of the result\u2014specifically, a DL model finally outperforming GBDT on an ensemble of datasets. Praises the extensive experiments and analysis. Raises minor concerns about inference complexity analysis.\n  * **Review 2 (Positive):** Appreciates the reproducibility and strong results. Notes that even the simplified version (TabR-S) performs well, suggesting the results are robust and not just due to \"overfitting via architecture search.\" identifying the \"ad-hoc\" nature of the architecture construction as a minor weakness.\n  * **Review 3 (Positive):** Agrees that the performance is superior to GBDT and other retrieval baselines. Asks for clarification on specific hyperparameters and categorical feature handling.\n  * **Review 4 (Negative/Mixed):** The outlier. Acknowledges the performance but criticizes the \"empirical\" nature of the module design (e.g., why L2 distance?). Suggests missing baselines (TabPFN, TANGOS) and questions robustness on large-scale data.\n\n**2. Key Strengths**\n\n  * **Milestone Performance:** The paper achieves a long-sought goal in the tabular deep learning community: convincingly outperforming Gradient Boosted Decision Trees (GBDTs) on \"GBDT-friendly\" benchmarks. This is widely recognized by Reviews 1, 2, and 3 as a significant step forward.\n  * **Ablation & Simplicity:** The paper breaks down the architecture (TabR vs TabR-S) effectively. The method is simpler than previous attention-heavy retrieval mechanisms.\n  * **Reproducibility:** Code is open-sourced, and the benchmarks are standard.\n\n**3. Critical Weaknesses & Severity**\n\n  * **Missing Baselines (Review 4):** Review 4 cites TabPFN, T2G-Former, and TANGOS. However, TabPFN is specifically designed for *small* datasets (typically <10k samples) via in-context learning and does not scale to the \"millions\" of objects TabR handles. Comparing them is a category error. The omission of T2G/TANGOS is less critical given that TabR beats the ultimate baseline (GBDTs), which these other methods often struggle to consistently surpass. **(Non-Fatal)**\n  * **Empirical/Ad-hoc Design (Review 2, 4):** The architecture is criticized for being empirically derived (e.g., L2 distance choice). While theoretical justification is ideal, empirical engineering is standard in deep learning when supported by rigorous ablation studies, which this paper provides. **(Fixable/Minor)**\n  * **Inference Complexity:** Retrieval is inherently slower than tree inference. While the paper claims efficiency over *other* retrieval DL models, the trade-off vs. GBDT is a valid point to clarify, but not a reason for rejection given the accuracy gains. **(Fixable)**\n\n**4. Conflict Resolution**\n\n  * **Robustness vs. Overfitting:** Review 4 fears the model is over-engineered for specific datasets. Review 2 provides the counter-argument: the \"Simple\" version (TabR-S) performs strongly without complex tuning, suggesting the core inductive bias (retrieval) is sound, not just the hyperparameters.\n  * **Scale:** Review 4 argues \"millions\" is only \"middle-scale.\" In the context of academic tabular benchmarks, millions of rows are considered large. The critique that it might fail on larger datasets is speculative and sets an unreasonably high bar for a conference paper.\n\n**5. Final Verdict Formulation**\nThe paper presents a convincing advancement in tabular deep learning. The ability to consistently outperform GBDTs is a significant contribution that the community has been actively seeking. The critiques regarding empirical design choices and missing specific DL baselines are outweighed by the robustness of the results against the gold standard (GBDTs). The paper is solid, reproducible, and impactful.\n\n</reasoning>\n<decision>\nACCEPT\n</decision>"
    }
  ],
  [
    {
      "role": "user",
      "content": "Title:  Neural Evolutionary Kernel Method: A Knowledge-Based Learning Architechture for Evolutionary PDEs\nAbstract:  Numerical solution of partial differential equations (PDEs) plays a vital role in various fields of science and engineering. In recent years, deep neural networks (DNNs) have emerged as a powerful tool for solving PDEs. DNN-based methods exploit the approximation capabilities of neural networks to obtain solutions to PDEs in general domains or high-dimensional spaces. However, many of these methods lack the use of mathematical prior knowledge, and DNN-based methods usually require a large number of sample points and parameters, making them computationally expensive and challenging to train. This paper aims to introduce a novel method named the Neural Evolutionary Kernel Method (NEKM) for solving a class of evolutionary PDEs through DNNs based kernels. By using operator splitting and boundary integral techniques, we propose particular neural network architectures which approximate evolutionary kernels of solutions and preserve structures of time-dependent PDEs. Mathematical prior knowledge are naturally built into these DNNs based kernels through convolutional representation with pre-trained Green functions, leading to serious reduction in the number of parameters in the NEKM and very efficient training processes. Experimental results demonstrate the efficiency and accuracy of the NEKM in solving heat equations and Allen-Cahn equations in complex domains and on manifolds, showcasing its promising potential for applications in data driven scientific computing.  \nReviews:   \nReview 1:\nSummary:  The paper introduces a novel approach called Neural Evolutionary Kernel Method (NEKM) for solving time-dependent semi-linear Partial Differential Equations (PDEs). The authors leverage a combination of operator splitting, boundary integral techniques, and Deep Neural Networks (DNNs) to construct evolutionary blocks that approximate solution operators. NEKM incorporates mathematical prior knowledge into each block, utilizing convolution operations and nonlinear activations tailored to the specific PDEs under consideration. This approach offers several noteworthy contributions:\n\n1\\. **Efficiency and Generalizability**: The use of boundary integral techniques is a standout feature of NEKM, allowing for a reduced requirement of network parameters and sampling points. This not only improves training efficiency but also relaxes the regularity assumptions on solutions. The capacity to apply NEKM to problems in complex domains and on manifolds showcases its versatility and potential real-world applicability.\n\n2\\. **Compatibility with Time Discretization Schemes**: NEKM can be effectively combined with time discretization schemes that possess structure-preserving properties, such as energy stability. This demonstrates the adaptability of the method to diverse mathematical contexts.\n\n3\\. **Treatment of Singular Boundary Integrals**: The paper introduces a method for computing singular boundary integrals that arise from fundamental solutions. This addition contributes to the overall training efficiency and robustness of NEKM.\n\nThe empirical validation of NEKM is conducted through testing on heat equations and Allen-Cahn equations in complex domains and on manifolds. The results demonstrate the method's high accuracy and its capacity to generalize across various domains.\n\nIn summary, the paper presents an innovative and promising approach, NEKM, which addresses the solution of time-dependent semi-linear PDEs. The combination of mathematical prior knowledge, boundary integral techniques, and DNNs provides a compelling method that improves training efficiency, generalizability, and adaptability to different mathematical scenarios. The successful testing on various equations and domains underscores the method's potential significance in the field of mathematical modeling and scientific computing.  \nStrengths:  The strengths of the paper \"Neural Evolutionary Kernel Method (NEKM) for Solving Time-Dependent Semi-Linear PDEs\" include:\n\n1\\. **Innovative Approach**: The paper introduces a novel approach, NEKM, which combines operator splitting, boundary integral techniques, and Deep Neural Networks (DNNs) to address the solution of time-dependent semi-linear Partial Differential Equations (PDEs). This innovation offers a fresh perspective on tackling complex mathematical problems.\n\n2\\. **Efficiency Improvement**: NEKM leverages boundary integral techniques to reduce the need for extensive network parameters and sampling points. This not only enhances the efficiency of training but also relaxes regularity assumptions on solutions. This efficiency improvement is a significant advantage in solving real-world problems.\n\n3\\. **Generalizability**: The paper demonstrates that NEKM can be applied to problems in complex domains and on manifolds, showcasing its generalizability across different mathematical contexts. This broad applicability enhances its potential usefulness in a wide range of scientific and engineering applications.\n\n4\\. **Compatibility with Time Discretization Schemes**: NEKM's compatibility with time discretization schemes that possess structure-preserving properties, such as energy stability, is a valuable feature. This adaptability makes it easier to integrate NEKM into existing mathematical frameworks.\n\n5\\. **Treatment of Singular Boundary Integrals**: The paper provides a method for computing singular boundary integrals that arise from fundamental solutions. This contribution adds to the method's efficiency and robustness, making it more practical for real-world applications.\n\n6\\. **Empirical Validation**: The authors validate the NEKM approach through rigorous testing on heat equations and Allen-Cahn equations in complex domains and on manifolds. The high accuracy demonstrated in these tests underscores the practical utility of NEKM.\n\n7\\. **Mathematical Rigor**: NEKM incorporates mathematical prior knowledge into its framework through convolution operations and nonlinear activations. This mathematical rigor ensures that the method is well-founded and theoretically sound.\n\n8\\. **Interdisciplinary Relevance**: The paper's focus on solving complex mathematical problems with machine learning techniques has broad interdisciplinary relevance, as it can find applications in various fields, including physics, engineering, and computational science.\n\nOverall, the strengths of the paper lie in its innovative approach, efficiency improvements, generalizability, compatibility with existing mathematical schemes, and the rigorous empirical validation of the proposed method. These qualities make NEKM a promising addition to the field of mathematical modeling and scientific computing.  \nWeaknesses:  While the paper on \"Neural Evolutionary Kernel Method (NEKM) for Solving Time-Dependent Semi-Linear PDEs\" offers several strengths, there are also some potential weaknesses to consider:\n\n1\\. **Complexity**: The proposed NEKM method, while innovative, is complex in its approach, involving the integration of operator splitting, boundary integral techniques, and Deep Neural Networks. This complexity might make it challenging for practitioners who are not well-versed in all of these areas to implement and understand.\n\n2\\. **Computational Resources**: The paper does not extensively discuss the computational resources required for training and applying the NEKM method. Deep learning methods often demand significant computational power, which could be a limitation for some users, particularly those without access to high-performance computing resources.\n\n3\\. **Limited Real-World Use Cases**: While the paper demonstrates NEKM's effectiveness in solving specific mathematical problems, it remains largely theoretical. More real-world use cases and practical applications in various domains would strengthen the paper's relevance and utility.\n\n4\\. **Interpretability**: The paper discusses the use of neural networks, which are often seen as \"black-box\" models. While the paper addresses some interpretability challenges, it might not provide a complete solution to the interpretability issues associated with deep learning approaches.\n\n5\\. **Algorithm Complexity**: The proposed method involves a combination of different techniques, such as boundary integral representation and neural networks. This may make the implementation and understanding of NEKM challenging for some users, potentially limiting its widespread adoption.\n\n6\\. **Empirical Validation Scope**: While the paper includes empirical validation on heat and Allen-Cahn equations, the scope of the empirical validation might be limited. A more extensive range of test cases across different scientific and engineering domains would strengthen the method's generalizability.\n\n7\\. **Scalability**: The paper does not explicitly address the scalability of the NEKM method. As the complexity of problems increases, it remains to be seen whether NEKM can efficiently scale to handle more complex and larger-scale scenarios.\n\n8\\. **Comparison to Existing Methods**: The paper lacks a comprehensive comparison of the NEKM method with existing approaches for solving similar problems. Such comparisons would help to better assess the relative strengths and weaknesses of NEKM.\n\nIn conclusion, while the NEKM method offers several promising advantages, such as efficiency improvements and generalizability, it also has some potential limitations, including complexity, computational resource requirements, and the need for more extensive real-world applications and validation. These weaknesses should be considered when evaluating the method's suitability for specific applications.  \nQuestions:  1\\. Can you provide more insight into the computational resources required for training and applying the NEKM method? What kind of hardware and software infrastructure is necessary for its practical implementation?\n\n2\\. The NEKM method is quite complex, involving a combination of operator splitting, boundary integral techniques, and neural networks. How user-friendly and accessible is the implementation for researchers and practitioners who may not be experts in all these areas?\n\n3\\. The paper mentions empirical validation on heat and Allen-Cahn equations. Are there plans to expand the empirical validation to a broader range of mathematical problems or real-world applications to further assess the generalizability of NEKM?\n\n4\\. How does NEKM address the interpretability challenge often associated with deep learning methods? Can you provide more details on how NEKM helps users understand and trust its results, especially in cases where interpretability is critical?\n\n5\\. The paper mentions combining NEKM with time discretization schemes that possess structure-preserving properties. Could you elaborate on specific scenarios or use cases where this combination has proven to be advantageous?\n\n6\\. NEKM proposes the treatment of singular boundary integrals arising from fundamental solutions. Can you discuss the impact of this addition on the overall efficiency and robustness of the method in practical applications?\n\n7\\. In the real world, problems often scale in complexity. How does NEKM address the scalability challenge, especially when dealing with larger and more complex scenarios beyond the examples provided in the paper?\n\n8\\. The paper does not include a comprehensive comparison of NEKM with existing methods for solving similar problems. Could you share insights into how NEKM performs in comparison to other approaches, and in what scenarios it may have a comparative advantage?\n\n9\\. Are there any specific plans or ongoing research aimed at addressing some of the potential weaknesses or limitations identified in the paper, such as making the method more accessible or broadening the scope of empirical validation?\n\n10\\. How do you envision the practical adoption of NEKM in various scientific and engineering domains? Are there specific industries or areas where NEKM is expected to have a significant impact, and if so, what are the next steps for its real-world application?\n\nThese questions aim to seek further clarification and insights from the authors regarding the NEKM method and its potential applications and improvements.  \nReview 2:\nSummary:  This paper aims to tackle solving partial differential equations (PDEs) traditionally solved by numerical methods with deep neural networks (DNNs). The authors address the challenges of solving PDEs with DNNs that a majority of these methods do not use any mathematical or physical parameters and require a large amount of parameters to tune. The authors propose the Neural Evolutionary Kernel Method (NEKM) to solve a type of evolutionary PDEs with DNN based kernels. The core idea is to incorporate pre-trained Green's functions. NEKM is an alternating two-step procedure that first analytically or numerically solves a nonlinear ODE to obtain a flow map and then numerically integrate the related linear PDE with a convolutional kernel.  \nStrengths:  - Nice abstract that motivates the need for PDEs in science and engineering problems and use of numerical methods to solve them.  \n- The paper and abstract are well-written.  \n- Incorporating ideas from numerical methods, e.g., Green's function, boundary conditions and energy stability is very nice. In particular, I like to the discussion in subsection 2.2 on energy conservation and would like more details in the Appendix.  \n- The generalization and use of the pre-trained Green's function is nice.  \n- The computational savings of defining the Green's function on the boundary rather than the interior domain is nice. For other boundary integral representations for conservation laws, see Hansen, et. al, \"Learning physical models that can respect conservation laws\", ICML 2023 (https://arxiv.org/abs/2302.11002).  \n- Nice high dimensional simulations in Figures 6-7.  \n- Generalizability to different manifolds and boundary conditions.  \nWeaknesses:  - The authors should define earlier what they mean by evolutionary PDEs.  \n- Connection to other kernel operator methods such as the Fourier Neural Operator (FNO) should be considered. It is only briefly discussed in one sentence of related work with a majority on the PINNs literature. In particular, in the related works, the authors discuss in detail how boundary conditions are incorporated into Physics-Informed Neural Networks (PINNs). The related in Neural Operator community should be discussed, such as how to incorporated boundary conditions into Neural Operators in Saad et. al, \"Guiding continuous operator learning through Physics-based boundary constraints\", ICLR 2023.  \n- The method only works on semi-linear PDEs. This is actually a very strong assumption and limitation. The authors should discuss the extension to nonlinear PDEs.  \n- Evaluation: the method is only tested on the simple linear heat/diffusion equation and Allen-Cahn equations. The heat equation is smooth and parabolic and very easy for numerical methods to solve. It would be nice to test hyperbolic problems with shocks, e.g., in the GPME benchmarking framework in Hansen, et. al, \"Learning physical models that can respect conservation laws\", ICML 2023 (https://arxiv.org/abs/2302.11002).  \n- The method seems to have strong limitations if the first step requires an analytical or numerical solution to the ODE.   \n- In particular, the authors should clarify this in the last paragraph of the introduction. I don't understand where the nonlinear ODE is coming from in step 1 and then how there is \"numerically integration\" for the related linear PDE. Typically, in numerical methods a (non)linear PDE is first discretized in space and then the resulting semi-discrete form of the ODE is discretized in time. The authors should clarify what they mean here.  \n- I think some of the equation details of BINet in the related work should be moved to an appendix or background section.  \n- Care should be taken with the discretization because this adds a first order error into the scheme. For example, the first equation should not be discretized with the 1st order accurate Forward Euler without even citing the method. This is an explicit method and there are necessary bounds on $\\Delta t/\\tau$ to ensure numerical stability.  See Krishnapriyan et. al, \"Learning continuous models for continuous physics\", 2023 (https://arxiv.org/pdf/2202.08494.pdf) on how the time discretization matters in NeuralODE and the 4th order RK4 is advantageous but even that scheme without being careful about the numerics can lead to convergence issues.  \n- Ideally the method and presentation wouldn't need to be separated into separate cases for linear equations or not.  \n- It seems like the method depends too strongly on the BINet method and the authors should better differentiate the novelty between the two.  \n- The exposition of the method in Section 2 isn't too clear and some of the details can be moved to an appendix.  \n- The unique features of the NEKM subsection seems like it could be incorporated with the contributions subsection in the intro.  \n- Label x and y axis in Figure 3.  \n- Another major weakness in the evaluation is just comparing to the exact solution and no other baseline methods, especially to related neural operator based methods.\n\nMinor  \n- First paragraph of related works can be longer and combined with parts of the longer second paragraph.  \n- heat equation shouldn't be plural in the last bullet point of the contributions.  \n- comma after \"In this section\" at the beginning of Section 2 Method  \n- I would name Section 2 with the specific method name Neural Evolutionary Kernel Method (NEKM) rather than the generic Method.  \n- Could use standard notation from numerical methods $\\Delta t$ instead $\\tau$  \n- Comma missing after Equation 7.  \n- Larger title lave on Figure 6.  \nQuestions:  - Does the method only work on semi-linear PDEs? If so, this is a bit limiting and the authors should discuss the extension to nonlinear PDEs.  \nReview 3:\nSummary:  The paper presents the Neural Evolutionary Kernel Method (NEKM) for solving semi-linear time-dependent PDEs. NEKM distinguishes itself by utilizing operator splitting and boundary integration, enabling efficient network architectures. The method is demonstrated to be effective and stable in solving classic PDEs, such as the heat equation and the Allen-Cahn equation.  \nStrengths:  NEKM can be combined with time discretization schemes that preserve energy stability, which is crucial for modeling physical systems.  \nThe method incorporates an evolutionary kernel, which inherently preserves the structure of the problem.\n\nThe method incorporates an evolutionary kernel, which inherently preserves the structure of the problem.  \nWeaknesses:  While NEKM is claimed to work in complex domains, the paper primarily provides examples in small and relatively simple domains. It would be beneficial to demonstrate its performance in more complex and realistic domains, similar to the level in the referenced paper (https://arxiv.org/pdf/2309.00583), including real-world scientific and engineering geometries.\n\nThe paper lacks references to related work that adopts neural networks only at the spatial level while using time discretizations to evolve spatial fields over time. Including references to papers like \"Evolutional deep neural network (Physical Review E 2021),\" \"Implicit Neural Spatial Representations for Time-dependent PDEs (ICML 2023),\" and \"Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations\" could help provide context and comparisons.\n\nThe paper does not provide information about the computational cost and scalability of NEKM compared to classical numerical methods, especially for larger 3D problems. It would be valuable to include performance comparisons in terms of computational efficiency.  \nQuestions:  My biggest confusion and concern is the relationship between this paper (Lin et al., 2023a) as well as (Lin et al., 2023b). Those paper also use a convolution representation of the solutions using Green's functions. What exactly is the author's contribution except working with time-dependent problems?\n\nThe paper focuses on semi-linear PDEs, but it would be interesting to know if NEKM can be extended to handle nonlinear PDEs. Clarification on the limitations and potential extensions of the method for nonlinear problems would be beneficial.  \nReview 4:\nSummary:  This paper proposes a neural network-based algorithm, namely the Neural Evolutionary Kernal Method (NEKM), for solving evolutionary PDEs. The method involves the operator splitting technique and the idea of boundary integral network. Specifically, the method pre-trains a neural network representation of the Green function and then solves the evolutionary PDE by applying the Green function block and kernel function block alternatingly with an ODE solver. Experiments on the heat equation and Allen-Cahn equations are conducted to demonstrate the performance.  \nStrengths:  - The paper is well-written and easy-to-follow.  \n- The proposed method is interesting and mathematically grounded.  \n- Experimental results seem strong.  \nWeaknesses:  - It seems the method heavily relies on the closed form formula of the fundamental solution $G_0$. The numerical error of the integration involving $G_0$ seems troublesome.  \n- The experimental results of Allen-Cahn equation is not compared with the exact one or any other method.  \n- Some minor issues: Figure 12 is too small.  \nQuestions:  - Now that the Green function $G$ is computed by pre-training a neural network, the error of this step may propagate to solving the time evolutionary PDE. Was this problem an issue in the experiments? How accurate should the numerically approximated Green function be so as not to affect the performance?  \n- As mentioned in the paper, the possible singularity of $G_0$ may demand special handling. But the form of $G$ is generally unknown. How can the singularity appearing in $G$ be dealt with?  \n- Energy stsability is claimed as one of the contributions. Is this only empirically observed or grounded with some particular design?"
    },
    {
      "role": "assistant",
      "content": "<reasoning>\n**1. Review Analysis**\n\n  * **Review 1 (Strong Accept):** Very enthusiastic. Praises the innovative combination of boundary integrals and DNNs, efficiency, and mathematical rigor. Finds the empirical validation on complex domains strong.\n  * **Review 2 (Reject/Weak Reject):** Detailed technical critique. Points out that the evaluation is limited to simple problems (Heat equation) and lacks comparisons to modern baselines like Fourier Neural Operators (FNO). Raises concerns about the limitation to semi-linear PDEs and the potential numerical instability of the time discretization used (Forward Euler). Notes the method relies heavily on \"BINet\" and needs to differentiate itself better.\n  * **Review 3 (Weak Reject):** Focuses on novelty and prior work. Explicitly questions the contribution relative to previous papers (Lin et al., 2023a, 2023b) that also used Green's function convolutional representations. Criticizes the lack of comparison to spatial-temporal neural network literature.\n  * **Review 4 (Weak Accept):** Finds the method mathematically grounded and well-written. However, notes the absence of comparisons for the Allen-Cahn experiments (even against exact solutions) and raises concerns about error propagation from the pre-trained Green's function.\n\n**2. Key Strengths**\n\n  * **Methodological Grounding:** The approach integrates classical numerical analysis concepts (Green's functions, operator splitting, boundary integrals) with deep learning, which is a desirable direction for scientific machine learning.\n  * **Geometric Flexibility:** The method is theoretically capable of handling complex domains and manifolds, which is a common pain point for standard grid-based methods.\n  * **Efficiency:** Potential for reducing parameters compared to pure \"black-box\" DNN solvers.\n\n**3. Critical Weaknesses & Severity**\n\n  * **Evaluation & Baselines (Fatal):** This is the most significant flaw. As noted by Review 2 and Review 4, the paper compares primarily against exact solutions on relatively simple PDEs (Heat equation, Allen-Cahn). There is a complete lack of comparison against state-of-the-art Neural Operator methods (e.g., FNO, DeepONet) or other recent physics-informed baselines. Without these comparisons, it is impossible to assess if NEKM offers any real advantage over existing tools.\n  * **Novelty & Prior Work (High Severity):** Review 3 identifies potential significant overlap with prior work (Lin et al., 2023) regarding the core Green's function representation. If the main novelty is applying this known technique to time-dependent problems via standard operator splitting, the technical contribution is incremental.\n  * **Scope Limitations (Moderate):** The restriction to semi-linear PDEs and the use of simple time-stepping schemes (potentially unstable Forward Euler, as noted by Review 2) limit the method's practical impact compared to more robust solvers.\n\n**4. Conflict Resolution**\n\n  * Review 1's praise for \"rigorous testing\" is contradicted by Reviews 2 and 4, which correctly identify that testing on the Heat equation without SOTA baselines is insufficient for a top-tier ML conference. Review 1 likely overvalued the *existence* of experiments rather than their *comparative quality*.\n  * The novelty concerns raised by Review 3 regarding the authors' own prior work are specific and unrefuted in the context of the reviews provided. This weighs heavily against acceptance.\n\n**5. Final Verdict Formulation**\nWhile the paper proposes a mathematically interesting hybrid approach, it fails to meet the bar for acceptance due to insufficient evaluation. The absence of comparisons against modern baselines (like FNO or DeepONet) makes it impossible to validate claims of efficiency or accuracy. Furthermore, significant questions regarding the novelty of the method relative to the authors' prior work (Lin et al.) and the limitation to simple semi-linear PDEs suggest the paper requires further maturation and a more robust experimental setup.\n\n</reasoning>\n<decision>\nREJECT\n</decision>"
    }
  ]
]