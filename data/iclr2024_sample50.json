[
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "cXs5md5wAq",
    "title": "Modelling Microbial Communities with Graph Neural Networks",
    "reviews": [
      {
        "summary": "The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.",
        "strengths": "Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.",
        "weaknesses": "The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as \u201cBy using k graph convolutional layers after one another we can achieve k-hop information propagation\u201d rather misleading. \n\nOverall, the proposed method - applying GNN model in a straightforward way to a very small, fully-connected graph - is poorly justified and weak on novelty.",
        "questions": "What is the rationale for using a GNN on a very simple graph?\n\nWhat is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.",
        "strengths": "The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.",
        "weaknesses": "1. The methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \n\n2. The main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\n\n3. For simulations, the GLV equations along with initial conditions and parameters $\\mu_i, K_i, a_{i,j}$ drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\n\n4. Given the GLV equations, the steady state solutions can be found by solving a system of $|S|$ linear algebraic equations:\n    \\begin{equation}\n        \\sum_{j=1}^{|S|}a_{i,j}n_j = K_i.\n    \\end{equation}\nThe steady state is entirely determined by the parameters $a_{i,j}$ and $K_i$. The authors use a vector composed of $[\\mu_i, K_i, \\nu_i^s, \\nu_i^r, random]$ (where $a_{i,j} \\approx \\nu_i^s. \\nu_j^r$) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components $[K_i, \\nu_i^s, \\nu_i^r]$ determine the steady state solution.\n\n5. The parameter $a_{i,j}$ (broken into two vectors $\\nu_i^s, \\nu_j^r$ to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\n\n6. A proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive $\\nu$ vectors. The claim of interpretability seems to be questionable. \n    \n7. The authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated \"\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}\" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\n\n8. The authors need to provide details on how the node (genome) attributes were obtained, especially $\\nu$'s, as in real-world data, the ground-truth interaction $a_{ij}$ is not available.",
        "questions": "1. How the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \n\n2. How scalable is the GNN-based implementation with respect to the number of microbial species?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.",
        "strengths": "I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:\n* The authors' comparative approach between models is commendable.\n* The paper addresses a clinically relevant topic, shedding light on bacterial interactions.\n* The authors' transparency regarding the challenges in scaling the mod",
        "weaknesses": "While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:\n* Motivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia \u201c1010 to 1011 cells per gram of intestinal content\u201d seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.\n* Sample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I\u2019m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn\u2019t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.\n* Clarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can\u2019t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.\n* Simulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.\nRegarding the conclusion I\u2019m a little confused as to why it doesn\u2019t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?",
        "questions": "See weaknesses. \n\nMy main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.",
        "strengths": "- Novel problem setup and the first use of GNN to tackle this problem. \n- The use of GNN matches with the data well since it is modeling a dynamic system. \n- Very interesting set of experiments and they are extensive. \n- The presentation is nice and clear.\n- Nice simulation data construction and results.",
        "weaknesses": "- Methodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.",
        "questions": "Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\n\nHave the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \n\nModeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "rhgIgTSSxW",
    "title": "TabR: Tabular Deep Learning Meets Nearest Neighbors",
    "reviews": [
      {
        "summary": "This paper considers the problem of making predictions on tabular data. The authors propose a retrieval-augmented approach where a predictor takes the representation not of the table being predicted but also the representation of the nearest neighbors from a training dataset. The encoding representations and the predictors are training together and use straightforward architecture architectures. The main result is that a combination of the carefully crafted techniques outperforms GBDT on an ensemble of tasks. The training time is higher than GBDT but not unreasonable, and better compared to prior deep learning methods. The prediction times are better",
        "strengths": "1. The results seem to be a significant advance over prior work in tabular data predictions. In particular, the first deep learning model to outperform GBDT on an ensemble of datasets.\n2. The experiments and analysis are quite extensive. Multiple datasets of different kinds of data, analysis of training and prediction times.\n3. Clear articulation of which techniques helped. the techniques are overall not too complex.",
        "weaknesses": "A comparison of the inference and query complexity between the methods is lacking.",
        "questions": "1. Inference time and compexity -- are the studies based on normalized inference time between models? If not, could you comment more? How does the inference complexity depend on the size of the table data?\n\n2. Could a different selection of datasets prove that the tabR is not superior to GBDT? In other words, are these datasets highly representative?\n\n3. Is it not surprising that Step-1 (adding context labels) did not help that much? One would guess that this is a big component of signal in retrieval augmentation.\n\n4. Not a question, but the methodology here reminds one of extreme classification and specifically this paper. https://arxiv.org/abs/2207.04452",
        "rating": "8: accept, good paper",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This work proposes a retrieval-augmented deep learning architecture for tabular regression/classification. The model passes $x$, the row to be classified/predicted, as well as additional retrieval context rows, through a learned encoder. TabR then retrieves the rows most similar to the encoded form of $x$, where similarity is defined as the Euclidean distance between the encoded versions of two rows, mapped through a linear layer. The top retrieval candidates and their respective labels are then sent through some more learned transformations before being aggregated and combined with the encoded form of the row to be classified/regressed. This combined embedding goes through more MLP layers to result in the output.\n\nThe paper goes through variants of the architecture and how each respective change impacts performance. It then compares against other deep learning-based models as well as gradient boosted decision trees. In both default-hyperparameter and tuned-hyperparameter settings, TabR performs well.",
        "strengths": "1. The extensive amount of open-sourcing and experiment reproducibility is greatly appreciated.\n1. Strong results relative to both deep learning and boosted tree methods, and TabR-S's relatively strong performance relative to out-of-the-box boosted tree libraries suggests this isn't just excessive parameter tweaking and overfitting via architecture search.\n1. Easy to read, with key pieces of information generally emphasized appropriately.",
        "weaknesses": "1. Paper doesn't go into detail describing differences with prior deep learning-based tabular methods. What might explain the performance differences? Ex. \"prior work, where several layers with multi-head attention between objects and features are often used\" but was this what led to retrieval's low benefit in the past?\n1. Insufficient discussion of categorical variables. Is accuracy or training time particularly affected by their relative abundance relative to numerical features?\n1. The steps of Section 3.2 seem rather arbitrary. Some of the detail could be compressed to make room for more intuition why the final architecture makes more sense (content from A.1.1). Description of architectural changes that didn't work would also be very insightful.\n1. Paper describes training times in A.4, but I believe a summary of this is important enough to warrant inclusion in the main paper. Something like a mention of the geometric mean (over the datasets) of the ratio between TabR's training time to a gradient boosted methods, described in the conclusion, would be sufficient. While the ratio is likely >1, it is better to acknowledge this weakness than to hide it.",
        "questions": "See weaknesses. Also, what is $I_{cand}$? Is it all rows of the table that labels have been provided for? It's mentioned in page 3 that \"we use the same set of candidates for all input objects\" but what it the set of candidates exactly?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper introduces TabR, a retrieval-augmented tabular deep learning model that outperforms gradient-boosted decision trees (GBDT) on various datasets. TabR incorporates a novel retrieval module that is similar to the attention mechanism, which helps the model achieve the best average performance among tabular deep learning models and is more efficient compared to prior retrieval-based models.",
        "strengths": "1. TabR demonstrates superior performance compared to GBDT and other retrieval-based tabular deep learning models on multiple datasets.\n2. The new similarity module in TabR has a reasonable intuitive motivation, allowing it to find and exploit natural hints in the data for better predictions.",
        "weaknesses": "1. Some aspects are not clear, see the questions section.",
        "questions": "1.  What's the reason for choosing m to be 96? How does m affect the performance of TabR?\n2.  What's the inference efficiency of TabR and how does it compare with other baselines (e.g., GBDT)?\n3.  Is TabR applicable to categorical features? It seems like the paper only considers continuous features.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The authors meticulously designed a supervised deep learning model for tabular data prediction, which operates in a retrieval-like manner. It outperformed tree-based models on middle-scale datasets, as well as other retrieval-based deep learning tabular learning models. To achieve this, they introduced a k-Nearest-Neighbors-like idea in model design.",
        "strengths": "- As emphasized by the authors, their method has managed to outperform tree based models like xgboost on middle-scale datasets.\n\n- Overall, the presentation is clear, and the experiments are comprehensive. The details are clear and the model is highly reproducible.\n\n- This model is the best-performing retrieval based model.",
        "weaknesses": "- The motivations behind the module designs are not entirely clear. It appears that the authors made meticulous module (equation) optimization based on its performance on some datasets empirically. Then: \n\n(1) Why does employing the L2 distance, instand of the dot product, lead to improved performance (as shown in Eq. 3)? \n\n(2) Why is the T function required to use LinearWithoutBias? \n\n(3) We are uncertain about the robustness of the designed modules. If the dataset characteristics are changed, is it likely that the performance rankings will change significantly? The performances only on middle-sized datasets cannot show the robustness.\n\n...\n\nI suggest that providing a theoretical analysis or intuitive motivation would enhance the reader's understanding of those details.\n\n- Some sota DL approaches are not compared, such as T2G-Former (an improved version of FTT)[1], TabPFN [2], and TANGOS [3]. Especially, TabFPN is relatively similar to TabR. These papers are current SOTA, and may outperforms tree based models.\n\n[1] T2G-Former: Organizing tabular features into relation graphs promotes heterogeneous feature interaction\n\n[2] TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second\n\n[3] TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization\n\n- The major comparison lies among middle-scale datasets, accompanied with some results on few other datasets shown in Table 3. In scenarios involving sparse, medium, and dense data-distributed datasets (which typically occur in small, medium-sized, and large-sized datasets, respectively), I suppose that there exists a variance in the nearest neighbor retrieval pattern. Hence, conducting tests solely on medium-sized datasets may not suffice. Furthermore, the issue of inefficiency when dealing with large-scaled datasets appears to have hindered the authors from proving the method's effectiveness in large-scaled datasets.\n\n- The method proposed by the authors appears to have achieved slight performance advantages on certain datasets (although some SOTA are not compared). However, due to the lacks of explanation for the model details that are designed empirically, it seems unnecessary and risky to apply this method in real-world scenarios (for example, it's unclear whether L2 distance may fail when uninformative features are present; or, for instance, when a table has a feature with values [f_1, f_2, f_3, ..., f_n], and we take the logarithm of these values [log f_1, log f_2, log f_3, ..., log f_n] or their reciprocals, the method may perform poorly in such cases).",
        "questions": "- In Section 3.1, you mentioned \"continuous (i.e., continuous) features.\" Could this be a typographical error?\n\n- I am curious if the L2 design is sensitive to uninformative features? You can offer some analysis or conduct experiments by adding some gaussian noise columns (uninformative features are commonly seen in tabular datasets) and observe the change of performances. Some transformation like logarithm may impact the results.\n\n- Some questions in weakness.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Accept"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "kKRbAY4CXv",
    "title": "Neural Evolutionary Kernel Method: A Knowledge-Based Learning Architechture for Evolutionary PDEs",
    "reviews": [
      {
        "summary": "The paper introduces a novel approach called Neural Evolutionary Kernel Method (NEKM) for solving time-dependent semi-linear Partial Differential Equations (PDEs). The authors leverage a combination of operator splitting, boundary integral techniques, and Deep Neural Networks (DNNs) to construct evolutionary blocks that approximate solution operators. NEKM incorporates mathematical prior knowledge into each block, utilizing convolution operations and nonlinear activations tailored to the specific PDEs under consideration. This approach offers several noteworthy contributions:\n\n1. **Efficiency and Generalizability**: The use of boundary integral techniques is a standout feature of NEKM, allowing for a reduced requirement of network parameters and sampling points. This not only improves training efficiency but also relaxes the regularity assumptions on solutions. The capacity to apply NEKM to problems in complex domains and on manifolds showcases its versatility and potential real-world applicability.\n\n2. **Compatibility with Time Discretization Schemes**: NEKM can be effectively combined with time discretization schemes that possess structure-preserving properties, such as energy stability. This demonstrates the adaptability of the method to diverse mathematical contexts.\n\n3. **Treatment of Singular Boundary Integrals**: The paper introduces a method for computing singular boundary integrals that arise from fundamental solutions. This addition contributes to the overall training efficiency and robustness of NEKM.\n\nThe empirical validation of NEKM is conducted through testing on heat equations and Allen-Cahn equations in complex domains and on manifolds. The results demonstrate the method's high accuracy and its capacity to generalize across various domains.\n\nIn summary, the paper presents an innovative and promising approach, NEKM, which addresses the solution of time-dependent semi-linear PDEs. The combination of mathematical prior knowledge, boundary integral techniques, and DNNs provides a compelling method that improves training efficiency, generalizability, and adaptability to different mathematical scenarios. The successful testing on various equations and domains underscores the method's potential significance in the field of mathematical modeling and scientific computing.",
        "strengths": "The strengths of the paper \"Neural Evolutionary Kernel Method (NEKM) for Solving Time-Dependent Semi-Linear PDEs\" include:\n\n1. **Innovative Approach**: The paper introduces a novel approach, NEKM, which combines operator splitting, boundary integral techniques, and Deep Neural Networks (DNNs) to address the solution of time-dependent semi-linear Partial Differential Equations (PDEs). This innovation offers a fresh perspective on tackling complex mathematical problems.\n\n2. **Efficiency Improvement**: NEKM leverages boundary integral techniques to reduce the need for extensive network parameters and sampling points. This not only enhances the efficiency of training but also relaxes regularity assumptions on solutions. This efficiency improvement is a significant advantage in solving real-world problems.\n\n3. **Generalizability**: The paper demonstrates that NEKM can be applied to problems in complex domains and on manifolds, showcasing its generalizability across different mathematical contexts. This broad applicability enhances its potential usefulness in a wide range of scientific and engineering applications.\n\n4. **Compatibility with Time Discretization Schemes**: NEKM's compatibility with time discretization schemes that possess structure-preserving properties, such as energy stability, is a valuable feature. This adaptability makes it easier to integrate NEKM into existing mathematical frameworks.\n\n5. **Treatment of Singular Boundary Integrals**: The paper provides a method for computing singular boundary integrals that arise from fundamental solutions. This contribution adds to the method's efficiency and robustness, making it more practical for real-world applications.\n\n6. **Empirical Validation**: The authors validate the NEKM approach through rigorous testing on heat equations and Allen-Cahn equations in complex domains and on manifolds. The high accuracy demonstrated in these tests underscores the practical utility of NEKM.\n\n7. **Mathematical Rigor**: NEKM incorporates mathematical prior knowledge into its framework through convolution operations and nonlinear activations. This mathematical rigor ensures that the method is well-founded and theoretically sound.\n\n8. **Interdisciplinary Relevance**: The paper's focus on solving complex mathematical problems with machine learning techniques has broad interdisciplinary relevance, as it can find applications in various fields, including physics, engineering, and computational science.\n\nOverall, the strengths of the paper lie in its innovative approach, efficiency improvements, generalizability, compatibility with existing mathematical schemes, and the rigorous empirical validation of the proposed method. These qualities make NEKM a promising addition to the field of mathematical modeling and scientific computing.",
        "weaknesses": "While the paper on \"Neural Evolutionary Kernel Method (NEKM) for Solving Time-Dependent Semi-Linear PDEs\" offers several strengths, there are also some potential weaknesses to consider:\n\n1. **Complexity**: The proposed NEKM method, while innovative, is complex in its approach, involving the integration of operator splitting, boundary integral techniques, and Deep Neural Networks. This complexity might make it challenging for practitioners who are not well-versed in all of these areas to implement and understand.\n\n2. **Computational Resources**: The paper does not extensively discuss the computational resources required for training and applying the NEKM method. Deep learning methods often demand significant computational power, which could be a limitation for some users, particularly those without access to high-performance computing resources.\n\n3. **Limited Real-World Use Cases**: While the paper demonstrates NEKM's effectiveness in solving specific mathematical problems, it remains largely theoretical. More real-world use cases and practical applications in various domains would strengthen the paper's relevance and utility.\n\n4. **Interpretability**: The paper discusses the use of neural networks, which are often seen as \"black-box\" models. While the paper addresses some interpretability challenges, it might not provide a complete solution to the interpretability issues associated with deep learning approaches.\n\n5. **Algorithm Complexity**: The proposed method involves a combination of different techniques, such as boundary integral representation and neural networks. This may make the implementation and understanding of NEKM challenging for some users, potentially limiting its widespread adoption.\n\n6. **Empirical Validation Scope**: While the paper includes empirical validation on heat and Allen-Cahn equations, the scope of the empirical validation might be limited. A more extensive range of test cases across different scientific and engineering domains would strengthen the method's generalizability.\n\n7. **Scalability**: The paper does not explicitly address the scalability of the NEKM method. As the complexity of problems increases, it remains to be seen whether NEKM can efficiently scale to handle more complex and larger-scale scenarios.\n\n8. **Comparison to Existing Methods**: The paper lacks a comprehensive comparison of the NEKM method with existing approaches for solving similar problems. Such comparisons would help to better assess the relative strengths and weaknesses of NEKM.\n\nIn conclusion, while the NEKM method offers several promising advantages, such as efficiency improvements and generalizability, it also has some potential limitations, including complexity, computational resource requirements, and the need for more extensive real-world applications and validation. These weaknesses should be considered when evaluating the method's suitability for specific applications.",
        "questions": "1. Can you provide more insight into the computational resources required for training and applying the NEKM method? What kind of hardware and software infrastructure is necessary for its practical implementation?\n\n2. The NEKM method is quite complex, involving a combination of operator splitting, boundary integral techniques, and neural networks. How user-friendly and accessible is the implementation for researchers and practitioners who may not be experts in all these areas?\n\n3. The paper mentions empirical validation on heat and Allen-Cahn equations. Are there plans to expand the empirical validation to a broader range of mathematical problems or real-world applications to further assess the generalizability of NEKM?\n\n4. How does NEKM address the interpretability challenge often associated with deep learning methods? Can you provide more details on how NEKM helps users understand and trust its results, especially in cases where interpretability is critical?\n\n5. The paper mentions combining NEKM with time discretization schemes that possess structure-preserving properties. Could you elaborate on specific scenarios or use cases where this combination has proven to be advantageous?\n\n6. NEKM proposes the treatment of singular boundary integrals arising from fundamental solutions. Can you discuss the impact of this addition on the overall efficiency and robustness of the method in practical applications?\n\n7. In the real world, problems often scale in complexity. How does NEKM address the scalability challenge, especially when dealing with larger and more complex scenarios beyond the examples provided in the paper?\n\n8. The paper does not include a comprehensive comparison of NEKM with existing methods for solving similar problems. Could you share insights into how NEKM performs in comparison to other approaches, and in what scenarios it may have a comparative advantage?\n\n9. Are there any specific plans or ongoing research aimed at addressing some of the potential weaknesses or limitations identified in the paper, such as making the method more accessible or broadening the scope of empirical validation?\n\n10. How do you envision the practical adoption of NEKM in various scientific and engineering domains? Are there specific industries or areas where NEKM is expected to have a significant impact, and if so, what are the next steps for its real-world application?\n\nThese questions aim to seek further clarification and insights from the authors regarding the NEKM method and its potential applications and improvements.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper aims to tackle solving partial differential equations (PDEs) traditionally solved by numerical methods with deep neural networks (DNNs). The authors address the challenges of solving PDEs with DNNs that a majority of these methods do not use any mathematical or physical parameters and require a large amount of parameters to tune. The authors propose the Neural Evolutionary Kernel Method (NEKM) to solve a type of evolutionary PDEs with DNN based kernels. The core idea is to incorporate pre-trained Green's functions. NEKM is an alternating two-step procedure that first analytically or numerically solves a nonlinear ODE to obtain a flow map and then numerically integrate the related linear PDE with a convolutional kernel.",
        "strengths": "- Nice abstract that motivates the need for PDEs in science and engineering problems and use of numerical methods to solve them.\n- The paper and abstract are well-written.\n- Incorporating ideas from numerical methods, e.g., Green's function, boundary conditions and energy stability is very nice. In particular, I like to the discussion in subsection 2.2 on energy conservation and would like more details in the Appendix.\n- The generalization and use of the pre-trained Green's function is nice.\n- The computational savings of defining the Green's function on the boundary rather than the interior domain is nice. For other boundary integral representations for conservation laws, see Hansen, et. al, \"Learning physical models that can respect conservation laws\", ICML 2023 (https://arxiv.org/abs/2302.11002).\n- Nice high dimensional simulations in Figures 6-7.\n- Generalizability to different manifolds and boundary conditions.",
        "weaknesses": "- The authors should define earlier what they mean by evolutionary PDEs.\n- Connection to other kernel operator methods such as the Fourier Neural Operator (FNO) should be considered. It is only briefly discussed in one sentence of related work with a majority on the PINNs literature. In particular, in the related works, the authors discuss in detail how boundary conditions are incorporated into Physics-Informed Neural Networks (PINNs). The related in Neural Operator community should be discussed, such as how to incorporated boundary conditions into Neural Operators in Saad et. al, \"Guiding continuous operator learning through Physics-based boundary constraints\", ICLR 2023.\n- The method only works on semi-linear PDEs. This is actually a very strong assumption and limitation. The authors should discuss the extension to nonlinear PDEs.\n- Evaluation: the method is only tested on the simple linear heat/diffusion equation and Allen-Cahn equations. The heat equation is smooth and parabolic and very easy for numerical methods to solve. It would be nice to test hyperbolic problems with shocks, e.g., in the GPME benchmarking framework in Hansen, et. al, \"Learning physical models that can respect conservation laws\", ICML 2023 (https://arxiv.org/abs/2302.11002).\n- The method seems to have strong limitations if the first step requires an analytical or numerical solution to the ODE. \n- In particular, the authors should clarify this in the last paragraph of the introduction. I don't understand where the nonlinear ODE is coming from in step 1 and then how there is \"numerically integration\" for the related linear PDE. Typically, in numerical methods a (non)linear PDE is first discretized in space and then the resulting semi-discrete form of the ODE is discretized in time. The authors should clarify what they mean here.\n- I think some of the equation details of BINet in the related work should be moved to an appendix or background section.\n- Care should be taken with the discretization because this adds a first order error into the scheme. For example, the first equation should not be discretized with the 1st order accurate Forward Euler without even citing the method. This is an explicit method and there are necessary bounds on $\\Delta t$/$\\tau$ to ensure numerical stability.  See Krishnapriyan et. al, \"Learning continuous models for continuous physics\", 2023 (https://arxiv.org/pdf/2202.08494.pdf) on how the time discretization matters in NeuralODE and the 4th order RK4 is advantageous but even that scheme without being careful about the numerics can lead to convergence issues.\n- Ideally the method and presentation wouldn't need to be separated into separate cases for linear equations or not.\n- It seems like the method depends too strongly on the BINet method and the authors should better differentiate the novelty between the two.\n- The exposition of the method in Section 2 isn't too clear and some of the details can be moved to an appendix.\n- The unique features of the NEKM subsection seems like it could be incorporated with the contributions subsection in the intro.\n- Label x and y axis in Figure 3.\n- Another major weakness in the evaluation is just comparing to the exact solution and no other baseline methods, especially to related neural operator based methods.\n\nMinor\n- First paragraph of related works can be longer and combined with parts of the longer second paragraph.\n- heat equation shouldn't be plural in the last bullet point of the contributions.\n- comma after \"In this section\" at the beginning of Section 2 Method\n- I would name Section 2 with the specific method name Neural Evolutionary Kernel Method (NEKM) rather than the generic Method.\n- Could use standard notation from numerical methods $\\Delta t$ instead $\\tau$\n- Comma missing after Equation 7.\n- Larger title lave on Figure 6.",
        "questions": "- Does the method only work on semi-linear PDEs? If so, this is a bit limiting and the authors should discuss the extension to nonlinear PDEs.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper presents the Neural Evolutionary Kernel Method (NEKM) for solving semi-linear time-dependent PDEs. NEKM distinguishes itself by utilizing operator splitting and boundary integration, enabling efficient network architectures. The method is demonstrated to be effective and stable in solving classic PDEs, such as the heat equation and the Allen-Cahn equation.",
        "strengths": "NEKM can be combined with time discretization schemes that preserve energy stability, which is crucial for modeling physical systems.\nThe method incorporates an evolutionary kernel, which inherently preserves the structure of the problem.\n\nThe method incorporates an evolutionary kernel, which inherently preserves the structure of the problem.",
        "weaknesses": "While NEKM is claimed to work in complex domains, the paper primarily provides examples in small and relatively simple domains. It would be beneficial to demonstrate its performance in more complex and realistic domains, similar to the level in the referenced paper (https://arxiv.org/pdf/2309.00583), including real-world scientific and engineering geometries.\n\nThe paper lacks references to related work that adopts neural networks only at the spatial level while using time discretizations to evolve spatial fields over time. Including references to papers like \"Evolutional deep neural network (Physical Review E 2021),\" \"Implicit Neural Spatial Representations for Time-dependent PDEs (ICML 2023),\" and \"Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations\" could help provide context and comparisons.\n\nThe paper does not provide information about the computational cost and scalability of NEKM compared to classical numerical methods, especially for larger 3D problems. It would be valuable to include performance comparisons in terms of computational efficiency.",
        "questions": "My biggest confusion and concern is the relationship between this paper (Lin et al., 2023a) as well as (Lin et al., 2023b). Those paper also use a convolution representation of the solutions using Green's functions. What exactly is the author's contribution except working with time-dependent problems?\n\nThe paper focuses on semi-linear PDEs, but it would be interesting to know if NEKM can be extended to handle nonlinear PDEs. Clarification on the limitations and potential extensions of the method for nonlinear problems would be beneficial.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposes a neural network-based algorithm, namely the Neural Evolutionary Kernal Method (NEKM), for solving evolutionary PDEs. The method involves the operator splitting technique and the idea of boundary integral network. Specifically, the method pre-trains a neural network representation of the Green function and then solves the evolutionary PDE by applying the Green function block and kernel function block alternatingly with an ODE solver. Experiments on the heat equation and Allen-Cahn equations are conducted to demonstrate the performance.",
        "strengths": "- The paper is well-written and easy-to-follow.\n- The proposed method is interesting and mathematically grounded.\n- Experimental results seem strong.",
        "weaknesses": "- It seems the method heavily relies on the closed form formula of the fundamental solution $G_0$. The numerical error of the integration involving $G_0$ seems troublesome.\n- The experimental results of Allen-Cahn equation is not compared with the exact one or any other method.\n- Some minor issues: Figure 12 is too small.",
        "questions": "- Now that the Green function $G$ is computed by pre-training a neural network, the error of this step may propagate to solving the time evolutionary PDE. Was this problem an issue in the experiments? How accurate should the numerically approximated Green function be so as not to affect the performance?\n- As mentioned in the paper, the possible singularity of $G_0$ may demand special handling. But the form of $G$ is generally unknown. How can the singularity appearing in $G$ be dealt with?\n- Energy stsability is claimed as one of the contributions. Is this only empirically observed or grounded with some particular design?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "ApjY32f3Xr",
    "title": "PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs",
    "reviews": [
      {
        "summary": "This paper provides both a collection of benchmark datasets as well as a standardized suite of PINN-type neural network PDE solution approximators arranged as a python package.\n\nIt further shows benchmark numbers of the different PINN methods on the benchmark datasets.",
        "strengths": "Providing any meaningful benchmark to the community is a valuable service.\nIn addition to creating the benchmark data sets, the authors have made a big effort in collecting and unifying PINN methods into a unified framework.\nThe paper appendix contains detailed specifications about the particular setup for the data benchmark.",
        "weaknesses": "While providing a benchmark data set to the community is a valuable service, several aspects could be improved.\n\nMinor: \n-It would be great to have a table or list (in the appendix) detailing a comparison of the provided data sets to those in PDEarena (and PDEbench).\n\nMajor: \n- The relative error values in the results tables are for the most part shockingly bad and simply not useful for many numerical analysis contexts. Given that PINNs seem to be mostly providing different function spaces for PDE solutions, one original base PINN should be included in the benchmark, which is to give each hat function on a finite element mesh one parameter, and hence include finite element methods. Because some of the data sets were created using FEM, the original mesh would yield 0 error, but different meshes may not, and in particular coarser meshes would accumulate error. Analyzing a curve of remeshing from same resolution to coarse would provide a baseline for the performances of the other PINNs.\n\n- In the above sense, it also becomes important to quantify flop counts. It appears that most PINNs need to be fitted for each PDE solution, incurring the typically high flop count of solving an optimization problem (compared to one forward pass), and only some of them can learn solutions conditional on hyperparameters given as input and require only forward passes to solve e.g. from different inital conditions.\nFor all cases, there should be 3 different flop counts provided: 1) The number of flops required to create the training set 2) The number of flops required for any general training of the method  3) the number of flops required to evaluate/fit the method on a particular example. Many PINNs, and the FEM baseline would only have nonzero counts in point 3, and it would be good to compare them.\nHaving flop counts or even wall time counts would allow answering questions like \"at equal error rate, does fitting a PINN or fitting FEM cost more computational power?\" and \"At equal computing power, can FEM beat the error rates of the listed PINNs?\"\n\n- continuing the discussion about flop counts, methods learning from multiple data sets/examples should be included in order to compare flop counts and provide additional reference error values. In particular for the time propagating PDEs, solutions using U-nets or FNOs from e.g. PDE bench should be included as reference values, in terms of performance, flops required for training, flops required to generate the required training data, and flops required to run a forward pass to obtain a solution. Then one can assess how many PINNs or FEM solutions one can compute for the same budget as a certain number of forward passes of the propagator network. The should be a break-even point at some number of forward passes justifying the training effort.\n\nWithout these points, the benchmark is unfortunately sitting just beyond actual widespread utility. I would highly encourage the authors to add these baselines to make the benchmark useful. Despite my positive bias towards benchmarking efforts I cannot recommend acceptance of this paper in its current state.",
        "questions": "Would it be possible to address the major issues listed above among weaknesses?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper provides a comprehensive comparison of PINN training methods, problems, and data. The paper visits common problems with training PINNs, namely the complex geometry, the multi-scale phenomena, nonlinearity of some PDE ofrs, and the high dimensional PDE problems. They also provide various training mechanisms such as domain decomposition and loss reweighting methods.",
        "strengths": "1. The paper is well-written; it seems obvious this work has gone through a few rounds of polishing and review.\n2. The literature review is detailed and comprehensive.\n3. The challenging aspects of training PINNs are decomposed and categorized well.\n4. The appendix section of the paper is thorough and contains quality information.\n5. The suite of experiments is admittedly comprehensive; there are more than 20 PDE forms, 10 methods considered and compartmentalized well in this paper.\n6. The scale of the experiments and the analyses of the hyper-parameters is certainly admirable.",
        "weaknesses": "1. I'm saying out of respect to the author's work, but this paper may be more suited for a journal format. In particular, the page limit constraint is hitting the work hard in my opinion. \n\n  * By the time the authors present the data and experiments, there is less than half a page left to interpret the results and provide discussions and conclusions.\n  * Many key discussions, at different points in the main text, were deferred to the appendix. While they do exist in the appendix and carry out important information, they carry more scientific content than the existing paper's text.\n\n    To be clear, the paper's topic is certainly relevant to ICLR and could benefit the ICLR community. However, the conference format may not be the most suitable to present the work as best as it could have been.\n\n2. The work utilizes 10 different methods for training PINNs, but a brief description of these methods in a single mathematical framework is missing. Adding such a description and correlating the numerical findings to the theoretical properties of each method is probably the most important, yet under-performed, part of the work in my opinion.\n\n    To be clear, I understand the paper's space constraints, but this is very important in my opinion. The least the authors could do is to add such a section, however briefly, to the appendix.",
        "questions": "See the weaknesses section.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper provides a benchmarking tool called PINNacle which was lacking in the domain of PINNs. The tool provides a diverse set of 20 different PDEs spanning over various application domains. The tool also provides implementations of 10 state-of-the-art techniques in PINNs and shows extensive experiments to show the strengths and weaknesses of each method.",
        "strengths": "1. The paper is overall well written and easy to follow.\n2. The paper provides an extensive comparison of the different SOTA methods for different PDEs.",
        "weaknesses": "1. The paper lacks technical novelty to be considered for the main track. In my opinion, the paper is more suitable for an application/dataset track, for e.g., NeurIPS Dataset/Benchmark Track.\n2. The insights provided in the paper are not novel and are also well-known in the PINN literature which the paper cites as well.",
        "questions": "1. Table 3 shows that all of the selected SOTA methods fail on the KS Equation. However, some PINN methods can solve KS Equations such as Causal PINNs [1]. \n2. When comparing the effect of the parametric PDEs on different PINN variants (shown in Table 4), using the Average L2RE is not a good choice. It would be more informative to show the mean and the standard deviations for the different parameter choices. The average L2RE can be skewed if one (or few) of the parameter settings fails (i.e., have L2RE of 100%) while others have very low errors (such as ~1e-4).\n\n\n[1] Wang, S., Sankaran, S., & Perdikaris, P. (2022). Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404.",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "The article introduces \"PINNacle\", a robust benchmark suite tailored for Physics-Informed Neural Networks (PINNs). This suite boasts a rich assortment of over 20 intricate PDE challenges, complemented by a user-centric toolbox that houses over 10 of the latest PINN techniques. These techniques are segmented by the authors into categories: loss reweighting, advanced optimizers, unique loss functions, and groundbreaking architectures. An exhaustive analysis is then executed with this benchmark dataset to scrutinize these variations.\n\nMany of the challenges pinpointed in the dataset resonate with a multitude of real-world scenarios. Thus, the efficacy of a method in tackling these challenges becomes a credible measure of its real-world utility. To generate the data, the authors employ the FEM solver from COMSOL 6.0 for intricately geometric problems and the spectral method from Chebfun for the more chaotic issues. This dataset encompasses challenges like the heat equation, Poisson equation, Burgers' equation, Navier-Stokes equation, among others.\n\nThe paper outlines a uniform criteria to gauge the performance of varied PINN techniques across all challenges, promoting a methodical comparison of different tactics. Performance assessment is conducted using various metrics, such as accuracy, convergence rate, and computational prowess. Moreover, the authors shed light on the advantages and limitations of these methods, providing direction for subsequent studies, especially in fields like domain decomposition and loss reweighting.\n\nIn essence, the article's merits lie in its crafting of a dataset that mirrors significant challenges confronted by PINNs, establishing a uniform assessment criteria for different PINN approaches, and giving valuable insights on the strengths and pitfalls of these methods. This work undeniably propels the growth of PINNs, igniting further creativity and advancements in this burgeoning domain.",
        "strengths": "This paper stands out with several merits, accentuating its importance in the realm of Physics-Informed Neural Networks (PINNs).\n\nTo begin with, it offers an all-encompassing benchmark suite for PINNs, showcasing a varied dataset containing over 20 intricate PDE challenges, supplemented by an accessible toolbox with more than 10 leading PINN techniques. This suite facilitates an organized comparison of multiple approaches and delivers a uniform metric to evaluate the efficacy of various PINN methodologies across tasks.\n\nNext, the authors embark on an in-depth evaluation using the benchmark dataset to appraise these variations. They measure the performance through multiple indicators such as accuracy, convergence speed, and computational prowess. Their findings elucidate the advantages and pitfalls of these methods, charting a course for prospective studies, especially in areas like domain decomposition and loss reweighting.\n\nMoreover, the challenges pinpointed in the dataset find parallels in many real-world scenarios. Hence, how a method navigates these challenges becomes a tangible testament to its applicability in practical contexts. This tangible applicability amplifies the relevance of both the benchmark suite and the research's findings to field professionals and researchers.\n\nIn conclusion, this work marks a significant leap in the trajectory of PINNs, fueling further innovation and exploration in this riveting domain. The paper's offerings, spanning from the benchmark suite to the critical insights, are poised to galvanize more in-depth investigations and advancements in PINNs, ushering in enhanced solutions for real-world quandaries.",
        "weaknesses": "The paper has some areas it could improve on.\n\nFirst, the authors only discuss PINN methods. They didn't look at other common methods. It would be good to see how PINN methods compare to these.\n\nSecond, they didn't give much detail on what computer stuff is needed for PINN methods. They did say if the methods work fast or slow. But, it would be helpful to know what computer tools or power is needed. People who want to use these methods would find that information useful.\n\nLast, the authors worked with a set of 20 PDE problems. But they might have missed some other important problems. In future studies, it would be good to add more problems to their list. This way, we can learn even more.",
        "questions": "How did you ensure that the PINN methods you evaluated were able to handle the diverse range of PDEs in your dataset, and what challenges did you encounter in this process?\n\nCan you describe the process of training the neural networks for each PDE, and how you optimized the hyperparameters for each method?\n\nHow did you handle issues such as boundary conditions and initial conditions in your experiments, and what strategies did you use to ensure that these conditions were satisfied?\n\nCan you discuss the limitations of your benchmarking tool, and how future research could address these limitations to further advance the field of PINNs?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "eUgS9Ig8JG",
    "title": "SaNN: Simple Yet Powerful Simplicial-aware Neural Networks",
    "reviews": [
      {
        "summary": "The paper describes an efficient, and effective approach for learning representations for simplices in a simplicial complex. The central idea is that of using injective functions for aggregating simplicial features, as it ensures that the embeddings are unique. The simplicial features are aggregated over upper, lower, boundary and co-boundary adjacencies. The paper provides precise definitions and theorems and statements on the properties of the networks. The proofs are summarized in the main body and provided in full detail in the appendices. The method is further experimentally validated and shows that the proposed model (SaNN) is both efficients (significantly faster than any of the other baselines) and effective (performance within the uncertainty intervals on accurcies, or above the baselines).",
        "strengths": "1. I am impressed by the clarity of presentation in the paper. I find talking and reading about simplicial complex often a messy business given all the types of simplices and adjacencies, and the abstract notion in the first place. It is clear that the authors though well about how to present the math. This includes proper use of figures.\n2. The goal of the paper itself -efficiency whilst not compromising on expressivity- is relevant and important, and it is great to see the authors succeeding in reaching this goal.\n3. I appreciate the summary of the proofs after the formal statements.\n4. Next to a sound theoretical exposition, the experiments are thorough as well and include many ablation studies that are used to distill insightful take home messages.",
        "weaknesses": "I only have 1 important concern:\n\n1. Although the main principles are clear, I am still confused about the actual architecture/predictive models. In the end we have equation 8, but it describes a representation for each of the $N$ sets of $k$-simplices, each consisting of the $N_k$ simplices. It is unclear how to distill a global prediction out of all these representations, as would be needed for e.g. the classification tasks. Details on how the architectural design for each of the benchmarks is missing.",
        "questions": "Could you respond to the above concern, and additionally address the following questions/comments?\n\n2. On several occasions the notion of \"non-deep baselines\" is used. What is meant by this. Could you clarify what non-deep means here, which methods are these?\n\n3. In section 2 when presenting the symbols it is mentioned that $k=1,2,\\dots,N+1$. Does $k$ always run up all the way to $N+1$?\n\n4. In section 4. The sentence that starts with \"The theorem implies that any arbitrary ...\" is extremely long and hard to comprehend. I suggest to split it 2 or 3 sentence to improve readability.\n\n5. Just above property 1 it is mentioned \"other commonly used sum, mean, or max read-out functions are not injective\" I am not fully sure I understand it correctly. The paragraph above explains that sum aggregation is the best injective aggregator, in contrast to mean aggregation. I think the statement that I just quoted is about aggregating over the different $\\mathbf{Y}$'s? Perhaps this can be clarified.\n\n6. In the tables: since colors red and blue are used you might as well color the text in the caption as well. I.e. \"The {\\color{red}first} and {\\color{blue}second} best performances ...\"\n\n7. The insights section says \"The deep models are observed to perform exceptionally better than logistic regression\", where do I see this? Logistic regression taking what as input? Could this be clarified.\n\nThank you for considering my comments and questions.",
        "rating": "8: accept, good paper",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The authors propose a class of simple simplicial neural network models, referred to as simplicial-aware neural\nnetworks (SaNNs), which leverage precomputation of simplicial features. The authors theoretically demonstrate that under certain conditions, SaNNs are better discriminators of non-isomorphic graphs than the WL and SWL test. Empirically, SaNNs are shown to perform competitively against other SNNs and GNNs on tasks such as trajectory prediction, simplicial closure prediction, and several graph classification tasks over various datasets.",
        "strengths": "1. The theoretical results are intriguing. Indeed, a competitor to the WL and SWL tests would be a valuable contribution to the graph ML community. \n\n2. A wide variety of benchmarks over several tasks and datasets are conducted to demonstrate the efficacy and efficiency of SaNNs. \n\n3. SaNNs inherit several valuable invariance properties of other SNNs including permutation invariance, orientation invariance, and simplicial-awareness. \n\n4. Compared to MPSNs, consideration of higher-order simplices does not blow up computation complexity.",
        "weaknesses": "1. It is unclear for a research with limited expertise in this rather niche area to conclude the strength of the conditions prescribed in Theorems 4.1 and 4.2. (See questions.) \n\n2. There do not appear to be any results describing the pre-computation time which should be included in any run-time comparisons which I imagine should scale near-exponentially with graph size and order of simplices considered. \n\n3. SaNNs are often not outright the winner in terms of prediction accuracies for the tasks displayed in Tables 1 and 3. For example, in Table 1, the SaNN is outcompeted by Projection and Scone on 3/4 of the datasets and the run-time savings of SaNN are not significant enough to justify usage of the SaNN. In Table 3, SaNN is not the leader in 4/5 of the datasets and it is not even the fastest. On the other hand, the time savings against MPSN are quite significant, but since many practitioners of graph learning expect training to take significant amounts of time, accuracy is the topmost priority, so there wouldn't be a strong enough justification to go with a SaNN.",
        "questions": "1. Is assuming the learnable transformation functions $g_k^{(t)}\\cdot)$ are injective too strong? Although the MLPs will be injective, appealing to the Universal Approximation Theorem to declare that $g_k$ can be injectively-approximated is probably not practical. \n\n2. I may have missed this but are pre-computation times explicitly indicated in the results?",
        "rating": "8: accept, good paper",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The authors present a Simplicial Graph Neural Network, which considers higher-order structures in the input graphs. In comparison to previous work, the features from k-simplices are precomputed without trainable parameters and only then fed into a GNN. This leads to lower runtime during training since features can be reused in each epoch, which is validated by the authors theoretically and empirically.\n\nThe authors prove that their method is more powerful than the WL test and as powerful as the Simplicial WL (SWL) test, when it comes to distinguishing non-isomorphic subgraphs. Further, they prove permutation equivariance, orientation equivariance, and simplicial-awareness.\n\nThe method is evaluated on trajectory prediction, simplicial closure prediction, and graph classification, where it is on par/slightly outperforms previous works with better training runtimes.",
        "strengths": "- The goal of the work, achieving better scalability of expressive networks by using non-parametric simplicial encoders makes sense.\n- The authors thoroughly analyze their method theoretically and provide proofs for all relevant properties.\n- The presented method seems to find a good trade-off between expressiveness, runtime and empirical quality.\n- There is theoretical value in the non-parametric encoder for simplices that keeps equivariant properties and simplicial-awareness\n- The paper is mostly well written",
        "weaknesses": "- Runtime and asymptotic comparisons in this work are done by excluding the precomputation of features. I think this is misleading, since in practice, the precomputation is certainly part of the computation, especially during inference. Thus, the presented gains seem to be only valid during training, when the features need to be computed only once for many iterations of training. \n- At the same time, the method only performs on par with previous work, with small gains on some datasets.\n- The method requires many hyper parameter choices like hops, T, k, which seem to have different optimal settings on different datasets. The result quality differs substantially depending on the configuration.\n- I am skeptical regarding the practical relevance of the presented method due to above reasons.\n\n- The method lacks conceptual novelty. The main idea of precomputing features by non-learnable functions has been seen in other areas, e.g. non-parametric GNNs. The general structure of the work follows a long line of work about GNN expressiveness (higher order and WL-level) without presenting many novel insights.",
        "questions": "- I wonder how the method compares to previous methods in inference runtime, when feature precomputation needs to be included.\n\n-----------\nI thank the authors for proving the precomputation times explicitly and for replying to other concerns I have - this is certainly helpful to evaluate the differences to previous work.\n\nIn general, I am still on the fence and still doubt the significance of the contribution. However, I acknowledge that other reviewers find value in it and, thus, slightly raise my score. I am not opposing this paper to be accepted, as I think it is a thorough and well executed work.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper considers the design of neural networks for simplicial complexes, which are more general combinatorial structures than graphs, but less general than hypergraphs. The authors propose to use multihop aggregation schemes to build an architecture that is more expressive than the simplicial Weisfeiler-Lehman isomorphism test, while satisfying useful invariance, equivariance, and expressivity properties. They also demonstrate the efficientcy of their proposed method, and its performance for a few different tasks in simplicial data processing.",
        "strengths": "1. For the most part, this paper is well-written, and is easy to digest for someone who is familiar with graph neural networks. I don't think the intended audience of this paper includes someone not familiar with GNNs, but this is fine in my opinion.\n\n2. The proposed method is demonstrated to be quite efficient in comparison to existing ones, with similar performance as well.",
        "weaknesses": "1. Certain definitions regarding the types of operators and features are not laid out clearly enough, which leads to ambiguity in the paper on a technical level. As noted in the list of questions and suggestions, the claimed properties of the proposed models are not clearly true, possibly due to this misunderstanding.",
        "questions": "My most important concern is summarized in point 1 -- in particular, the ambiguities around orientation equivariance and the use of oriented operators built from the incidence matrices are what cause me to suggest this paper be rejected. If the authors are to focus on either of the two points in order to change my mind on this paper, it should be the first one.\n\n1. There are some details missing regarding the type of data being handled. In particular, the incidence matrices are not defined in a way sufficient for the discussion following in the paper. Normally, the incidence matrices have values of +-1 depending on a chosen reference orientation (usually given by some ordering of the nodes). Coupled to this, the signs of the features on the simplices are determined relative to the same reference orientation -- this gives meaning to the notion of orientation equivariance. Without discussing these things, orientation equivariance is not a meaningful concept within the context of the paper. \n\na. This calls into question the validity of the example in Section 4.1. You say that all simplices are given a feature value given by some scalar $a$ -- yet, the matrices acting on these feature vectors/matrices have an orientation associated to them. It seems as if you are using an *oriented operator* to act on *unoriented features*. Property 1 in this example is thus difficult to claim, as the property of orientation equivariance is one describing the action of *oriented operators* acting on *oriented features*, and how the choice of orientation to begin with is irrelevant to the computation. \n\nb. Furthermore, this problem yields a comparison for isomorphism testing incorrect, as the erroneous imposition of differently-oriented features relative to the chosen orientations could be used by SaNN to yield a \"false negative,\" i.e., saying that two isomorphic complexes are different. \n\nc. A more minor comment in this direction comes from the **Insights** section of Section 5.1. It is not correct to say that \"the superior performance of SaNN also proves the orientation equivariance of SaNN experimentally.\" Orientation equivariance is a simple mathematical property, and does not guarantee good performance, nor are all performant architectures on a given dataset orientation equivariant. These properties are possibly linked, but the claim that one proves the other in some way is not justified. \n\nd. Moreover, based on my reading of the appendix, many of their experimental setups for tasks other than trajectory prediction use \"unoriented data\" by simply assigning scalar values to high-order simplices, which is again incompatible with the use of oriented operators. Perhaps something in the implementation of SaNN in these examples does not use oriented operators such as the incidence matrices, but this is not clear to me. \n\nPlease either justify, clarify, or revise the paper's discussion regarding orientation equivariance.\n\n2. Related to the above point, the claims in Section 4.2 seem reasonable at first glance, but are not explained well enough. Permutation equivariance is easily seen to hold, so is not much of a concern. Orientation equivariance is subject to the problems noted above, so more clarification on the type of simplicial features and relevant operators needs to be made. That is not to say that the result proved in the appendix is wrong, but it needs to be clarified in order to be understood in a way that acts on oriented features. Simplicial awareness is more subtle than the other two, based on the definition from (Roddenberry et. al., 2021). For instance, some of the existing convolutional-type SNNs in the literature fail to satisfy simplicial awareness if they are implemented without nonlinear activation functions, due to the fact that the square of the (co)boundary operator is the zero operator. Perhaps it is the case that the assumptions of Theorem 4.2 are sufficient to exclude such methods, but a clearer connection is needed. It would be very helpful for the authors to briefly survey some of the methods they compare to, and clarify whether Theorems 4.1 and 4.2 apply or don't apply to them.\n\n---\n\nThank you for addressing my questions -- I have raised my suggested score.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Accept"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "mnyXZBa5dP",
    "title": "Image Authenticity Detection using Eye Gazing Data:  A Performance Comparison Beyond Human Capabilities  via Attention Mechanism, ResNet, and Cascade  Strategies",
    "reviews": [],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "fMX07g3prp",
    "title": "FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search",
    "reviews": [
      {
        "summary": "This paper proposes a new GNN performance predictor for NAS that considers the forward and reverse computational graph of architectures. Furthermore, the authors also propose a loss function that minimizes the variance between the dual encodings of the forward and backward pass. Experiments in standard tabular and surrogate benchmarks show improvements NPNAS and NPENAS.",
        "strengths": "- The paper presents a simple and effective way to improve the predictive performance of GNNs for NAS. The empirical evaluation demonstrates that the performance increases with the number of datapoints, which is nice to see.\n\n- Easy to read and clearly written.\n\n- Compared to NPNAS and NPENAS, the proposed algorithm shows significant improvements.",
        "weaknesses": "- The proposed method to encode both the forward and backwards encoding is well-known in literature (see section 3.4 in [1] for instance) as well as in NAS [2]. The linear scalarization of the prediction loss with the loss term that minimizes the variance between the two encoders is trivial.\n\n- The authors evaluate their method on 3 tabular/surrogate benchmarks. I think this is not enough considering the diversity of available NAS benchmarks out there. There are more interesting NAS benchmarks (see NAS-Bench-Suite [3]) that also have evaluated NPENAS, and therefore makes the comparison to the proposed method possible.\n\n- No code available at submission time.\n\n\n**References**\n\n[1] https://arxiv.org/pdf/1904.11088.pdf\n\n[2] https://arxiv.org/pdf/2010.04683.pdf\n\n[3] https://arxiv.org/pdf/2201.13396.pdf",
        "questions": "- Can the authors evaluate their method on the same framework as used in [4]? It would be great to see how FR-NAS performs under the same settings as those methods are evaluated.\n\n- What is the performance of the predictor inside a NAS algorithm? Can you evaluate FR-NAS as done in NAS-Bench-Suite (see Table 2)?\n\n**References**\n\n[4] https://arxiv.org/pdf/2104.01177.pdf",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "This paper proposes FR-NAS, a neural architecture performance predictors that estimates performance using both the forward-pass and backwards-pass representation of a NAS architecture. FR-NAS uses an Instance Relation Graph (IRG) loss to train the dual encoder. The author's evaluate the method on three NAS-Benchmarks and compare to known predictors NPENAS and NPNAS, outperforming both.",
        "strengths": "There is some novelty to considering the backwards pass representation of a NAS architecture when making a prediction. \nThe evaluation shows that FR-NAS conclusively defeats NPNAS and NPENAS on NAS-Bench-{101, 201, 301} at every training dataset size.\nThere are additional ablation studies for some components.",
        "weaknesses": "The novelty of this work is somewhat limited as its really only using a dual encoder with adjacency matrix transpose, while components like the IGR loss are heavily borrowed from different work.\n\nThis work only considers experiments on cell-based NAS Benchmarks but not on real NAS problems, which are outperformed by macro-based NAS structures like Once-for-All/MobileNets/EfficientNets. Also, no search is applied and no found architectures are evaluated. \n\nThere are probably simpler ways to consider the backwards-pass representation of a NAS DAG which this paper does not consider. The trivial method would be to simply cast the DAG as a fully-directed graph (for every edge (i, j), add edge (j, i)) and still use a simpler encoder. Another way, also simpler than this would be to consider weighted edges, e.g., forward-pass edges have weight '1', backwards-pass have weight '-1', and you use torch.nn.GINEConv instead of torch.nn.GINConv. \n\nThe IGR loss in this paper is somewhat counter-intuitive. The intuition behind considering the transposed adjacency matrix is that you are providing the predictor with new information not found in the forward-pass adj. matrix. This information should allow the predictor to learn a better understanding of architecture performance, which would help performance. Under this assumption, you would expect the encodings of the forward encode and backwards encoder to probably be different as they should be learning on distinct information, and that the concatenation of that information (graph embeddings from each encoder) benefits predictor performance. Instead, the IGR loss is counter to this as it forces both the forward/backwards encoders to 'learn the same thing' using different views of the same data. In other words, in Figs 2-3, showing how the IRG matrix values goes down with the addition of the loss and more samples seems counter-intuitive.\n\nAnalysis in Figures 2 and 3 is missing NAS-Bench-201 using the IGR loss, NAS-Bench-301 400 samples with the loss, even though the manuscript is not even 9 pages.\n\nAuthor's mention Graph Attention Networks (GAT) a few times in the paper, but do not use them to perform any analysis on their encoders, e.g., highlighting the nodes/edges assigned high attention scores. This would be a good way to highlight how their method learns and the benefits of their design, and rebut the hypothesis that FR-NAS outperforms NPNAS and NPENAS simply because the predictor has more parameters.\n\nThere are a lot of missing entries in the related work section. Some of which should be added, and compared to, e.g.,\n- TNASP [1] and PINAT [2] deal with special encodings for the adjacency matrix, like this paper.\n- CDP [3] is a cross-domain predictor which cases 201 and 301 to be like 101, to deal with limited target data like this paper.\n- GENNAPE [4] also deal with limited target data like CDP, but they also utilize a robust form of Computational Graph that covers the entire architecture, not just the NAS cell design.\n- Multi-Predict [5] show how to leverage other information like Zero-Cost Proxies [6] and device latency/FLOPs to aid prediction - both of which this paper does not acknowledge, yet it is a critical concern of NAS.\n\nFor the above reasons I would recommend rejection of this manuscript. \n\nReferences:\n\n[1] Lu et al., \"TNASP: A Transformer-based NAS Predictor with a Self-Evolution Framework\", in NeurIPS 2021.\n\n[2] Lu et al., \"PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor\", in AAAI-23.\n\n[3] Liu et al., \"Bridge the Gap Between Architecture Spaces via a Cross-Domain Predictor\", in NeurIPS 2022.\n\n[4] Mills et al., \"GENNAPE: Towards Generalized Neural Architecture Performance Estimators\", in AAAI-23.\n\n[5] Akhauri and Abdelfattah, \"Multi-Predict: Few Shot Predictors For Efficient Neural Architecture Search\", in AutoML Conf 2023.\n\n[6] Abdelfattah et al., \"Zero-Cost Proxies for Lightweight NAS\", in ICLR 2021.",
        "questions": "Not a question but minor nitpick: Eq. 2 should be Enc(A_{T}, O; W_2)",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "The FR-NAS paper devised a new graph neural network (GNN) based surrogate model for neural architecture search. The adjacency matrix is passed to a GNN which encodes the forward propagation of the neural network. Its transpose is passed to another GNN which encodes the backward propagation. These encodings are passed to their respective predictors ($p_{f}$ and $p_{r}$) and the final predictor is an average of these two. $p_{f}$ and $p_{r}$ are trained using mean squared error loss between the predicted and the true accuracies of the networks. To ensure that the forward and backward embeddings are consistent with each other, they used an additional loss to enforce that the relative distance between two architectures in the forward embedding space and the backward embedding space is similar.\n\n They report the results on NasBench-101, NasBench-201 and Darts search space. In their ablation studies, they bolster the case for using both the forward and the backward pass encodings.",
        "strengths": "1. Using two encoders to capture the forward and backward propagation encodings and using the IRG loss to synchronize them is novel.\n2. Their algorithm outperforms the other 2 baselines on NASBench-101, NASBench-201 and the DARTS search space.",
        "weaknesses": "1. Please compare against [1], [2] which are also GCN based predictors. \n2. It is also important to demonstrate that the surrogate model is competitive to other baselines such as those included in Neural architecture optimization (NAO) [3], BANANAS [4] and other predictors in  [5]\n3. For all the baselines, please report the time taken to train the predictors and to compute the correlations on all the 3 benchmarks.\n\n[1] BRP-NAS: Prediction-based NAS using GCNs,  Dudziak et al.\n[2] Bridging the gap between sample-based and one-shot neural architecture search with bonas, Shi et al.\n[3] Neural Architecture Optimization, Luo et al.\n[4] BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search, White et al.\n[5] How Powerful are Performance Predictors in Neural Architecture Search? White et al.",
        "questions": "1. Can you please tabulate figure 5? Given that the NPENAS-FR and FR-NAS plots are very close to each other as the training data increases, it would be good to see the actual correlation values.\n2.Did you consider other alternatives to the feature loss?  Given that both $L_{pf}$ and $L_{pr}$ are predicting the accuracy of the same architecture, what would happen if you minimize the divergence between the outputs of $L_{pf}$ and $L_{pr}$ predictors?\n3. Given that the algorithm is trained to minimize the feature loss, it would have the least Diff(i,j) when compared to those that are trained without them. So is figure 3 a fair comparison?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposed a GNN-based performance predictor for NAS, the bidirectionality information is employed for performance improvement, and some experiments are conducted for verification.",
        "strengths": "Using the bidirectionality information to improve the performance of the predictor is quite interesting because almost all existing works did not recognize this point.",
        "weaknesses": "The peer competitors used for comparison in this paper are not SOTA. This paper should not only compare the methods based on GNN but also SOTA performance predictors based on other techniques.\n\nThe experiments should also go to ImageNet, instead of only the measures for performance predictors, the final goal of which is for NAS.",
        "questions": "See Above",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "qBL04XXex6",
    "title": "Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models",
    "reviews": [
      {
        "summary": "The paper proposes a new framework Boosting of Thoughts (BoT) with large language models (LLMs) for task-specific prompting. It provides how to construct prompts and use the trial-and-error reasoning approach to interact with the LLM to generate the final responses. The experiments show the effectiveness of the proposed method.",
        "strengths": "- Prompt engineering is a non-trivial task, and crafting effective prompts may require specialized training for human experts. The paper introduces an innovative framework for iterative prompting, leveraging LLM's feedback on its own reasoning, thereby reducing the need for human prompt engineering.\n\n- Addressing complex problems is crucial in LLM applications. This approach effectively demonstrates the power of prompt engineering and expands the capabilities of LLMs without the need for retraining or fine-tuning. Experiments conducted on multiple datasets show competitive performance compared to other prompting approaches.",
        "weaknesses": "- I agree that prompt engineering is crucial for LLM applications. However, it's worth noting that prompt engineering is often model-dependent, and the techniques may evolve as LLM capabilities improve. This may not offer long-term guidance for research unless it uncovers fundamental insights. This distinction is critical in differentiating academic research from practical production. Therefore, while the paper does offer valuable techniques for prompting the model and achieving good results on evaluation sets, it lacks in-depth discussion of the underlying reasons. This makes the paper better suited for application-oriented conferences rather than ICLR.\n\n- LLMs can be unstable and prone to hallucination, which could result in bad or incorrect feedback when using the Boosting of Thoughts (BoT) iterative prompting framework. Is there analysis on the impact of \"bad\" LLM feedback? Further, as the iterative produces are automatic, spurious feedback could get amplified over iterations. Some discuss may be necessary.\n\n-  Details are lacking on key components like aggregation strategies and generating edge weights for trees. More analysis or ablation studies are also helpful.",
        "questions": "- In Section 3.2, it is not quite clear how to calculate the weights for the weighted binary tree.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper presents an extension of the Chain of Thought (CoT) and Tree of Thoughts (ToT) method, named Boosting of Thoughts (BoT). BoT refines the problem-solving process in large language models (LLMs). BoT harnesses error analysis to improve the LLM's problem-solving accuracy iteratively. The \"Boosting of Thoughts\" (BoT) procedure is a two-step process that first generates a diversity of reasoning paths from a Large Language Model (LLM) in the form of a weighted binary tree, enhancing problem-solving by creating a hierarchy of potential solutions. Then, it employs a novel aggregation strategy that iteratively refines and combines these paths. Through best-first and greedy aggregations, BoT selects and optimizes the most promising chain of thought, using iterative feedback to progressively improve the LLM's performance on complex problem-solving tasks. The paper reports improved performance on complex mathematical problems when tested with GPT-4 and LLAMA2, compared to CoT and ToT.",
        "strengths": "1. This is an innovative extension of the Chain-of-Thought (CoT) and Tree-of-Thought (ToT) methods. Compared to CoT and ToT, the author adopts the idea on leveraging error analysis to refine the LLM. This can be a limitation of CoT and ToT, as they do not conduct error analysis and more importantly, learn from errors. The motivation is intuitive and clear.\n\n2. Unlike ToT, which expands multiple reasoning tree branches, the BoT method iteratively refines a single line of thought. This focus on iteration rather than expansion allows for a more concentrated and efficient improvement of the reasoning path. The computation moves from exploring the tree into learning from erroneous trials. \n\n3. The Boosting of Thoughts (BoT) concept shows a clear advancement in problem-solving methodologies within large language models. It effectively combines generation and evaluation steps to progressively enhance reasoning, demonstrating a significant leap in the model's ability to handle complex tasks. \n\n4. The experiments are clear, the results are effective. And all experiments are classic experiments from CoT and ToT, so it is clear to compare BoT\u2019s performance over CoT and ToT.",
        "weaknesses": "The mauscript need polished in their figures' presentation, e.g., the authors need give more detailed examples in Fig1.",
        "questions": "Q1: In the prompt, I wonder whether the \u201cerror input\u201d are included, or only the \u201cexperience\u201d is included? From figure 1, I only see \u201cerror report\u201d like \u201cstep 1 is not closer to 24\u201d, no \u201cerror input\u201d like what is step 1, 2, 3. How the LLM know what step 1 mean, and how can LLM learn from error, if LLM does not know specific input?\nQ2: How about you consider the entire (input, error analysis) as an In-context Learning example? Then the entire method is similar to CoT, meaning that you can manually construct an exemplar consisting of (input, error analysis) pair. Then use the CoT idea to follow the strategy to generate analysis and think about the correct answer.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper proposes a Boosting of Thoughts (BoT) framework, which aims to achieve the boosting mechanism that embraces aggregation and experience, thereby enabling the progressive refinement of unreliable reasoning steps (weak thoughts) by learning from errors to solve various problems, eventually.",
        "strengths": "This paper reiterates their proposition that a simple prompt can be enhanced by gradually accumulating error analysis on its generated thoughts to address complex tasks.  The authors present a novel framework, the Boosting of Thoughts (BoT), to implement such progressive prompt enhancement for effective thought generation with an experience-driven iteration process. Iteratively exploring and self-evaluating the generated simplistic trees of thoughts enables a simple initial prompt to be gradually enhanced by an ensemble of trial-and-error reasoning experiences, resulting in accurate solutions. \nThis work seems like a quite comprehensive investigation with well-structured and easy to read sections.",
        "weaknesses": "The paper is based on the motivation that starting with a simple prompt without human annotations for LLMs, BoT may get weak thoughts. However, with aggregation, BoT is capable of deriving a more logical and effective thought chain from them, thereby guiding the subsequent refinement.\n\nCould the authors expand on this statement \"Experience consistently leads to thought revision, but too much can have the opposite effect.\"? If one is looking to recreate the study, are there any guidelines or steps one could adopt to as where should be the stopping point?\n\nVery interesting findings, however Experimental results reported are limited. The authors evaluated LLM models only on a single testing procedure. However, the analysis doesn't seem concrete due to the smaller sample set considered and it would truly be insightful if the analysis was done on a larger dataset to infer results.\nFurther experiments should be performed using statistical metrics, and statistical distribution of the results should be extracted. These outcomes help better support the conclusions' claims.\nThe paper would be greatly strengthened if the proposed algorithm would outperform state-of-the-art methods",
        "questions": "Please review the weakness section",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes a new framework called Boosting of Thoughts (BoT) for complex problem solving with large language models. BoT aims to iteratively explore many possible trees of thoughts and learn from ineffective thoughts/errors to progressively refine the prompt and elicit effective reasoning from LLMs. It aggregates the best reasoning chains from the trees and analyzes them with the LLM to gain experience on errors and revisions. Experiments on mathematical reasoning show BoT matches or exceeds previous SOTA approaches without needing human annotations.",
        "strengths": "1. The paper proposes a novel framework, Boosting of Thoughts (BoT), that utilizes an iterative trial-and-error approach to refine prompting and elicit complex reasoning from LLMs. The key idea of learning from errors/ineffective thoughts is creative and mimics human problem-solving.\n2. Authors involve interesting techniques like weighted binary trees and heterogeneous growth strategies to generate diverse, shallow thought structures from a simple prompt.\n3. Evaluations on mathematical reasoning benchmarks demonstrate effectiveness of BoT. It matches or exceeds state-of-the-art methods without needing human annotated prompts. Also, the authors conduct ablation studies to further explain the mechanisms.",
        "weaknesses": "1. Although this article proposes several practical strategies, its reasoning framework remains inherently reliant on the Tree-of-thoughts model, thereby limiting its novelty. BoT's structure is restricted to binary trees. Expanding to more complex graph structures will further improve reasoning but is not explored.\n2. For analysis, the prompts used to seed BoT could introduce biases and variances. More evaluations on OOD data would be useful to assess the robustness and generalizability of the improvements.\n3. The evaluations are mainly limited to mathematical reasoning. For generality, testing BoT's performance on other domains like commonsense reasoning or symbolic reasoning is needed.\n4. In the 'Competitors' paragraph, authors mentioned incorporating CoT-SC and Complex CoT as  baselines, yet CoT-SC is not shown in the 'mathematical reasoning' part. I hold the view that comparing the proposed method with prevailing baselines like SC(5) or SC(10) will offer a more direct reflection of BoT's efficacy. If it can outperform Complexity-based SC with fewer resources, it would make the work more solid.",
        "questions": "1. As for the statement on page 3, 'Our paper embraces ToT due to its high ability and leaves GoT and BoT for future work,' is 'BoT' a typo error here? Or you mean combining BoT method with GoT? Regardless, I believe that including GoT in the comparison would make this work more interesting and informative.\n2. In the 'Competitors' paragraph in experiments, could you clarify how many reasoning chains are sampled for Complex-CoT and PHP respectively?\n3. The study conducts experiments based on GPT-4, which can lead to substantially high experimentation costs. Have the authors considered or utilized more cost-effective options like GPT-3.5-turbo? I'm aware of the recent variability in performance of this model. However, if there are experimental results showing that GPT-3.5 combined with BoT can outperform GPT-4 with CoT/CoT-SC, it would render the study's findings more convincing.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper looks at optimizing prompting for GPT-4 and Llama2 for solving mathematical problems. They provide an iterative strategy to prompting models for complex problems. The key challenges are SVAMP (1000 tasks), GSM8K (8500 tasks), AQUA (100 000 tasks), and MATH (12 500 tasks). The BoT, especially when enhanced with CoT, outperforms alternative methods.",
        "strengths": "When we reach the limits by simply increasing language models, optimal interaction becomes increasingly interesting. Exploring new ways of pushing the models to do more complex tasks can get more value out of existing LLMs and is highly relevant. \n\nThe paper provides code that is easy-to-read (although a Readme would be a nice addition).\n\nThe method shows that BoT and CoT perform above the comparisons.",
        "weaknesses": "The use of the term 'boosting' in the context of refining 'weak thoughts' introduces some ambiguity. In traditional machine learning, boosting involves the iterative enhancement of quantifiably weak learners. In the BoT framework, the concept of a 'weak thought' is more abstract, and its \"weakness\" is not as straightforward to measure. This led me to perceive the process more as a 'pruning of weak thoughts' rather than 'boosting' in the conventional sense. It would be beneficial for the paper to clarify how the model aggregates and refines these thoughts in the tree structure, and how the \"weakness\" of a thought is determined and improved upon.\n\nI think the paper comes across unnecessarily complicated, compared to the code the text is hard to fully grasp. The figures all depict Game of 24, adding examples from both a successful and a failed example of BoT for the other tasks would be beneficial.\n\nFor complete reproducibility and clarity, it would be beneficial to provide the full codebase, including modules like 'llmpebase\u2019s residual_tree_of_thoughts', which is referenced several times but not included.\n\nThe title suggests a general problem-solving approach using Large Language Models. However, the content is specifically focused on mathematical problems. It might be beneficial to make the domain-specific nature of the research clearer in the title or early in the abstract to set accurate expectations for readers.",
        "questions": "Do I understand correctly that T 10 was maximum 10 prompts and M 15 consisted of 15 instances that generated binary trees that you then averaged over?",
        "rating": "8: accept, good paper",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Accept"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "H9DYMIpz9c",
    "title": "Farzi Data: Autoregressive Data Distillation",
    "reviews": [
      {
        "summary": "This paper proposes FARZI, a data distillation method for auto-regressive ML tasks/event-sequence datasets. The method summarizes a large dataset into a set of synthetic sequences in latent space which can be decoded later. They show that model performance is upheld/enhanced when compared to training on the complete dataset on the downstream tasks of sequential recommendation and language modeling. For data distillation, the paper shows Adam to be better than SGD as inner loop optimizer, and derives an efficient reverse mode differentiation of Adam such that its memory complexity is independent of the number of inner loop steps.",
        "strengths": "- Originality and Significance: The latent parametrization that makes FARZI optimization friendly, and the proposed trick that enables reverse mode differentiation of Adam such that its memory complexity is independent of the number of inner loop steps are great contributions and of practical value.\n- Quality and Clarity: The paper is well written with extensive experiments whose details and evaluations are that are clearly described. The results are impressive. The method is able to achieve better performance on downstream tasks compared with using the full dataset.",
        "weaknesses": "- It is not clear whether this method will be practical and scale for larger language models and larger datasets. It would be great if the authors can elaborate on this.\n- There is not a clear analysis of the total time gains of this method in comparison with training from scratch. Providing some values would make the case for this method more compelling.",
        "questions": "Listed in weakness section.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper introduces FARZI, a data distillation framework for machine learning tasks. The goal is to condense the original large dataset into a much smaller number of synthetic sequences, so that downstream performance on the synthetic data matches (or even improves) performance on the full real dataset. The authors cast the problem using a bi-level optimization formulation, similar to meta-model matching based dataset distillation. The naive formulation is infeasible due to the very large token vocabulary and the maximum sequence length. To address this, the authors propose to factorize the synthetic dataset into a latent data summary and a token-decoder matrix. This renders the optimization continuous (as opposed to discrete), while it provides flexibility to sample synthetic sentences from a distribution (as opposed to having a fixed small set of synthetic sentences). Furthermore, the authors suggest to replace SGD in the inner loop by the Adam optimizer. To mitigate the large memory footprint, they derive an efficient approximation for reverse-model differentiation of the Adam optimization. The authors assess FARZI on sequential recommendation and language modeling tasks, where they manage to match or even exceed the downstream full-data performance using as little as 0.1% of the original dataset. The authors conduct several experiments and ablation studies to shed light on various aspects of their framework.",
        "strengths": "The paper makes several interesting contributions. The meta-model matching based dataset distillation was originally proposed for continuous data (e.g., image data), as opposed to language data that use discrete tokens. The use of a latent space addresses this challenge by ensuring that the optimization can be performed in a continuous space, but by also allowing us to sample the synthetic sentences from a compact distribution. Furthermore, the observation that the Adam optimizer is a much better choice for the inner loop optimization (compared to SGD) is very interesting and dramatically improves downstream performance. To address the large memory footprint, the authors derive an efficient approximation of the reverse-mode differentiation of the Adam optimizer, which nicely complements their finding that Adam is better than SGD. Interestingly, this may be more broadly applicable in other bi-level optimization tasks (e.g., in a meta-learning context).\n\nThe paper is well written and the related work is covered quite extensively. The authors describe in detail the various insights of their framework. When it comes to the experimental evaluation, they provide a lot of information on the metrics, datasets, hyperparameters, objectives, and even architectures.\n\nThe experimental evaluation is quite convincing and supports the claims made by the authors. It is very interesting that FARZI can even outperform downstream performance on the full original dataset, which could indicate the improved robustness with dataset distillation. I liked the fact that the authors investigated various aspects of FARZI, such as the versatility of the synthetic data, the cross-architecture generalization, the performance of different meta-objectives, the cold start problem, and the impact of pre-trained trajectories.",
        "weaknesses": "1. Even though this paper makes interesting contributions to the DD literature for autoregressive tasks, it is not so obvious that it would be \nvery helpful for much larger text corpora and large language models with millions or billions of parameters. The memory footprint might end up being very large, rendering the whole framework infeasible. Furthermore, a compression rate of 0.1% may not be extremely helpful for very large datasets consisting of billions of sentences. This may limit the applicability of FARZI to settings consisting of \"reasonably large but not very large\" language corpora.\n\n2. It was not clear to me how time-consuming the FARZI dataset generation process is. For example, how long did it take to generate the synthetic datasets for the tasks considered in this work? In particular, did FARZI improve the total runtime? For instance, if generating the synthetic data takes very long, then there may be very little benefit (if any) from this process. Furthermore, it is not automatically obvious that a smaller dataset can be trained faster than a larger one. There is the added question of the number of epochs required to reach convergence. The synthetic dataset may require more rounds. This was not obvious in the experimental evaluation. If I am not mistaken, I feel that the subject of runtime was only superficially touched in this work, and a more thorough discussion (with detailed pros and cons) would be needed.\n(Theoretically, this may not be a big issue if the same synthetic dataset could be successful used on several downstream tasks, but this is not immediately true. If we need dataset distillation for each separate task, then we may end up performing FARZI several times.)",
        "questions": "1. Could the authors elaborate more on the total runtime (total time for synthetic dataset generation + total time for downstream training with synthetic vs. full data)? It would be helpful if the authors could shed light on the various questions/comments raised in Weakness (2) above.\n\n2. In Equation (2), \\Omega is a set containing initializations for the inner loop, if I understand correctly. But instead of picking the initialization randomly, these come from a small number of training trajectories on the full dataset. If that is true, then the \\theta_i in the definition of \\Omega has nothing to do with the update rule for \\theta_t in Equation (2). This may still be confusing to some readers though because the same symbols are used (theta with a subscript, so the authors may want to clarify this point (i.e., what exactly is in \\Omega).\n\n3. I was not clear how exactly the authors chose the final hyperparameters for each setting. Did they exhaustively try all corresponding combinations in the hyperparameter table and picked the best one?\n\n4. Is a new synthetic batch created at the beginning of each outer-loop step based on the latent factorization?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposes a method for distillation of \"auto-regressive data\", in this case meaning any data that is represented as event sequences. This can include natural language text, but also general time-series data. Their method aims to summarize a dataset into a sequence of latent embeddings (which can subsequently be decoded) given a downstream task such that they achieve similar performance to training on the complete dataset. They do this through a meta-learning procedure, optimizing directly through Adam for data which lowers downstream task loss.",
        "strengths": "My review comes from the point of view of someone familiar with training on natural language (and associated downstream evaluation), but not general event forecasting problems. I was not familiar with the benchmarks used by the author prior to reading this paper. \n\n**Originality and Significance**\n\n- The paper seems original. Aspects of this work (e.g. using meta-learning/second order methods) for distillation have been touched on in the past, but usually for smaller datasets, and generally not for auto-regressive tasks. Most past works I have seen which work on large corpuses revolve around finding mixing coefficients for existing datasets [1]. This method doesn't work on datasets of that size, however this shows an improvement in scaling. \n- Getting a meta-learning approach to work on such dataset sizes is quite difficult, given difficulties with estimating second-order components over the full dataset. Scaling this to even larger language-style datasets would be an interesting (future) contribution.\n\n\n\n**Quality and Clarity**\n\nThis paper is quite well-written. Experimental details are clear, and the method is properly motivated. Diagrams clarify the algorithm and the key difficulties to this method are highlighted appropriately.\n\n[1] The Pile: An 800GB Dataset of Diverse Text for Language Modeling, Gao et al. 2021",
        "weaknesses": "**Weaknesses**\n\n- The authors touch on language datasets as a motivation, however do not study this (or other large-sequence tasks) due to practical model/sequence length scaling constraints. Are there reasonable paths forward that would allow this to scale to longer sequence lengths/larger models? \n- Given that the outer loop evaluates across the full original dataset, and the inner loop needs to be run several times to get updated parameters (Figure 5), what's the overall cost saving versus just training a model on the original dataset for more time (until matching student performance), if any? \n- Have the authors thought about cases where there is significant noise in the training corpus? Given that the loss is computed with respect to the original dataset, it seems like this could be a problem if one ever tried to directly filter a noisy web-crawl.",
        "questions": "All questions have been included in the \"Weaknesses\" section above.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper provides an extension of dataset distillation to sequence modeling along with a few other innovations, such as a low rank approximation of the distilled dataset and an efficient trick to save memory during meta-learning. Overall, the paper contains strong (albeit limited) empirical results on the sequence modeling (penn tree bank) and recommendation systems datasets.",
        "strengths": "* The high level motivation of the problem is quite the need of the hour, as with larger models we need to better understand their dependencies on the data\n* Pursuit of this research direction could potentially yield methods that enable us to train SOTA transformer models for a fraction of the input cost\n* Empirical results are thorough, although a bit limited in terms of number of datasets for sequence modeling (only PTB is used)",
        "weaknesses": "A number of points about the approach were unclear to me from the writeup, and I would appreciate clarifications from the authors:\n\n* It is said that the complexity of the dataset distillation algorithm scales by the size of the vocabulary (page. 4) and the size of the sequence that we wish to model. I can see the latter to be the case, since the loss will now be summed over the entire sequence as opposed to one forward pass (so the complexity of the forward pass is increased). However, I do not see how the time complexity increases with the vocabulary size. Do we mean space complexity? Also, more than the forward pass the dominant factor in dataset distillation is the computation of a bunch of hessian vector products in the meta gradient. Those terms do not depend on the vocabulary size either\u2026 please clarify..\n* It would be nice to provide an intuition for what is saving the memory, making things O(1) in memory.  Currently the big algorithm block does not provide an intuition for how this approach is O(1) in memory regardless of the number of timesteps of unrolling. This is important to clarify, since this is an important contribution, if clearly explained. If this approach is essentially gradient checkpointing, then it is worth noting that Deng and Russakovsky already implement a version of this in their code. \n* Looking at Eqn. 2, I am a bit puzzled as to how \\Omega, namely the trajectories from the real data are incorporated in the DD process. From what I am able to understand, \\theta_0 \\sim Omega -- namely the init is sampled from the pretrained trajectories, and then from the right hand side of eqn. 2 I understand that the rest of the trajectory is obtained using Adam on the synthetic data. Where is the role of the pretrained trajectories then? Please explain..\n\n* Rank regularization has been done in the previous work (Deng and Russakovsky) for dataset distillation. It should be cited that this has been done, and not be presented as a novelty..",
        "questions": "My major questions concern the clarifications about the approach listed above, without which it is really hard to judge the technical correctness / soundness of the paper.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The authors introduce a dataset distillation (DD) method called Farzi Data for data with a \"left to right\" (autoregressive) causal structure. Their algorithm has two novel elements: 1) the parameterization of the synthetic distilled data, which allows them to apply it to discrete data (such as the tokens in language modeling); and 2) a method for computing the outer loop gradient for DD when the inner loop is performed with Adam, which has a constant memory footprint independent of the number of inner optimization steps. They conduct extensive experiments with their proposed method on language modeling and sequential recommendation tasks. Compared to existing DD methods (adapted to discrete data via their parameterization), they obtain improved performance across the tested datasets, often obtaining downstream performance better than training a model on the entire original dataset.",
        "strengths": "**Algorithmic Contribution.** Algorithm 1 for computing the gradient through the inner-loop optimization with Adam using constant memory is a significant contribution. Among existing dataset distillation methods, those which take into account the entire training trajectory on the distilled data tend to obtain better accuracy (as compared to other methods which use surrogates for this objective such as the gradient matching objective in dataset condensation). However, the computational burden of these methods (specifically the memory requirement, which necessitates keeping the entire computation graph) renders them infeasible for application to larger datasets. Farzi Data takes a significant step towards addressing this problem by introducing an algorithm for differentiating through an inner loop optimized with Adam, whose memory does not scale with the number of steps in the inner loop (see Fig. 5). This is an important improvement for DD to be practically useful in real ML applications.\n\n**Empirical Results.** The empirical results are also impressive. The authors obtain better performance than competing methods across several different real-world benchmarks. There are even scenarios where their distilled data consistently outperforms training on the entire original dataset (cf. Table 1), indicating that Farzi Data implicitly promotes some sort of \"data cleaning\" whereby samples that *hurt* model performance are removed or discounted. This is similar to, e.g., removing mislabeled points or data with negative Shapley values, but Farzi Data is not explicitly trained for this task.",
        "weaknesses": "**Presentation and Clarity.** While the actual prose of the paper was generally clear and easy to read, there are some major concerns with notation/presentation that limit understanding of some of the main contributions of the paper.\n\nP1. There are many cases where important notation is not defined. For instance, $\\mathrm{Rep}(\\mathcal{F}, \\mathcal{D})$ is defined in the Appendix, but not the main text, and is critical to interpreting Theorem 3.1. It is not stated what the terms $d\\mathbf{m}$, $d\\mathbf{x}$, and $d\\mathbf{w}$ in Algorithm 1 are supposed to be, so it is impossible to determine if the expressions are correct or not. How to construct the output of the algorithm from these quantities is also not clear. What is the correspondence of the quantities in Alg. 1 to the DD problem, i.e., what will we actually update using the meta-gradient once we know how to compute it? Some (but not all) of these details can be found in the Appendix, but as they are critical to being able to understand the results, they should be moved to the main text and given appropriate explanations.\n\nP2. Stylistically, there is also some nonstandard notation. For instance, $\\mathcal{O}(100)$ (3rd bullet point, pg. 2). I suppose the authors meant \"on the order of 100x\", but big-O notation has a mathematically precise meaning that doesn't make sense here. Another instance is Proposition 3.2. \"Correctness of Algorithm 1, Line 13\" is not a complete mathematical statement (or a complete sentence). The result should be stated completely and precisely.\n\n**Theoretical Results.** There are also issues with the theoretical results.\n\nT1. The most critical problem is that the proof of the main theorem (Theorem 3.1) is not mathematically sound. Specifically, the authors want to show that the expected representativeness of their low-rank synthetic data parameterization is strictly less than the expected representativeness of a naive synthetic data parameterization, under some suitable conditions and for quadratic classifiers: $\\mathbb{E}[\\mathrm{Rep}(\\mathcal{F}, \\mathcal{D}_F)] < \\mathbb{E}[\\mathrm{Rep}(\\mathcal{F}, \\mathcal{D}_N)]$. ($\\mathcal{D}_F$ and $\\mathcal{D}_N$ stand for Farzi and naive data, respectively.) In their proof in Appendix B.1, they show that $\\mathbb{E}[\\mathrm{Rep}(\\mathcal{F}, \\mathcal{D}_F)] < B_1$ and $\\mathbb{E}[\\mathrm{Rep}(\\mathcal{F}, \\mathcal{D}_N)]$ for some bounds $B_1$ and $B_2$. Then, since $B_1 < B_2$, they conclude the desired result. This is not valid: $a < b$, $c < d$, and $b < d$ does not imply that $a < c$. There needs to be a _lower_ bound on the representativeness for the naive parameterization.\n\nI remark that I believe the _result_ is (at least \"morally\") correct. The theorem essentially reduces to saying that the Rademacher complexity resulting from the low-rank parameterization is smaller than the Rademacher complexity from a general parameterization, which is intuitively obvious. However, the _proof_ has a fatal error and must be corrected somehow.\n\nT2. For Lemma B.3 to hold, there must clearly be some assumptions on the loss function $l$; in order to apply the lemma from Shalev-Shwartz, the Rademacher complexity of the loss composed with the models in $\\mathcal{F}$ must be considered, not $\\mathcal{F}$ itself. As stated, I believe this lemma is not correct and the loss must be accounted for. Apart from the logical error, the motivation for the use of quadratic classifiers in the theorem wasn't clear to me. What connection do such models have to the auto-regressive tasks that Farzi Data is applied to?\n\nT3. This is related to the presentation problems regarding the notation used in Algorithm 1, but the proof of Proposition 3.2 is also suspect. What is meant by $d\\mathbf{m} = d\\mathbf{m} + \\frac{\\partial w_t}{\\partial m_t} \\cdot d\\mathbf{w}$? Is $w_t$ supposed to be $\\mathbf{w}_T$, or is this expression meant to be a recursive formula? What about the formulas for the other quantities, and how are these combined to compute the meta gradient?\n\nIf these issues can be satisfactorily addressed, along with the questions in the section below, I would be willing to raise my score to accept, given how promising the empirical results are.",
        "questions": "Q1. The authors mention that training with the reference trajectories $\\Omega$ is important for obtaining the best performance, as compared with training only from randomly initialized networks. However, it wasn't clear to me if this might just have been the result of a greater number of training steps when learning the distilled dataset. That is, are the results in Fig. 6(b) with the total number of meta-gradient steps constant, or do the additional precomputed trajectories result in more meta-gradient steps?\n\nQ2. On a related note, it was not clear to me exactly how the precomputed trajectories were used. My assumption was that instead of training the network in the inner loop only from random initializations, instead the network from the inner loop will be initialized with parameters from one of the training trajectories. Is this correct?\n\nQ3. Why isn't FMLP also used as a teacher network in Table 1?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "rp5vfyp5Np",
    "title": "BATTLE: Towards Behavior-oriented Adversarial Attacks against Deep Reinforcement Learning",
    "reviews": [
      {
        "summary": "This paper studies behavior-oriented attacks agains deep RL agents, where the adversary forces the victim to have specific behaviors. The proposed attack first learns an intention policy based on human preference, and then trains an adversary to perturb the victim observation such that the behavior follows the intention policy. The adversary also adopts importance weights of states to optimize the attack objective. Experiments on multiple meta-world and mujoco show that the proposed method is able to manipulate the victim with high success rates, including offline policies based on decision transformer. The method can be also used to improve the robustness of agents.",
        "strengths": "This paper proposes an interesting type of attacks that are oriented by desired behaviors. Compared to prior works focusing on reward minimizing, the proposed attack can be more widely applicable. In real-world environments where rewards are not well-defined, such attack objective can be interesting to investigate. Learning the intention policy from human preference is also an interesting idea, although I have some concerns on it (see weakness).",
        "weaknesses": "1. The human preference-based intention policy learning brings extra requirement and uncertainty to the process - the collection of human preference data can be expensive. More importantly, to obtain human preference labels, one need to first collect diverse behavior data so that human can pick the intended policy. Would the collection of the behavior data already involve a pre-defined target policy? (If that's the case, why not directly use the target policy for attacks?)\n2. In experiments, the authors mainly evaluate the attack success rate. However, it is not clear how the success rate is defined. Is it based on whether the victim acts as the intention policy suggests? But would it be biased since the intention policy is just an approximation of the real human intention? What if the intention learning does not learn a desired reward model or intention policy?\n3. For baselines, the authors used the codebases of SA-RL and PA-AD and modified their attack's reward as the learned reward. However, this straightforward modification of the PA-AD baseline contradicts with the original method (PA-AD's formulation is for a reward-minimizing adversary, so directly replacing the attacker's reward may not work). Since the original PA-AD method is to use an RL director to find the target policy and to use an actor to conduct targeted attack, a more natural modification of PA-AD in the behavior attack scenario can be to directly use the learned intention policy as the target of actor ($\\hat{a}$ in Equation (G) in the original paper).",
        "questions": "How are the behavior sequences generated for human preference labeling?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "They introduce a method to attack reinforcement learning policies. There are three key components. First, they use PbRL to train a policy to exhibit the desired behavior. This is a relatively novel step because most work in adversarial RL assumes that the desired target behavior is already known and incentivized by a reward function. Second, they train a weighting function to help prioritize relevant states and keep the next step from policy drift. Finally, they attack the target policy with an adversarial policy that makes it behave similarly to the target behavior using the weighting function.",
        "strengths": "- Working with both classic RL agents and decision transformers makes for much more thorough experiments.\n- Adversarial policies that result in targetedly bad behavior is an area of research I believe is important and neglected.",
        "weaknesses": "1. Writing\n    - I have found some of the writing to be confusing and verbose. For example, \u201cintention policy\u201d is not defined until multiple mentions in. The description of what it is in the abstract is very ambiguous. \u201cInner\u201d and outer\u201d level loss are not described. I don\u2019t see a definition for \u201csuccess rate\u201d in the paper. I don\u2019t think the paper does as good of a job as it could with laying out things in a way that is clear and quick to understand.\n    - I do not understand the rationale in the first paragraph of section 4.1. I do not think this makes sense as an explanation of why an intention policy is needed instead of a direct attack.\n    - I do not understand figure 1. Why is there an arrow between reward learning and the replay buffer?\n    - Numerous grammar mistakes. I would recommend using a grammarly browser plugin.\n2. This may speak to either issues with my reading of the paper, its writing, or the quality of the experiments. But I am unsure why BATTLE trains an intention policy with PbRL instead of just training the adversarial policy directly with PbRL. This would seem to be substantially simpler. \n3. I do not understand how SA-RL can perform so poorly relative to BATTLE unless it is just due to reward shaping. What is the reward function used for SA-RL? If an adversarial policy is directly trained to minimize the agent\u2019s reward, how can this do worse than BATTLE at making the target agents\u2019 reward be minimized? If the key difference truly is just reward shaping, then this paper would just seem to be one about how PbRL makes reward shaping automatic and implicit. And if so, then this paper would seem to have no novelty.\n4. Relatedly, I do not understand why this paper is about adversarial attacks. BATTLE could be used to make RL policies do anything \u2014 not just to targetedly adversarially attack them. But in reality, to make RL policies do things, we just finetune them directly. This relates to why I do not understand why the intention policy was used. Why not just finetune the target angent or adversary directly wit pbrl?",
        "questions": "- Which experiments were performed with real humans and which were with synthetic feedback?\n- See weaknesses",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper introduces BATTLE, an adversarial attack framework targeting DRL agents. The main focus is on behavior-oriented adversarial attacks, which aim to induce specific behaviors in a DRL agent, as opposed to merely reducing the agent's rewards or driving it to a pre-determined state. BATTLE uses an intention policy aligned with human preferences and an adversary to guide the victim DRL agent to imitate the intention policy. A weighting function is also introduced to optimize the effectiveness of the attack. The authors claim that BATTLE outperforms existing methods in inducing specific behaviors and can also be used to improve the robustness of DRL agents when used in an adversarial training setup.",
        "strengths": "The availability of both code and demos enhances the paper's reproducibility. The paper enhanced the proposed methodology with convergence guarantees for BATTLE, adding rigor to the work.",
        "weaknesses": "1. The presentation quality could benefit from further refinement for better clarity and impact.\n2. The method's reliance on extensive human labeling hampers its real-world applicability, raising concerns about scalability.\n3. The paper could be strengthened by including more motivating examples from real-world scenarios. The assumption that an adversary can modify observations is strong and raises questions about practicality. For instance, if an adversary has the ability to control the sensor, they might as well directly control the effector, making an agent-based adversarial approach seem more practical. Additionally, the rationale for using preference-based RL remains unclear.\n4. The paper lacks some critical methodological details. For example, it doesn't specify how the victim policy approximator is trained or the volume of data required, leaving gaps in the understanding of the implementation.\n5. The experimental setup and evaluations could be more convincing. The choice of baselines (PA-AD and SA-RL), which are un-targeted attacks, makes the comparison seem potentially unfair. Moreover, while various defense methods like adversarial training, robust learning, policy ensemble, and policy distillation exist, the authors have limited their experimentation to ATLA.",
        "questions": "1. Could the authors elaborate on potential real-world applications for the proposed method and discuss the challenges that might arise in such contexts?\n2. Expanding the experimental results to include additional comparison metrics would be valuable. Specifically, how does PALM fare against targeted attacks and various other defense methods?\n3. What is the extent of annotation required, especially in relation to the complexity of the task at hand?\n4. Could you provide details on the training process for the victim policy approximator, including the amount of data needed for effective training?\n5. How generalizable is the weighting function across different types of tasks and domains?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper introduces BATTLE, a novel universal behavior-oriented adversarial attack method designed to induce specific behaviors in deep reinforcement learning (DRL) agents. Unlike prior approaches that focus on directing agents towards predetermined states or policies, BATTLE employs an intention policy aligned with human preferences for flexible behavior orientation, guiding the victim agent to imitate it. The paper demonstrates the effectiveness of BATTLE through empirical results across various manipulation tasks in Meta-world, showing its superiority over existing adversarial attack algorithms. Additionally, BATTLE enhances the robustness of DRL agents by training with the attacker, achieving a convergence guarantee under mild conditions, and proving effective even against the latest Decision Transformer agents. In summary, the paper makes contributions in the realm of behavior-oriented adversarial attacks on DRL agents, both in theory and practical applications.",
        "strengths": "1. The paper introduces an interesting and novel concept, proposing a new type of attack based on preference-based RL.\n\n2. The design of the inner-level optimization and outer-level optimization is well-founded, and the paper provides theoretical analysis of the algorithm.\n\n3. The paper sets up different scenarios for evaluating various agents and conducts detailed ablation studies.",
        "weaknesses": "1. The writing needs improvement, particularly in clarifying several terms and diagrams. For example, some terms like \"find a precise weighting function to balance the state distribution\" need better explanation. Clarification is also needed for the diagram in Figure 2.\n\n2. The presentation of experimental results is somewhat confusing. The differences of scenarios in Figure 4 and 5 are not clear, and additional explanations are required for the target coordinates mentioned for Figure 4. Captions of Figures 7 (a) and (b) might need to be swapped, and sections (c) and (d) require clearer explanations.\n\n3. The paper lacks a discussion of limitations, which should be addressed.",
        "questions": "1. It's disappointing that the paper doesn't include RADIAL-RL[1] or WocaR-RL[2] as baselines when discussing robust training. Even if only ATLA is selected as a robust baseline, it would be valuable to mention other adversarial robust RL papers in the related work.\n2. In the introduction, the paper illustrates the practical implications of targeted attacks on robotics, but the concern is raised that BATTLE is a white-box attack applying perturbations to states. In the context of robotics, its practical applicability is very limited. The paper could benefit from a more thorough clarification or discussion of this concern and its potential implications for practical applications. It fails to persuasively underscore the significance and relevance of this work within the field.\n\n[1]Robust deep reinforcement learning through adversarial loss\n\n[2]Efficient adversarial training without attacking: Worst-case-aware robust reinforcement learning",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "miGpIhquyB",
    "title": "Understanding Large Language Models Through the Lens of Dataset Generation",
    "reviews": [
      {
        "summary": "This work studies the attributes of dataset generation, which has recently been explored as a way to train task networks without needing a natural, human-generated dataset. Particularly, this work studies 4 domains/tasks that dataset generation can be applied to (e.g. SST-2), and studies the trade-offs between different attributes: faithfulness, diversity, conformity, complexity, and performance, all of which the authors measure automatically. The authors find significant differences between different model types, especially finding that instruction-tuned models differ from classical LMs. Neither paradigm seems to completely dominate.",
        "strengths": "- Overall, this type of contribution is sorely needed in dataset generation, which is still not a well-understood field\n- The attributes to study are diverse and relevant\n- Very interesting and informative conclusions drawn about the tradeoffs, e.g. the loss of diversity in generated datasets when using instruction-tuned models\n- paper is well presented and quite clear",
        "weaknesses": "- I have concerns wrt the measurement of some of the aspects:\n   - faithfulness is measured as the accuracy on the synthetic set with a model trained on the reference (human) set. While being unfaithful is one reason this value may be low, it is not the only one. It is easy to imagine a *faithful* dataset on which this classifier will perform poorly, due to issues like style shift or poor generalization of the classifier. To be more concise: staking faithfulness on the accuracy of a classifier ignores the fact that this may be an issue of the classifier rather than the dataset that is being evaluated. \n   - similar issue with complexity, which is measured as inverse accuracy on a held out chunk of the synthetic set. While I agree that lower complexity will indeed raise this accuracy, high complexity is not the only reason this accuracy may decrease. \n- Overall, I would suggest renaming these metrics. They likely correlate with the values they are described as, but it is overly presumptuous to label them this way as there are many other factors. More direct names (e.g. complexity -> self-accuracy or something like this) might be more accurate, leaving discussion of factors affecting these values (like complexity) to the discussion\n- Tradeoffs (Figure 2) are only shown in terms of temperature, which may be a confounding factor. It would be good to show other curves, e.g. for values of top-p, because it is not clear if these tradeoffs may have to do specifically with the specific warping effect that temperature has on sampling distributions. Alternatively, being more precise in the paper text, that these are tradeoffs over temperature as the variable, rather than general tradeoffs.",
        "questions": "Have you tried variables besides temperature to test the tradeoffs?",
        "rating": "8: accept, good paper",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper studies the text generation capabilities of various large language models, proprietary and open, instruction-tuned and vanilla, by evaluating synthetic datasets generated from them. The datasets are evaluated in terms of\n1) diversity in vocabulary\n2) complexity, or difficulty in modeling them given by the performance of a model trained and evaluated in-distribution.\n\nBy comparing the generated datasets to existing (reference) datasets in similar tasks and domains, they are also evaluated in terms of\n3) faithfulness, given by the performance of models trained on the reference datasets and evaluated on the generated ones\n4) conformity, given by a measure of distributional similarity between the reference and generated datasets\n5) performance, given by the performance of models trained on the generated datasets and evaluated on the reference datasets\n\nBased on this evaluation framework, the paper discusses the tradeoffs between these aspects of generation quality, how they change across model families, and how instruction tuning affects these tradeoffs.",
        "strengths": "The evaluation framework is sensible and analyzing the capabilities of language models in terms of the tradeoffs between various aspects of generation quality is quite informative. The results of studying the effect of model size, the impact of instruction tuning, and that of the level of instruction tuning can potentially inform how to finetune future versions of language models.",
        "weaknesses": "This study has some missing details, several limitations, and potential confounders not accounted for in the experiments.\n\nMissing details\n\nMD1:The evaluation is done over four classification datasets, but the actual details of the tasks are missing in Section 4. Particularly for AGNews and ELI5, it is unclear what is being classified After reading the Appendix, the AGNews task seems to be some news genre classification, and the ELI5 task seems to be subreddit classification (maybe it should just be called \"subreddit classification\"?) This issue can easily be fixed by including explicit details in Section 4.\n\nMD2: The motivation behind the chosen evaluation metrics is somewhat unclear. Particularly, faithfulness, conformity, and performance seem to be measuring the difference between the generated and reference data distributions. Why do we need these three variants? Relatedly, one would expect these metrics to correlate highly with each other. Analyzing this further would be helpful.\n\nLimitations and potential confounders\n\nL1: It is unclear how noise in the datasets (due to inaccurate labels) affects the trends seen in tradeoffs. For example, is the increase in diversity beyond the the conformity threshold in Fig 2 simply be due to noise? Having humans classify (subsets of) the generated datasets, and introducing the accuracy of the synthetic datasets as an additional metric could make this clearer.\n\nL2: The biases in the reference datasets could also be affecting conformity, faithfulness and performance. It might help to include multiple reference datasets per domain-task combination to evaluate whether the trends hold across them.\n\nL3: It is possible that the models used for generating datasets have seen the reference datasets either during pretraining or instruction-tuning. This would inflate the quality measures according to conformity, faithfulness, and performance. This issue cannot be dealt with directly, but it would help to check the zero-shot performance of the large language models on the reference datasets, and take it int account while inferring the tradeoffs.",
        "questions": "- It would be helpful to put the reported diversity and complexity values in context. What are these values for the reference datsets?\n- Can you elaborate on the motivation behind the three metrics comparing generated and reference datasets (see MD2)?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This work studies the quality of synthetic data generated by LLMs. The major contribution of this work is proposing a framework to evaluate LLM's ability to generate synthetic data for specific tasks, and compare behavior across different LLMs. The evaluation framework consists of five different axes: performance, complexity, conformity, diversity and faithfulness. These properties are either evaluated using accuracy-based metrics, or modified version of existing tools (e.g., distict-n, mauve, etc.). Using this framework, this work compares LLMs with different size, from different model families and with or without instruction tuning. The empirical study reveals interesting tradeoffs among the five axes, and also report general performance trends on overall performance.",
        "strengths": "1. Generating synthetic datasets is a very popular application of LLMs. This work provides a useful framework on evaluating this ability of LLMs.\n2. The empirical study shows interesting tradeoff from the models, and the reported performance trends can be useful for related applications.",
        "weaknesses": "1. I like the general idea of the proposed evaluation framework, but my biggest concern about this framework is the heavy use of DistilBERT accuracies in the evaluation framework. For the faithfulness metric, the framework is evaluating the performance of DistilBERT on the generated dataset. This confounds faithfulness with the difficulty (or complexity) of the dataset. This makes some of the finding questionable. For example, is there really a tradeoff between faithfulness and diversity/complexity, or is this correlation comes from the correlation between difficulty and diversity/complexity? I wonder if the authors can provide gold evaluation results for the DistilBERT models. \n2. This study only focuses on synthetic data generation for relatively simple classification tasks. It would be great if this work can include evaluation on some more complex tasks.\n3. While this paper proposes four other properties addition to the performance. There is not much discussion on the relationship between these properties and the final performance. So while this study show many interesting findings, it is unclear what users should do besides checking the performance rankings.",
        "questions": "1. For the value k in the diversity metric, are you keeping the example size the same, or the token size same?\n2. How do design or select prompts for the study conducted in your paper? Have you checked the sensitivity of the findings with respect to different prompts?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper examines the generation of text datasets using Large Language Models (LLMs) with a focus on distributional metrics like data diversity and faithfulness. It reveals trade-offs between these metrics across different LLMs and training methods, highlighting the impact of popular instruction-tuning techniques on LLM text generation abilities.",
        "strengths": "1. The studied task on using LLMs for data generation is interesting and can be useful for the research community.\n\n2. The authors conduct experiments on various datasets and LLMs (including both open-sourced and close-sourced models).\n\n3. The paper is overall easy to read.",
        "weaknesses": "1. The authors only consider the most simple prompts for the target tasks. However, there are several works that aim to improve the quality of prompts to yield higher-quality datasets, some examples include:\n\n- Chung et al. \"Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions.\" ACL 2023.\n\n- Yu et al. \"Large language model as attributed training data generator: A tale of diversity and bias.\" NeurIPS D&B Track, 2023.\n\nIt is also important to note that some dimensions (e.g. diversity) have already been studied in this work. As a result, some of the conclusions in this paper are already known and there are not many new insights about using LLMs for data generation.\n\n2. Unsupported Claims. The paper raises a claim that \"reinforcement learning with human feedback (RLHF) in ChatGPT leads to a significant degradation in synthetic dataset generation capabilities.\" However, the paper lacks a clear explanation of how the authors attribute this performance drop specifically to RLHF. A more detailed description of the experimental setup and results related to this assertion would enhance the paper's clarity and credibility.\n\n3. In the main paper, the author only considers the average performance over different patterns, which can be less informative as different datasets show diverse patterns (according to Figure 5).\n\n4. For the metrics, it is somehow not clear why using `unique number of tokens` as the metrics of Diversity.",
        "questions": "1. Could you elaborate on why this paper primarily relies on simple prompts for target tasks, especially when recent research has emphasized advanced prompt engineering techniques for improving dataset quality? How might incorporating more sophisticated prompts affect the study's outcomes?\n\n2. Given that some dimensions, like diversity, have already been studied in this work, what new insights or contributions does this paper bring to the field of using LLMs for data generation? \n\n3. In the paper, you assert that \"reinforcement learning with human feedback (RLHF) in ChatGPT leads to a significant degradation in synthetic dataset generation capabilities.\" Could you provide a more detailed explanation of the experimental design and results that support this claim?\n\n4. What conclusions can be made after your study? What are the recommendations for practitioners to use LLMs for training data generation? Currently, it is not very clear after reading this paper, so I feel readers will not benefit much from this paper.",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "SMZnJtkNX5",
    "title": "Temporal Parallelization for GPU Acceleration of Spiking Neural Networks",
    "reviews": [
      {
        "summary": "The authors describe a method and code for accelerating spiking neural\nnetworks (SNNs) on GPUs. They first claim to parallelize the temporal\nmembrane integration of a layer in an SNN and secondly divide the\ncompute onto multiple GPUs. They provide a template how to implement\nit in common ML frameworks such as JAX. Finally, they show that their\nimplementation outperforms other toolboxes.",
        "strengths": "The implementation seems to outperform current toolboxes in terms of runtime.  The authors show that this layer-first\napproach gives a considerable speedup on GPUs due to reduced memory movement.",
        "weaknesses": "While better implementation of simulating SNNs using GPUs has its merits,\nthe task is merely a software\nengineering task. The paper does not add any value in terms of novel\ninsights. This is in particular true since the \"temporal\nparallization\" argumentation is indeed a misnomer as the temporal dimension is *not*\ncomputed in parallel, but instead time of one layer is simply handled\nwithin one GPU kernel (but still computed sequentially if I understand it correctly).\n\nIf one wanted to design a custom CUDA kernel and would assume that\nonly feed-forward layers are allowed, this would be just the standard\napproach to do, I don't see any innovative aspects here. In\nparticular, equation 3 is just a re-writing (inserting) of $x^{(t-1, n)}$,\nthere is no \"transformation\" I can see. Note that $v_i^{(t, n)}$ still\nis a function of previous times, $v_i^{(t-1, n)}$. All what is done is to\ncompute all time steps per layer first before sending the full output\nspike train to the next layer. This will obviously not work for\nrecurrent SNNs. \n\nAlso, the authors do not even provide their own optimized CUDA kernel\n(which would have more merit), but instead rely on generic toolboxes\nlike JAX. The code listings do not provide any details of the\nimplementation and are more like a tutorial how to use it.  \n\nOverall, while the implementation might be useful as it improves the\nruntime of SNNs compared to the (apparently very non-optimized)\nstandard SNN packages, the paper does not provide any new scientific\ninsights. It is also not discussed that the approach works only for\nfeed-forward SNNs. Moreover, the presentation of \"temporal\nparallelization\" is not correct (as it just points to a fused\nsequential CUDA-kernel). Finally, the layer-first approach (fusing\nkernels to reducing memory operations) and dividing the compute for\nmultiple GPUs are rather standard practices in GPU programming in\ngeneral and not novel enough for a research oriented conference\ncontribution in my opinion.",
        "questions": "*  In Eq 3: $x_i^{(t, n)}$ should be $x_i^{(t, n-1)}$",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper trys to use a temporal parallelization method to accelerate the propagation dynamics of SNNs on GPUs. The feature it claims is a cross-timestamp acceleration of LIF model. With the Leaky Integrate- and-Fire model as a test case, the CUDA-based implementation achieved 5\u00d7 to 40\u00d7 acceleration on the A100 GPU.",
        "strengths": "The author proposed temporal parallelisation method tailored for universal SNN units on single and multiple GPUs. It supports both CUDA and JAX frameworks.",
        "weaknesses": "1. The motivation behind this paper lacks clarity. Spiking Neural Networks (SNNs) are not typically intended for deployment on GPUs, meaning that a GPU is not the most suitable platform for SNN deployment. Without a demonstration of the clear benefits of utilizing GPUs for SNNs deployment as opposed to other platforms, the paper's underlying motivation remains unconvincing.\n\n2. How does this paper leverage GPU to implement true spiking mechanism? It is not clear or discussed. Is it only considering simulating the mechanism of the Leaky-Integrate-and-Fire model behavior? Plus, there\u2019s no true spiking signals in GPU, addressing the temporal information is not really Spiking implementation. This paper doesn\u2019t clarify the basic concept. \n(In some sense, parallelizing temporal information is possible, but there\u2019s conversion between spiking temporal information and the muti-bit digital temporal information for GPU? Then what\u2019s the conversion cost?)\n\n3. Although this paper is based on the computational model of LIF, but it does not clearly describe how training and inference is done, respectively. Training an SNN is hard, and it is not discussed at all in this paper, so it\u2019s only about inference, or even, the simulation of inference?\n\n4. Last but not least, most importantly, this paper does not provide any AI-model based results, such as accuracy, performance, respective speed-up, etc, let alone thorough analysis based on the comparison of results. The only result is a table based on a single-layer toy model? For multi-GPU, where is Fig. 4, seems this paper is incomplete?",
        "questions": "1. How SNN neuron spiking behaviour described in Eq.1 and Eq. 2 reflected in GPU?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper presents an SNN-based acceleration strategy with parallelized temporal computation that supports both single and multiple GPUs.",
        "strengths": "Largely improved SNN inference speed compared to the previous implementation. \n\nCompatibility with both single and multi-GPU processing.",
        "weaknesses": "**W1:** Figure 4 is missing. \n\n**W2:** The biggest bottleneck of this work is that the accuracy benchmarking is completely missing in the paper. I understand the inference speed-up is very important in SNN, but I cannot see the reason why the paper chose not to report the accuracy. It is important to verify the proposed implementation with different SNN model architectures. E.g.. ResNet vs. VGG. \n\n**W3:** It seems like the implementation can only accelerate the inference rather than training, which I think is not powerful enough.",
        "questions": "Please refer to the Weakness.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposes a temporal parallelization method for SNNs that can accelerate SNNs on both single or multi GPUs with up to 40x acceleration.",
        "strengths": "The training of deep SNNs requires much more time and memory consumption. Thus, it is meaningful to explore the acceleration of simulating SNNs on GPUs.",
        "weaknesses": "The details of the proposed method are not described clearly in this paper. To make matters worse, the Supplementary Material is the same as the main paper.",
        "questions": "In Figure 3, how the propagation of the spiking neuron layer is paralleled? I assume that V[t] is still computed in serial. For an input sequence with length T, the time complexity is still O(T).\n\nIn section 3.2, the authors claim that the SNN accelerated by pipeline in multiple GPUs may have a faster speed than using a single GPU. However, I am afraid that the communication time between GPUs will be the bottleneck. According to my experience, the communication time is much longer than any other time. Thus, the pipeline method is seldom used in training, and the Distributed Data Parallel is the mainstream.\n\nIn Table 1, the time of SpikingJelly with or without CuPy does not have much difference, which is against my experience. \n\n\nWhere is Figure 4?",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "6AtXCnHCFy",
    "title": "FSN: Feature Shift Network for Load-Domain Domain Generalization",
    "reviews": [
      {
        "summary": "This paper targets a domain generalization problem for fault diagnosis of the bearing dataset and proposes a new model, called the feature shift network (FSN), to adjust the features between source and target domains. The numerical experiment using CWRU and MNIST datasets is conducted to evaluate the effectiveness of the proposed FSN.",
        "strengths": "- The motivation to exploit the additional information of the problem by assuming the specific task of fault diagnosis in bearing datasets is good.\n- The domain generalization problem treated in this paper is important.",
        "weaknesses": "- The paper is not well written and has a lot of unclear points. For example, the detailed setting, such as loss function and calculation of each model component, is omitted. It is hard to understand the technical novelty and advantages of the proposed method.\n- I cannot find the formal definition of the load-domain (LD) generalization problem treated in this paper.\n- In Table 1, the performance gain of the proposed FSN variants is marginal.\n- The motivation of the evaluation using the MNIST dataset is unclear.",
        "questions": "- What does the \"Relation\" mean in Table 1?\n- How does the proposed FSN exploit the physical meaning of domain labels for model training?\n- Is the target domain data accessible in the load-domain generalization? In general, the target domain data is not accessible in domain generalization.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "Traditional deep learning methods for fault detection usually assume that the training set and the test set share the same fault mode space and domain space. Based on the analysis of CWRU bearing data set and its domain division method, this manuscript proposes a Feature Shift model called FSN (Feature Shift Network) to improve the detection accuracy of unknown domain, which can divide domains according to different operating conditions with specific loads, and take advantage of the physical significance of domain labels.",
        "strengths": "1.This manuscript proposes the idea of \"exploitability\" of domain-related information, and it may be a point worth exploring further.\n2.This manuscript is written in a standard and clear hierarchy,  and the structure is easy to follow.",
        "weaknesses": "1.In this manuscript, a parameter with physical significance is used as a domain label, and then the related features of the domain are used to assist classification. But now that labels have physical meaning, what happens if they are input directly to the network with other data? We didn't see the related comparison experiments. So it is not  convincing.\n\n2.Few comparison experiments are conducted.\n\n3.The detailed design of the model, including the loss function, is not explained in sufficient detail.",
        "questions": "1.Why label a domain with a piece of information that can be numerically and physically meaningful, and how is that different from feeding it directly into a neural network?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper aims to address the multi-source domain generalization problem by proposing a feature shift network (FSN). Distinct from traditional domain generalization, the problem of interest has additional information of inter-domain linear relations in the form of domain labels. By taking advantage of such information explicitly in the proposed model, superior performance can be achieved.",
        "strengths": "--The paper attempts to addresses the domain generalisation problem derived from a real-world application. The problem itself is somewhat novel and has not been extensively studied and hence solving such a problem is of great significance.",
        "weaknesses": "--The introduction section lacks essential information of problem definition, description of methods and brief experimental results. This makes it less readable to the readers. For example, it is not clear what the \"Load-Domain\" means and how the feature shift model handles the problem.\n\n--The section of related work is not well organized. More focus should have been put on the most closely related works (i.e. domain generalization in fault detection problems) rather than a broad review of fault detection methods. In addition, the relations between existing works and this work should also be discussed.\n\n--In table 1, Multi FSN does not perform the best as Multi DANN has a result of 83.3.\n\n--The authors fail to compare with SOTA domain generalization methods.\n\n--There exist language issues/typos/notation inconsistency in the manuscript. E.g., \"P(1), P(2), ..., P^{(K)}\"; \"edge distribution\" should be \"marginal distribution\"; \"1 data of source domain a+1 and 9 data...\"; \"This thesis DANN domain adaptive network...\"; \"the ERM said empirical ...\";",
        "questions": "1. What is the loss function of the network?\n2. What is the input (images?) and the output of the model?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper introduces a special domain generalization scenario termed Load-Domain domain generalization and proposes a new model, the Feature Shift Network (FSN), tailored for this scenario. The authors conduct experiments on the CWRU bearing dataset and the MNIST dataset, comparing FSN with classical fault diagnosis methods and other domain generalization methods.",
        "strengths": "The experimental results show good performance of FSN in certain scenarios and hence its potential for practical applications in fault diagnosis and domain generalization.",
        "weaknesses": "1. The writing of the paper should be substantially improved. It reads like bad machine translation and has a lot of grammatical and terminological errors.\n2. The theoretical foundation of the FSN model could be explained in more detail. The model architecture shown in Fig. 3 requires further clarification and motivation.\n3. Experiments are only conducted on two datasets, with limited baseline methods for comparison. It is unclear how the proposed method performs on other datasets that also have \"linear\" domain labels.\n4. The accuracy values do not have confidence intervals.",
        "questions": "See above.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper introduces a novel approach called Load-Domain (LD) domain generalization for fault detection in situations where the training and testing sets have different fault pattern spaces and domain spaces. The authors propose a feature shift model called FSN (Feature Shift Network) specifically designed for LD domain generalization. The model is trained on adjacent source domains to learn feature shifts and then applies these shifts to target domain features, enabling generalization beyond the training set. The approach is validated through extensive experiments on the CWRU bearing dataset and the Rotation MNIST dataset, demonstrating superior performance compared to existing models in LD domain generalization scenarios.",
        "strengths": "1. The topic of Domain Generalization is highly relevant and of significant interest to the research community. Furthermore, the paper addresses the important aspect of leveraging domain information during the training process, which has gained increased attention in recent times.\n2. The paper is well-written and easily comprehensible, effectively conveying its ideas and findings to the readers.",
        "weaknesses": "1. The LD domain generalization problem setting addressed in the paper is acknowledged as a highly specialized case, which limits its broader contribution to the field.\n2. The experimental results presented in the paper lack persuasiveness. Firstly, the dataset used is small and may not accurately represent real-world scenarios. Additionally, the chosen baselines are outdated, primarily predating 2018, despite the emergence of numerous domain generalization methods since then. It is recommended to refer to recent surveys for a comprehensive overview of the latest approaches, e.g., [1].\n3. While the main idea of the paper is generally understandable, there are instances where sentences may create misunderstandings, and insufficient definitions of the problem and task settings are found throughout the paper. Notably, the captions for Figure 1 may inaccurately describe Figure 1(b), potentially causing confusion among readers.\n\n[1] Domain Generalization: A Survey",
        "questions": "Please review the weakness section, and kindly correct any misunderstandings that may exist in my assessment.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "In this paper, the authors introduce a new Load-Domain (LD) domain generalization setting, where the domain label corresponds to actual load magnitude. To serve the scenario, the authors propose a feature shift model (FSN) to learn feature mapping between adjacent domains according to the physical meaning in domain labels. Experiments are carried out on CWRU bearing dataset and rotated MINST datasets to showcase the performance.",
        "strengths": "1. The idea of employing the physical meaning of domain labels to achieve generalization on consecutive domains makes sense to me. \n2. The new setting of LD domain generalization also seems suitable for the benchmark of CWRU dataset, where the physical meaning of domain labels can be clearly defined.",
        "weaknesses": "1. The paper\u2019s writing and formatting are not good enough, making it sometimes hard to read and understand. There exist many formatting errors (e.g., the use of spaces in Sections 1 and 2, the math symbol consistency in Section 4.1: P(1) and P^{(K)}). The caption of Figure 1 is duplicated. The abbreviation in Paragraph 3, Section 2 might be RAP. In the second line of paragraph in section \u201cDistribution Law Conjecture\u201d, F_p should be the the mapping relation between features, not labels.\n2. Besides the ones from 1., the Experiment part (e.g., paragraph 4 in \u201cClassical Model Contrast\u201d part) is hard to understand. Bad formatting and discontinuous sentences make it unreadable to me.\n3. Key references are absent. In the first paragraph of Section 4.2, methods aligning the three types of distributions should be cited to justify the categorization. The compared methods in \u201cComparison with Classical Models\u201d should also be referred to, and the Li et al. (2018) reference in this paragraph is wrongly cited, this paper should be \u201cDeep Domain Generalization via Conditional Invariant Adversarial Networks\u201d.\n4. As to the experimental results, the metric of Table 1 is not clearly stated. Also, the experimental details like backbone choice, learning rate, optimization schedules are not provided.\n5. The setting is still too limited. The current method and experiments only focus on generalizing from highly relevant and sequential source domains to a target domain close to the last seen source domain. The performance of the proposed method should be further evaluated on broader settings where the relationship of source and target domains is not fixed. Also, the setting seems much relevant to that of Continuous Domain Generalization, which should be discussed.",
        "questions": "Apart from those in weakness, the authors are encouraged to experiment on larger domain generalization benchmarks. Moreover, the compared methods are not recent enough, therefore more experiments should be added to provide a more comprehensive comparison.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper proposes a feature shift network (FSN) for a new domain generalization task called load-domain (LD) generalization based on analyzing the CWRU-bearing dataset. The key idea is to leverage domain labels to shift target features into adjacent source domains. The method is evaluated on the CWRU and rotated MNIST datasets by comparing them to existing domain generalization techniques.",
        "strengths": "The application of domain generalization on the problem of fault detection is novel.",
        "weaknesses": "The paper lacks novelty as feature shift is explored in prior work. The theoretical analysis relies on unproven conjectures and lacks rigor. More comprehensive empirical evaluation on realistic datasets and comparisons to recent benchmarks are needed to demonstrate effectiveness.",
        "questions": "The novelty of the proposed feature shift network (FSN) is questionable given prior work on feature shift for domain generalization. The current paper does not sufficiently differentiate FSN from these existing methods. \n\nThe paper also lacks theoretical analysis regarding the generalization abilities of FSN.\n\n Empirically, evaluation is limited to two small datasets, which cannot sufficiently demonstrate effectiveness and robustness for the load-domain generalization task. More extensive testing on diverse realistic datasets are needed.",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "The paper addresses a challenge in deep learning-based fault detection, where real-world faults may not always appear in the training set. This limitation makes it difficult for conventional models to generalize well to unseen fault patterns. To address this, the authors introduce a domain generalization method, Load-Domain (LD) domain generalization, specifically designed based on the CWRU bearing dataset. In this method, the domains are divided based on different operating conditions that have specific loads, which correspond to the actual load magnitude. This inclusion of physical information helps enhance the model's accuracy for unknown domains. The authors propose the Feature Shift Network (FSN), which is trained to shift features between adjacent source domains and the target domain for better generalization. The effectiveness of FSN is shown through experiments on both the CWRU bearing dataset and the MNIST dataset, where FSN outperforms existing methods.",
        "strengths": "+ The authors tackle a crucial issue in fault detection where conventional models may not perform well on unseen fault patterns.\n+ This novel domain generalization approach, based on real physical properties (load magnitude), can potentially be more representative and robust than abstract or purely data-driven domain divisions.\n+ The model's applicability on both the CWRU bearing dataset and the MNIST dataset suggests it is versatile and not limited to one type of data.\n+ The authors compare their model with classical fault diagnosis methods, showing its superiority in specific scenarios.\n+ The paper appears to have a well-structured format, with sections dedicated to reviewing the current state of research, introducing their novel domain generalization method, and discussing experimental results.",
        "weaknesses": "- The assumption that domain label corresponds to actual load magnitude might not hold for all real-world scenarios. It may be beneficial to test scenarios where this is not the case.\n- Introducing domain-specific information like load magnitude could risk overfitting to specific domain characteristics. The generalization capability of the model in truly unseen domains is a concern.",
        "questions": "- How does the Load-Domain (LD) domain generalization approach compare with other domain generalization methods that don't rely on physical information like load magnitude?\n- Are there potential scenarios where the assumption of domain labels corresponding to actual load magnitude may not hold? How would FSN perform under such conditions?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "9ceadCJY4B",
    "title": "Ask Again, Then Fail: Large Language Models\u2019 Vacillations in Judgement",
    "reviews": [
      {
        "summary": "This paper explores testing the judgment consistency of conversational LLMs (e.g., ChatGPT) by using follow-up questions that express disagreements/doubts and challenge the model's response. Across a range of reasoning benchmarks, the authors find that modern conversational LLMs (e.g., ChatGPT, PaLM2-Bison, Vicuna-13B) are vulnerable to such disturbances, changing their beliefs into wrong answers for a large portion of examples where they can generate correct initial solutions. The authors also experimented with different settings including sampling temperature and prompt choices, and found that despite occasional improvements, such an issue largely remains.",
        "strengths": "- The paper is overall well-written and easy to follow.\n- The experiments are quite comprehensive, covering a wide range of reasoning tasks and LLMs. The findings are also consistent across different models and tasks, suggesting that what's found in this paper is a rather systematic issue of current (conversational) LLMs.\n- The analysis of the impact of different settings & alternative prompt designs on the model behavior could be interesting and valuable to the community.",
        "weaknesses": "- The overall novelty of this work is a bit limited given that prior work (many of which are also cited by the authors) has investigated the \"sycophantic\" behavior of LLMs, and the proposed methods in the paper are quite similar to the ones in prior work. For example, the paper by [Turpin et al.] which the authors seem to miss studies LLM's behavior when there exists bias in the context, where one of the settings is exactly about putting human user's belief (in a wrong answer) in the context, which is close to the type L (leading questions) prompt explored in this paper. Similar findings are also present in [Perez et al., 2022] as cited. [Wang et al., 2023a] as cited explores using another conversational LLM conditioned on a wrong solution to engage in a debate with the original LLM; the \"follow-up\" responses by the simulated user there also share many similarities with the ones proposed (expressing disagreement, doubt, different opinions, etc.).\n- The qualitative analysis misses some rather important details such as the proportion of each error category. While there are some discussions/insights about the issue in the paper, overall, as an analysis/evaluation type work, I feel the contribution could be strengthened if more fruitful thoughts/speculations about the underlying cause of the observed issues (and potential ways of mitigating them) are included.\n\n\n[Turpin et al.] Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting. arXiv-23.",
        "questions": "None",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The research addresses a critical concern in the use of generative conversational large language models (LLMs) like ChatGPT, focusing on their judgement consistency when faced with follow-up questions expressing skepticism or disagreement. Drawing inspiration from educational questioning strategies, the study proposes a FOLLOW-UP QUESTIONING MECHANISM and introduces evaluation metrics to assess LLMs' consistency before and after disturbances. The study evaluates ChatGPT, PaLM2-Bison, and Vicuna-13B across reasoning benchmarks, revealing a decline in judgement consistency even when initial answers are correct. The research explores the impact of disturbances, sampling temperature, and prompts, conducting an in-depth error analysis. Moreover, it introduces and evaluates various prompting methods to mitigate this issue, demonstrating their effectiveness.",
        "strengths": "- **Comprehensive Evaluation**: The research evaluates multiple LLMs (ChatGPT, PaLM2-Bison, and Vicuna-13B) across eight reasoning benchmarks, ensuring a comprehensive analysis of their performance under different conditions.\n- **Thorough Analysis**: The study conducts a detailed analysis of disturbances, sampling temperature, prompts, and prompt tone, offering valuable insights into the factors affecting judgement consistency.\n- **Effective Solutions**: The research explores various prompting methods and demonstrates their effectiveness in mitigating the issue, suggesting practical solutions for enhancing LLMs' reliability.",
        "weaknesses": "- **Limited Scope of LLMs**: The study evaluates a specific set of LLMs (ChatGPT, PaLM2-Bison, and Vicuna-13B), potentially limiting the generalizability of the findings to other models in the rapidly evolving landscape of conversational AI.\n- **Scope of Disturbances**: While disturbances like questioning, negation, and misleading are considered, the study might benefit from exploring a wider range of disturbances to provide a more comprehensive understanding of LLMs' judgement consistency challenges.\n- **Lack of Real-World Application**: The research focuses on theoretical evaluation and proposed mechanisms; it would strengthen its impact by discussing practical implications and real-world applications of the proposed solutions.",
        "questions": "- Considering the rapid advancements in AI technologies, how might the results differ when applied to newer or upcoming LLMs? Is there room for future research to address this limitation?\n- Can you provide insights into how the proposed mechanisms and solutions could be practically applied in real-world scenarios, especially in fields where LLMs are extensively used, such as customer support or healthcare?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper investigates the problem of answer consistency in large language models (LLMs), especially when prompted with questioning, disagreement, or misleading input. The authors designed a follow-up questioning mechanism, inspired by questioning strategies in education, to experiment with LLMs. After an initial correct response, the authors attempted prompts of questioning, disagreement, or misleading input in two different ways, one of the three and all of the three in a sequential manner. The authors conducted experiments on ChatGPT, PaLM2-Bison and Vicuna-13B using four kinds of objective reasoning questions: arithmetic reasoning, commonsense reasoning, symbolic reasoning, and knowledge reasoning. They found that a significant decrease in judgement consistency occurred after the models were prompted with questioning, disagreement, or misleading input, both in isolation and in sequence. The authors also tried some mitigation methods, but there is still room for improvement",
        "strengths": "- The paper is clearly written and easy to follow. \n- It addresses the critical issue of trustworthiness in large language models. \n- The well-designed experiments and mitigation approaches clearly demonstrate the problem of LLMs and draw attention to its importance.",
        "weaknesses": "- I do not see a major problem with the paper. While some people may prefer a paper that proposes a new model, this investigative paper could still be a valuable contribution to the field.",
        "questions": "1. I didn't understand the second sentence in footnote 1.\n\n2. Modification Rate (M. Rate) was not clear to me.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "BXYZvcgVUv",
    "title": "Object-Relational Graph Framework for Zero-Shot 3D Scene Segmentation",
    "reviews": [],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "gYcft1HIaU",
    "title": "Do Current Large Language Models Master Adequate Clinical Knowledge?",
    "reviews": [
      {
        "summary": "The paper introduces a large-scale medical disease-based knowledge base MedDisK, covering 10,632 common diseases and 18 clinical knowledge to evaluate LLMs. The purpose of the dataset is to  (a) include common diseases (b) involve disease base knowledge and (c) ensure that the sourcing of the dataset is such that it remains publicly inaccessible to prevent leaks during testing.\t\n\nFirst filter common diseases (determined by clinical experts based on ICD10 databases and frequency in EHR)  resulting in 10,632 common diseases. Then  employ clinical experts to define 18 disease-based clinical knowledge aspects that are crucial to medical decision-making (diagnoses, examinations, treatments) for each of the diseases. They use this database to probe LLMs and evaluate the mastery of clinical knowledge. They show that their scoring measures are in high agreement with clinical experts' subjective evaluation.  \n\nUsing the evaluation metrics they show that existing LLMs have not mastered adequate knowledge for clinical practice (showing that over 50%  of the generated information is not consistent with their KB) and are not ready to be foundation models for clinical domain.",
        "strengths": "The paper does a good job in communicating the ideas. I agree with the author's motivation that for the LLMs to be accepted as foundation models they need to have mastered adequate clinical knowledge. This is an important question and needs comprehensive evaluation.",
        "weaknesses": "The paper could provide a more thorough justification for the introduction of the new medical dataset, especially in the context of existing evaluation datasets. The paper mentions that the existing evaluation datasets cover only some common diseases and lack extensive coverage of knowledge across various aspects of diseases. This reviewer feels that this needs to be substantiated with more thorough comparison. \n\nWhile it is surprising that most of the LLMs perform poorly (with over 50%) predicted to be completely wrong. The evaluation procedure used to arrive at this conclusion requires further elaboration.\n\nOverall I am not fully convinced that this dataset MedDisK  and the outlined evaluation procedure is robust for determining LLMs clinical knowledge yet. \n\nThis reviewer has listed all the concerning questions in detail below.",
        "questions": "What is the source of the EHR resource used in the preliminary making of the dataset?\n\nThe authors state \u201cThe existing medical evaluation benchmarks are predominantly based on question-answering (QA) tasks. These benchmarks collect questions from diverse sources, including medical examinations, electronic health records, online resources, and expert crafting\u2026\u2026cover only some common diseases and lack extensive coverage of knowledge across various aspects of diseases. \u201d  Can you compare each of these resources the paper is referring to in this sentence with MedDisK in terms of coverage of common diseases, disease base knowledge and public availability?  How does this compare with other existing medical relational databases - MIMIC, i2b2, iBKH KG etc?\n\nI understand that the paper does interval sampling (10 examples from each interval) and engages clinical experts to provide a categorical standard - wrong, correct or partially correct.  And this resulted in the following standard (0-0.3 is wrong) and (0.3 to 0.8 is partially correct) and (0.8 to 1.0 is correct). How representative are these categories? Did the experts find that all the samples in 0.8 to 1.0 are correct and correspondingly all in 0-0.3 are wrong? Can you provide more representative examples or more thorough classification of the \u201cCompletely Wrong\u201d category?\t\n\nSince LLMs response is post-processed using the NER model I think the NER model's performance is extremely crucial to evaluation. How well does it perform in identifying medical entities? From the analysis conducted in Table 8, it appears that all the LLMs are underperforming in identifying symptoms, affected sites, etc., while they generally perform well in recognizing population ages involving numeric entities. \n\nWould it be considered a correct hit if the model predicts 'GI tract' instead of 'digestive system' in the examples from Table 3? What kind of standardization was performed in evaluating LLMs response with the experts output?\n\nWhat according to the authors are the limitations of the dataset and the evaluation procedure outlined here?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "To evaluate whether LLMs have mastered sufficient clinical knowledge, the authors first propose a large-scale medical disease-based knowledge base named MedDisK. They then develop MedDisKEval, a method that prompts LLMs to retrieve information on clinical knowledge aspects and measures the similarity between LLM-generated information and MedDisK. Results show that most of the current LLMs do not have sufficient clinical knowledge.",
        "strengths": "1. The motivation is clear, and it is interesting to know whether current LLMs have mastered sufficient domain knowledge to help in the medical domain.\n2. The authors conduct extensive experiments with 12 LLMs, which include general LLMs and medical LLMs.\n3. The authors provide sufficient examples of prompt instructions, knowledge aspects, and LLM responses, which make it easier for readers to grasp the basic idea of the paper.",
        "weaknesses": "1. One significant issue with this paper is that the authors may overstate the implications of their evaluation results. The experiments are exclusively conducted in Chinese. However, this critical detail is not adequately emphasized in the main paper, particularly in their conclusion that \"none of the evaluated LLMs have mastered sufficient knowledge to handle real clinical problems effectively.\" Based on their evaluation, the valid conclusion should be that LLMs do not possess adequate clinical knowledge **in the Chinese language**, and this finding cannot be generalized to other languages.\n\n2. In the second paragraph of the introduction, the authors claim that current QA-based medical evaluation datasets cannot evaluate whether LLMs have mastered sufficient medical knowledge because those datasets cover only some common diseases. It would be more robust if the authors could further justify this statement with some analysis (e.g. to quantitatively show the coverage of diseases in the existing benchmarks).\n\n3. For the proposed knowledge base MedDisK, it would be better for authors to include more details of the construction process. For example, how is the agreement among the clinical experts, is there any strategy used to tackle disagreement, and will this process introduce any additional human bias?\n\n4. In section 3.2.1, the authors \"employ a specialized NER model to identify and extract medical entities from the text\". However, the exact name and citation of the used NER model are missing, and it will be more convincing to include an analysis of the accuracy of the NER model as incorrectly recognized entities could impact the evaluation results of LLMs.",
        "questions": "1. The authors claim that current QA-based medical evaluation datasets cover only some common diseases. However, in section 3.1 where the authors introduce their proposed knowledge base, it is said that \"We first select a subset from the ICD10 database according to whether the diseases are common in clinical (determined by clinical experts) and are statistically frequent in EHR (Electronic Health Record), resulting in 10,632 common diseases.\" I wonder why they also consider common diseases in their knowledge base?\n\n2. In the section of \"Disease-Knowledge-based Automated Scoring\", are there any better metrics to evaluate the similarity? The token-level BLEU-1 and ROUGE-1 cannot consider semantic meaning, and the M3E model is described as a sentence-level metric, whereas the evaluation in this context focuses on the meaning of individual tokens.\n\n3. In Table 3, one completely wrong example of LLM response is \"ok, I see\". Since the authors mention that they employ a specialized NER model to identify and extract medical entities from the text, I wonder why the NER model could extract such words from the responses.\n\n4. In section 4.2.2, the authors assign scores of 0, 5, and 10 to \u201dCompletely Wrong,\u201d \u201dPartially Correct,\u201d and \u201dBasically Correct,\u201d respectively, to calculate a total score. It's important to clarify how they arrived at the values \"0, 5, 10\" for this scoring system.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper evaluates the current performance of medical LLMs by creating a benchmark and testing existing said LLMs against it. This work creates MedDisK, a database designed to test the medical knowledge of LLMs on different \"clinical knowledge aspects\". These properties are not limited to those used just for diagnosis; example properties include patient population, treatment principles, departments (relevant medical departments), etc. This work also introduces MedDisKEval, a method that includes automated and clinical-expert-dependent steps to grade the performance of LLMs. Notably, the paper concludes that most current medical LLMs do not perform better than the base LLMs they are built upon.",
        "strengths": "* The development of a medical knowledge benchmark involved consulting 20 clinical experts over 10 months is good. This paper focuses largely on Chinese data/expert consult, but the presentation itself features relevant English translation.\n* Creating a clear evaluation method combining automated/expert consultation is also useful. \n* The conclusions of the evaluation point out specific flaws in existing medical LLMs; certain models evaluate different features poorly, for example. This provides a concrete criticism/evaluation of those methods that can be built upon.",
        "weaknesses": "* The creation of a medical LLM benchmark itself does not make fundamental improvements over existing benchmarks developed in medical LLM research. As an example, the Singhal et al. 2023a paper also tested modern LLMs with human evaluation (MultiMedQA). Creating another benchmark by itself is not a conceptually novel improvement, and this work did not sufficiently argue for its improvement above these existing models/evaluations.\n* This work does not go into as much detail about the representation of medical knowledge in LLMs, providing only a benchmark without technical insight of what the LLMs might be doing or how they encode medical information.\n* Using MedDisKEval seems expensive or possibly unreliable. Someone seeking to use this evaluation method may need to consult expert opinion themselves, just to calibrate the alignment scores. The motivation behind the linear combination of BLEU-1, ROUGE-1 and cosine sim is empirically driven and is not inherently convincing as a metric.",
        "questions": "* The database MedDisK was constructed with \"clinical experts and machine assistance.\" Further clarification is required; what was the exact process of constructing the database, and how was machine assistance used? \n* This work focused on a set of LLMs that is somewhat disjoint from existing popular medical LLMs. For example, MedPaLM?",
        "rating": "3: reject, not good enough",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "10eQ4Cfh8p",
    "title": "SIMULTANEOUS GENERATION AND IMPROVEMENT: A UNIFIED RL PARADIGM FOR FJSP OPTIMIZATION",
    "reviews": [
      {
        "summary": "The paper introduces a reinforcement learning framework tailored for the Flexible Job Shop Problem (FJSP). The methodology leverages graph neural networks, allowing the model to handle FJSP instances of varying scales. The main novelty consists of simultaneous generation and improvement: a generative model sequentially produces solutions while an improvement model refines them. Both models are trained concurrently via reinforcement learning. The approach is at least an order of magnitude faster than metaheuristics and outperforms dispatching rules and some previous RL approaches in terms of solution quality.",
        "strengths": "The tackled problem is important in several practical scheduling applications. Unlike previous approaches that either only generate solutions in one shot or only learn to improve, the proposed approach trains two models to generate and improve at the same time, which could potentially provide the \u201cbest of both worlds\u201d, i.e., speed of one-shot generation and solution quality of improvement methods. The proposed two-stage approach and training is novel for scheduling problems to the best of my knowledge.",
        "weaknesses": "My biggest concern is that the proposed approach seems to be only applicable to a specific scheduling problem (FJSP) with no variation in terms of constraints. In the abstract, the authors state that:\n\n> It is worth noting that this training paradigm can be readily adapted to other combinatorial optimization problems, such as the traveling salesman problem and beyond.\n> \n\nhowever, there is 1) no empirical evidence to justify the claim and 2) no explanation of *how* this can actually be done. For instance, how can the improvement step be applied to the traveling salesman problem (TSP), especially considering the reward function? In several combinatorial optimization problems, it is hard to define a step-wise reward function, such as in routing problems such as the TSP. Moreover, the specific design of Section 3 seems to be over-fitted to the FJSP, with new problems requiring a substantial restructuring of the model.\n\nAnother important point is that the proposed generation-improvement method is not well justified in terms of performance. There is no ablation study on just using the generator model without any improvement:\n\n> From the design of our framework, it can be seen that the generative model and the improved model can run independently, which means that we can only use the generative model to generate a complete solution or use the improved model individually to improve any feasible initial solution generated by other methods (such as random generation or PDRs).\n> \n\nbut there is no result about this; in Table 3 only the improvement method alone is shown with other models. How would the `generate` only perform? Moreover, a natural question would arise, namely why authors decided to go for a potentially more burdensome generate+improve method (in which the generator may potentially be worse due to over-reliance on the improvement model), and not just a generator. In these regards, it would be interesting to see how the same model with the generation part only would do.\n\nThe experimental section seems to be lacking some baselines - for instance, Table 1 only compares against OR-Tools and dispatching rules, but not against RGA and 2SGA and the 2 DRL baselines. Also, OR-Tools is missing the solution time, so it is difficult to assess how the proposed approach compares in solution time (given that the quality is already worse than the OR-Tools metaheuristics). Finally, no standard deviation has been reported nor multiple runs.\n\nIn terms of the quality of the paper, there is room for improvement. Aside from several typos, the writing feels sloppy, and there are missing references (`(ref)`  in the paper, mk[?] in Table 2 and more), so I would suggest some revision. More importantly, in Algorithm 1:\n\n> Store Transition $\\tau_{t+1}^g :< \\mathcal{S}_t; ~ \\mathcal{S}_{t+1} > \\text{into} ~EP_I$\n> \n\nI believe this should be, in fact, $EP_I$ , given that $EP_G$ is not being used here.\n\nFinally, no code has been provided to reproduce the results.",
        "questions": "1. Why did you decide to use DuelingDQN, and not actor-critic algorithms such as PPO [29] or policy gradient methods as done in MatNet [17]*?\n2. As in the \u201cweaknesses\u201d section, how would the model perform if only the generator was trained? And what if we trained with generator+improve but only used the generator for the solution?\n3. What is the number of improvement iterations $n_t$, and how was it selected?\n4. How would the proposed method fare in larger-scale instances? [29] studies scale up to $100 \\times 60$.\n\n---\n\n*Note: MatNet [17] is cited in the manuscript but not referenced throughout the text. It may be useful to at least briefly introduce the differences with the proposed method in the related works.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes an end-to-end RL framework to solve the Flexible Job-Shop Problem (FJSP). The framework consists of two major components: a generation model that produces an assignment of operations that updates the partial solution, and an improving model that refines the current partial solution. By repeating the generation and improving steps until the complete solution is found, the proposed framework finds a solution for FJSP.\n\nThe authors evaluate the proposed framework with various-sized FJSP instances, and it is shown to outperform compounded Priority Dispatching Rules (PDR) but underperform Meta-heuristics (e.g., OR-tools).",
        "strengths": "- The proposed framework suggests a novel perspective for solving FJSP. Unlike the majority of iterative improving approaches that often perform improvement steps from a complete solution, the proposed framework employs \"improving\" actions during solution construction.",
        "weaknesses": "- The current manuscript still has room for improvement, including a more detailed explanation of the training.\n- The performance evaluation of the proposed framework seems quite limited, especially as the baselines are overly simplified in Table 1.",
        "questions": "- It seems the number of improvement iterations $n_t$ would play a crucial role within the proposed framework. Could the authors provide further details on how to decide $n_t$? In the current manuscript, it is simply mentioned as a hand-crafted function depending on the iteration index $t$.\n- What is GIM in Table 3? From the context, I assume it is the proposed method, but the acronym is never introduced.\n- What is \"Generate+improve\" in Table 3? Is it different from GIM?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes an RL based scheduling methods for Flexible Job Shop Problem. The approach empolys two graph neural network models, a generative model and an improvement model, which collaboratively solve the problem. At each timestep, the generative model progressively constructs a partial solution by adding a new component into the existing partial solution, and the improvement model refines this partial solution for better performance. Both models are designed to leverage inductive biases from the problem and its current partial solution, e.g., neighbor nodes from different types of edge. The models are trained end-to-end using the reward signal for each model, in an alternating manner to stabilize the learning of two models.\n\nThe proposed algorithm is evaluated with two experiments, one for synthetic datasets and the other for public benchmarks, and it showed superiority over several heuristics and DRL-based methods in terms of solution quality. Also, though the method failed to outperform the meta-heuristic algorithms, it showed comparable result while spending much less time than the meta-heuristics.",
        "strengths": "- This work proposed a new RL-based framework for solving FJSP, which combines the construction and the improvement processes so that they can be trained in end-to-end manner.\n- The method utilizes different graph representation that corresponds to a single partial solution, providing each model with relevant information. This approach is both interesting and convincing. \n- Ablation study for the two distinct models provides a good empirical evidence for the proposed architecture.",
        "weaknesses": "[Methods and Experiments]\n- This paper doesn't provide a clear rationale or justification for the use of various embeddings. Also, there's no ablation study for these design choices.\n- The method is evaluated only two public benchmarks, whereas the DRL baseline [1] has been tested on a more extensive set of benchmarks. This raises concerns about the comprehensiveness of the evaluation and potentially limits the generalizability of the proposed method's performance.\n- The reported performance of DRL baseline [1] is based on the greedy selection, while the method of this paper leverages sampling for improvement steps. For fairer comparison, the results from both greedy and sampling decoding should be included. Note that sampling performance reported in [1] for v_la task is better than the proposed method, while consuming more computation time.\n\n[Writings]  \nThis paper has significant defects with clarity. \nFirst of all, there are too many typos, wrong spacing and inconsistent notaions. Below are some of them:  \n- page 1: 'PRD' \u2192 'PDR'\n- page 2: There are many wrong spacing in Sec. 2, e.g, 'O_i,which', 'operations,O_{ij}', or \"...end of production.These two ...\"\n- page 3: There is a wrong figure reference, '(in figure)' \n- page 4: 'avenger' \u2192 'average'\n- page 4: GAT has no reference\n- page 5: 'avitation' \u2192 'activation'\n- page 5: 'M_{ij}' suddenly pops up, which supposedly typo of {A_I}_{ij}, and suddenly A_J is used, which is definitely a typo.\n- page 7: In the Algorithm 1, 'EP_I' \u2192 'EP_G' for the transition of generative model.\n- page 7: There are several '(ref)'s in Sec 5.1, which should have been replaced by appropriate reference.\n- page 8: In the text they say they use Gurobi Solver, but they report OR-Tools in the table.\n- Throughout the paper, the authors use abbreviations without declare it, e.g., DRL in page 3, GAT in page 4, and GIM in page 7 (Algorithm 1)\n\nMoreover, the models are not clearly described, which makes it hard to fully understand the algorithm.  \nFor example, in GAT Module section in page 5, it is unclear whether W is shared among different u's or not.  \nAlso, the reward for each model is not stated mathematically, which introduces an ambiguity.\n\n[1] Song, Wen, et al. \"Flexible job-shop scheduling via graph neural network and deep reinforcement learning.\" IEEE Transactions on Industrial Informatics 19.2 (2022)",
        "questions": "- How long it takes for training?\n- Why the 40 x 10 result is missing for OR-Tools?\n- How can this work be extended to other scheduling or CO problems?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The author proposed a deep reinforcement learning model to address the FJSP problem. This approach involves the simultaneous application of construction heuristics and improvement heuristics, enabling it to achieve better performance in shorter time on several public datasets.",
        "strengths": "- Based on the claim of paper, it seems good to use construction heuristic to construct a better partial solution and use improvement heuristic to improve the partial solution.",
        "weaknesses": "- Actions (in Section 3.1) are critical, but not defined clearly. I have no problems with actions for construction heuristics, but actions for improvement heuristics are not well defined. In Section 3.2 \u201cInsertion Position Embedding\u201d (P5), the definition of insertion position is undefined clearly, and why the number of choices is (n+m) for each operation. Besides, it is also unclear about why the total number of insertion positions is equal to n\u00d7(n+m). For these unclear descriptions, there is no clue to understand the proposed method. Note that in Section 3.2 \u201cPolicy Model\u201d (P6), there is no way to understand the description \u201cObviously, there are at most m different insertion schemes for each improvement decision.\u201d\n\n- Figure 2 is confusing and unconvincing. For example, why is 31 moved to the position after 11, not before 11? If it can also be moved to that before 11, I don\u2019t see the strategy.\n\n- The representation of operations is inconsistent and thus makes it hard to understand how the Insert Position Embedding works (There are $O_{ij}, O_j, O_{j(i)}, O_i$ in the article).\n\n- Lack of test results for public benchmark dataset. With comparison to [29], you should also compare with la(edata) and la(rdata). And you may test on the dataset which is referenced by [29] to improve the reliability of your method.\n\nPresentation comments: \n- Lack of spaces in many places. E.g., \u201cBoth the generative model and the improvement model will use formula(4) to select the action to be executed in the current state st at step t on their respective feasible action sets.The advantage value function is fitted by a parametric MLP\u201d \n\n- In section 5.1, \u201c In addition, we also used (ref1),(ref1),\u201d, and \u201cmk [? ]\u201d in Table2. Please carefully check the content.\n\n- In Algorithm1, \u201cE%K\u201d => \u201ce%K\u201d, the second \u201c$EP_I$\u201d => \u201c$EP_G$\u201d, etc. There should be more that you need to find out for fixing. \n- There is no data in some places in the tables, such as 40x10 for OR-Tools in Table1 and mk[?] for UB* in Table2.",
        "questions": "- I am still wondering about your method for the Machine Process Queue Embedding:\nIs $M_{ij} = 1$ if $O_j$ is processed on Machine $i$, or $O_j$ \u201ccan be\u201d processed on Machine $i$? What is the concept of model designing (or why it is designed in this way)?\n\n- It\u2019s not clear that \u201cJob Sequence Embedding\u201d, if $O_{ij}$ ($j$-th operation of Job $i$) is processed then $A_J(J_i, O_{ij})$ = 1?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "NFqFA2vCQV",
    "title": "AdaptIP: Transferring Cross-modal Information to Temporal Modeling for Video-Language Representation Learning",
    "reviews": [],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "BQvbL2sFQx",
    "title": "Model-Agnostic Shift-Equivariant Downsampling",
    "reviews": [
      {
        "summary": "The authors propose and implement MASS, a method for downsampling that is exactly equivariant to shifts in images, making CNN networks exactly equivariant (or invariant) with respect to this symmetry in their downstream tasks (which are typically image classification). The method is implemented in a \u201cmodel-agnostic way\u201d, and can be used to invariantize pre-trained CNNs. Its performance is demonstrated on standard data sets.",
        "strengths": "The problem of imposing exact shift equivariance (in CNNs) is important in current literature and applications. The proposed solution is simple, robust, and easily applicable to pre-existing methods.",
        "weaknesses": "Main\n* The algorithmic/mathematical presentation should be clearer. Occasionally notation appears that has not been precisely defined (e.g. $S_o$ on pg. 4 or the use of the $y$ variable). I specifically find Figure 1 hard to understand. \n\n* A substantial effort is made to separate the proposed method from general polyphase sampling, but the exact reason behind the latter\u2019s \u201cperformance degradation\u201d should be explained more rigorously, as this is what would set it apart in applications.\n\nMinor\n* There are several typos, and all acronyms need to be defined upon first appearance.",
        "questions": "Regarding the choice of selection rule:\n* In what way does the choice of function matter? Can it be determined adaptively, if the noise distribution is known?\n* And finally, is it always possible to find a good function regardless of the level of noise?",
        "rating": "8: accept, good paper",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper presents an approach to shift equivariant up- and downsampling in convolutional neural networks.",
        "strengths": "- The paper presents a very compelling motivation for shift equivariance based on industrial applications\n- The paper seems to provide the shift-equivariant scheme that is consistent by design and also compatible with multiple architectures\n- The proposed approach in principle could be used without fine-tuning if some accuracy loss is acceptable, unlike some other methods in the literature",
        "weaknesses": "- The description of theory is not at all clear, especially the part related to figures. Maybe if I read this paper 2 or 3 times, I will eventually understand what color schemes imply in Figures 1,2,4. But I want to be able to understand this from the first glance. Figures should serve the purpose of clarifying things and not making them more obscure. Without the explanation of what colors are supposed to signify and explain in the figures - it is impossible to quickly understand what they are supposed to clarify.\n- The compelling motivation for shift equivariance is not supported by problem specific datasets. All experiments are done on generic datasets. CIFAR-10 does not seem to fit the motivation at all with its 32x32 images. It seems like a misfit for the purpose of the paper. I expect that the industrial applications involve high-resolution imagery. If authors can provide results on high-resolution datasets, especially from the industrial domain this will make the results a lot more compelling. There is a recent dataset described here: https://arxiv.org/pdf/2303.06673.pdf. I am sure that more search will reveal more datasets like this. I remember encountering similar problems on kaggle.\n- Consistency metric defined in equation (4) does not make any sense to me. What does it measure, what is x and y? Is it pointwise pixel match, if so, why there is no summation over pixels? One of the closing brakets is missing.\n- Baselines used in experimental tables are not explained well. As a result, the experiments do not seem persuasive\n    - What is the reference for DDAC and LPF?\n    - Why LPS is not included in Tables 2,3?\n    - Why Table 3 does not contain same baselines as Table 2? It seems that a few of the baselines in Table 2 are very effective. It may well be that APS with enhancements presented in Table 3 might be as effective or better than MASS?\n- Results in Table 2 are marginal and statistically insignificant. To me, the value of this result is approaching 0, because most confidence intervals overlap. It does not make sense to use bold font to signify the best model, when the best model is not significantly different than another model.\n- From Tables 2-4, I do not see a decisive value of the proposed approach with respect to other approaches such as LPS-DDAC-3 or ASP-DDAC-3. Why do we need this approach, what is the value?\n- I am not sure I see value in using the pretrained version of any of the approaches discussed in the experimental section. What is the point, can you explain in detail the actual use case? When the networks are fine-tuned properly, many of them achieve very similar results.\n- Table 5 confirms previous concerns.",
        "questions": "- page 2: missing reference. \"2016; ?), and group operations\"\n- page 6: typo \"Schemetic of MASS\" -> \"Schematic of MASS\"?\n- is your approach compatible with visual transformers?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The proposed work suggests a downsampling technique that is shift equivariant by equivariant origin alignment. This method is well suited for adapting to the existing layer and can utilize the weights of pre-trained models. Moreover, the proposed models outperformed other shift equivariant techniques without introducing more learnable parameters.",
        "strengths": "The proposed method achieves perfect shift equivariance and performs better in classification tasks, even without any learnable sampling parameters (compared to the LPS). It is also well-suited for reusing pre-trained weights.",
        "weaknesses": "1. The proposed method resembles building equivariant layers with canonical functions [a]. The proposed method can be seen as a special case of the mentioned work for shift equivarinace. This limits the contribution of the paper. \n\n2. The benefit of the proposed technique compared to the existing method (APS, LPS) is poorly described.\n\n3. The improvements are marginal.\n\n\na. Equivariance With Learned Canonicalization Functions",
        "questions": "1. Figure 2 caption: \u201cOn the other hand, in the case of polyphase sampling, only data from specific regions is retained, which may result in potentially suboptimal representations. MASS-Max-pool combines the advantages of selecting suitable representatives and ensuring shift equivariance.\u201d\u2014 I do not entirely understand the statement. We can perform convolution with max filter followed by LPS. What is the extra benefit of MASS-Max-pool?\n2. Section 4.1 \u201c there exist only $s^2$ unique sampling origins represented as o \u2208 {(0, 0),(0, 1), ...,(s, s)}.\u201d \u2014 should it be \u201c{(0, 0),(0, 1), ...,(s-1, s-1)}.\u201d?\n3. While training from scratch as the MASS-Max-pool shifts the input to match the new calculated origin, does it likely introduce unwanted data augmentation? Especially if the pooling window is large.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper addresses the problem of how to preserve shift-equivariance property for convolutional neural networks. Specifically, the authors merely consider circular shift operation over the input image sample, and simply extend an existing method APS (adaptive polyphase sampling, proposed by Anadi Chaman and Ivan Dokmani\u0107 in their CVPR 2021 work) by incorporating a pre-defined selection function for determining the origin which can accurately fit the shift operation. Experimental validation is conducted on image classification and semantic segmentation tasks.",
        "strengths": "+ The problem, i.e., how to preserve shift-equivariance property for convolutional neural networks, is critical.\n\n+ The proposed method is simple and hand-crafted even though its implementation is not clear.\n\n+ Comparative experiments are conducted on both image classification (with CIAFR-10 and ImageNet-1K datasets) and semantic segmentation (with PASCAL VOC dataset) tasks.",
        "weaknesses": "- The method and presentation.\n\nIn this work, although the authors addresses a fundamental research problem, how to preserve shift-equivariance property for convolutional neural networks, the proposed method called MASS is rather incremental, lacking new tech insights. To the best of my knowledge, MASS is merely a simple modification of existing work APS (adaptive polyphase sampling) proposed by Anadi Chaman and Ivan Dokmani\u0107 in their CVPR 2021 paper. Specifically, the authors use a pre-defined selection function for determining the origin with ASP which can accurately fit circular shift operations over the input image sample.  Generally, I have not seen any insightful differences against APS. \n\nThe presentation of the method is poor: 1) usually no explanations for notations and terms appeared in formulas; 2) no explanations/details on the formulation of the proposed MASS; 3) rather coarse descriptions for Figure 1 and Figure 2; 4) some sub-figures are wrong, e.g., two sub-figures for MASS in channel 1 of Figure 1 are not consistent to the others.\n    \nThe writing of the paper is also poor. Please see my comments in \"Others\" part for details.\n\n- The limitations.\n\nThe authors did not discuss on the limitations of the proposed method.\n\n- The experiments.\n\nNote that the authors claim that the pre-defined selection function for determining the origin can accurately fit the shift operation. However, the authors did not provide any details on how to implement it in experiments. This makes experimental comparison confusing. \n\nComparison is limited to APS.\n\nExperiments are not convincing. On CIFAR-10 dataset, the proposed MASS brings very marginal gains to APS. On PASCAL VOC dataset, MASS performs worse than APS. However, on ImageNet-1K dataset, MASS is much better than APS. What are the root reasons? \n\nThere is no ablation to study how does the proposed method MASS work. \n\nHow about the performance of MASS under other shift operations to the input image sample instead of circular shift operations?\n\n- Others.\n\nThe writing can be improved significantly. There exist numerous typos, grammar errors and inaccurate descriptions throughout the whole paper. Here, I just list some example errors in the \"Related Works\" section:\n\n1. \"Cheng et al.,2016; ?\" -> an inaccurate citation;\n2. \"a lack of shift equivariance occur\" -> \"a lack of shift equivariance **occurs**\";\n3. \"While careful augmentation strategies substantailly improves\" -> \"While careful augmentation strategies **substantially improve**\";\n4. \"Another line of research is to apply anti-aliasing low-pass filter, which originate\" -> \"Another line of research is to apply anti-aliasing low-pass filter, which **originates**\";\n5. \"This anti-aliasing concepts are\" -> \"This anti-aliasing **concept is**\";\n6. \"The first absolute shift-invariant method for image classification tasks are proposed \" -> \"The first absolute shift-invariant method for image classification tasks **is** proposed\";\n7. \"While the selection of the polyphase components of APS is based on the l2 norm, learnable polyphase sampling (LPS) generalize to select\" -> \"While the selection of the polyphase components of APS is based on the l2 norm, learnable polyphase sampling (LPS) **is generalized** to select\";\n8. Many citations are not formal, even to APS.\n\n----------------------------------------------------- Post Rebuttal----------------------------------------------------------\n\nAs the authors did not provide any responses to my concerns, I downgrade my rating from \"borderline reject\" to \"reject\".",
        "questions": "Please refer to my detailed comments in \"Weaknesses\" for details.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper presents a strategy to achieve perfect equivariance in convolutional neural networks. That is, the model produces exactly the same output when the input image is shifted horizontally or vertically. This is achieved by preserving statistics of the positions of the downsampling process in the pooling layers of convolutional networks. The results indicate that the method works perfectly for downsampling (classification) and upsampling (segmentation) operations without the need to re-train the models.",
        "strengths": "* The problem is important and the paper is well motivated.\n* The solution is simple and generic, can be applied to any convolutional model.\n* The results are strong. 100% equivariance is achieved in all experiments, demonstrating the effectiveness of the proposed solution.\n* The approach works on downsampling and upsampling paths of CNNs. The evaluation includes image classification and semantic segmentation.",
        "weaknesses": "Main comments:\n\n* Equivariance is demonstrated only for inference (test) time. It is unclear how the method would facilitate equivariance during training. In other words, by implementing MASS in all pooling layers, what augmentations would be unnecessary when training a new model? The only experiments that involved training a model from scratch were conducted with the CIFAR dataset, but the augmentation procedure was not explained. More analysis of equivariance during training would be informative.\n* In general, the explanation of the method has a few gaps that could be better presented and clarified. For instance, the paper indicates that previous work ignores classical sampling theory, but how MASS uses classical sampling theory is not explained later. Also, it is unclear what the authors mean by \"MASS meticulously preserves the initial downsampling process\". The introduction indicates that MASS uses input data statistics to select the origin, but these statistics are not clearly defined later. The procedure could be more formally presented to avoid confusions.\n* The paper mentions that non-equivariant methods can display severe accuracy drops, but this does not seem to be reflected in the results. The consistency of other methods is usually above 80% and the classification rate remains high. If shifts are introduced randomly, the accuracy of a non-equivariant method can change every time. Reporting how the results change with the amount of shift introduced to break the classification of a model would be informative.\n\nOther comments:\n* It is unclear if the method results in computing or memory overhead (even if minimal, what additional operations / variables are added compared to regular pooling).\n* Some acronyms are not clearly defined, such as APS, LPF and DDAC. Table 2 uses them extensively without citations or explanations to what they refer to exactly.\n* Some minor typos: equivaiant, \"architectures.architectures\", experimants, inializing.",
        "questions": "* Does the proposed method remove the need for using certain augmentations during training?\n* Are the accuracy results reported without shifts? The experimental procedure is unclear, please explain.\n* Can you add results of how shifting affects accuracy in shift-sensitive models?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "eR4W9tnJoZ",
    "title": "Visuo-emotional perception and Human Cognition to engineer content-generation using Generative AI",
    "reviews": [
      {
        "summary": "The paper proposes a method for rapid, AI-generated content, increasing the efficiency of visual communication on digital media. Within\nthis exploration the authors include themes of Hyperpersonalisation and Search-engine optimation.",
        "strengths": "I have not found any strengths of this paper.",
        "weaknesses": "1. The theme of this paper may not be closely related to the conference, as it is only an engineering specification and lacks theoretical explanation.\n\n2. The presentation of the paper is chaotic, making it difficult to read.\n\n3. The method mentioned in the paper, which utilizes ChatGTP to generate accurate prompts and generates high-quality digital advertisements using this prompts and a large text-to-image model, has been widely applied in the engineering field and therefore lacks innovation.",
        "questions": "Please refer to Weaknesses.",
        "rating": "3: reject, not good enough",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper mainly investigates whether generative AI can produce content to attract the user and explains the procedure of content generation from the neuroscience perspective.",
        "strengths": "1. This paper introduces a communication protocol to explain how the brain has been triggered, the entire process is fluent and reasonable.\n2. The content of the pre-research is sufficient.\n3. The strategy of the prompt is meaningful.",
        "weaknesses": "1. This work is too simple, just using the existing GenAI to produce the context and comparing it with the corresponding items.\n2. The prompt is hand-crafted, and cannot be applied flexibly.\n3. The number of samples in the experiment is too small, and the experiments should cover more scenarios.",
        "questions": "1. How do you confirm the prompt is reliable and the output of the GenAI is following the rules?\n2. Since it's an online experiment, why not invite more people?",
        "rating": "1: strong reject",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "The paper proposes a framework that leverages Generative AI to create Ad creatives that aim to increase the Click-through rate of advertisements. The framework and ad creative generation leverage four principles: 1) the evolutionary category need, 2) past memories and brand guidelines; 3) the strongest emotional memory, and 4) context with photographic details.",
        "strengths": "The paper does a good job of motivating and explaining the problem, as well as providing all the necessary details and motivation to understand the necessary background. Also, the paper focuses on an interesting aspect of generative AI and how it can be used to generate ad creatives with the goal of increasing click-through rates that, over the years, have been declining. Overall, I think that this work has the potential to inform various interested stakeholders, including advertisers, policymakers, and social media operators. Also, I like the paper\u2019s approach that aims to leverage the power of Generative AI (particularly ChatGPT) to generate content based on principles obtained from the neuroscience field.",
        "weaknesses": "My main concerns with the paper are related to the framework\u2019s evaluation. I believe that the evaluation is quite limited and simplistic, given that the sample of the recruited participants is biased (the overwhelming majority being from India) and the evaluation focuses on only two products. I suggest that the authors explain and motivate how they perform the user recruitment procedure and the reason why they selected the two products. Overall, given these limitations, it\u2019s unclear whether the paper\u2019s results are generalizable.\n\nAdditionally, the paper fails to explain how this study is different from previous efforts that aim to understand the use of neuromarketing methods without the use of Generative AI to create the ad creatives. The presented framework can also be applied by people to generate ad creatives, so its unclear if the novelty of this work lies in the formulation/use of the framework or the combination of the framework with Generative AI models like ChatGPT. I suggest to the authors to better contextualize their work and better explain the novelty of this work. \n\nAlso, the paper does not explain how the envisioned framework will be applied in practice. The paper\u2019s evaluation defines a set of prompts that are very specific to the products that are studied and generates creatives that are then subsequently used to compare the user perceptions vs. ad creatives that simply show the product with a white background. Overall, it\u2019s unclear on whether the envisioned framework can be applied in practice without great input and effort from experts that will guide the generation of the ad creatives. \n\nIn addition, there is a disconnection between the motivation of the work and the framework/evaluation. The framework does not account for user personalization, which is an important aspect when considering the ad ecosystem. So I am wondering how the paper is planning to incorporate user personalization in this framework and how Generative AI models can assist in this, especially when considering the privacy concerns that may arise from sharing user-specific data with companies that offer LLM solutions (e.g., OpenAI).\n\nTo summarize, I believe that this work is interesting and important, however, at this stage, I believe that the paper is not ready for publication. In addition to the above concerns, I would like to make the following suggestions to the authors (mainly minor issues):\n1. There are a couple of references listed as Anonymous, when they are not Anonymous so I suggest fixing these issues.\n2. Consider not using pie charts for the evaluation results, given that it is one of the worst visualization methods.",
        "questions": "1. How did you recruit participants, and why most of them are from India? How can the recruitment approach affect the presented results? \n2. How are the two products selected? Are these products popular in India, where most participants are from?\n3. How is this study different from previous efforts studying the use of neuromarketing methods vs. plain advertisements like the ones shown to the participants (plain background with the product in the middle)? Is the novelty of the work the use of ChatGPT to generate the ad creatives?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper leverages the content generated by generative AI to enhance the critical last moments of decision-making. Grounded in the understanding that long-duration decisions are the cumulative result of numerous micro-decisions, the author dissects the final seconds of an e-commerce purchase into multiple stimuli. Subsequently, the author introduces a four-point prompt strategy, informed by the outcomes of this analysis. After that, to validate the efficacy of this prompt strategy, the author conducted a series of experiments.",
        "strengths": "Thanks for your interests in ICLR! Overall, this is an interesting paper on a topic which is of interest to ICLR Conference. It offers valuable insights into the application of neuroscientifically designed content to enhance ad click-through rates. The paper astutely recognizes the promise of leveraging Generative AI for this purpose. Building upon this foundation, the author thoughtfully presents four distinct prompt strategies and supports them with well-structured experiments, thus substantiating the validity of their approach.",
        "weaknesses": "While the author presents a comprehensive theoretical framework and provides clear and detailed insights into the prompt strategies, there is room for improvement in the experimental validation of the proposed techniques. As outlined in the paper, the experiments are limited to a single product tested on a sample of 236 participants. Given the potential applicability of this technique to a wide range of products, the scope of experimentation appears somewhat narrow. Expanding the experiment set to encompass a more diverse array of products would strengthen the paper's claims.\n\nAdditionally, the manual design of prompts by the author may not be a scalable solution when considering the need for ad design across a vast array of products. Further exploration of automated or semi-automated prompt generation methods could enhance the paper's practicality and applicability in real-world scenarios.",
        "questions": "1. Have you explored the possibility of automating the prompt generation process for various products?\n\n2. Could you provide insights into any supplementary experiments conducted to further validate the effectiveness of the prompt strategy outlined in your paper?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "jx6njBKH8E",
    "title": "Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships",
    "reviews": [
      {
        "summary": "This work investigates how model fine-tuning may potentially make the models more vulnerable to leaking their pre-train dataset. The authors apply the machine-generated text with more like human-written to fine-tune the language models. Reinforcement learning with self-generation is employed to fine-tune the models. To demonstrate the effectiveness of their approach, the author conducts experiments on six datasets over 6 language models with different amounts of trainable parameters.",
        "strengths": "1. This work proposes a new perspective to make data extraction attacks on pre-training language models easier.\n2. This study performs experiments across diverse datasets and various models, enhancing the generalizability of the empirical analysis.",
        "weaknesses": "1. While the author explores various models in the experiments, there is a noticeable lack of diversity in their architectures; all the studied models originate from the same architectural family.\n2. It would be valuable if the authors could show some qualitative results, e.g., reconstructed text in the model fine-tuning with their approach and the standard approaches.\n3. There is no model utility performance comparison between this work and the other work.",
        "questions": "see weakness.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper proposes a new attack strategy to increase the exposure of private training data from pre-trained language models. The main contributions are:\n1. The paper introduces a novel scenario where an attacker fine-tunes a pre-trained language model with self-generated texts that are pseudo-labeled based on their machine-generated probabilities. The paper assumes that texts with lower machine-generated probabilities are more likely to contain training data.\n2. The paper uses a zero-shot machine-generated text detection method (DetectGPT) to calculate the perturbation discrepancy of each generated text, and a reinforcement learning from human feedback method (RLHF) to fine-tune the target language model to favor texts with lower perturbation discrepancy.\n3. The paper evaluates the proposed attack strategy on six versions of the OPT language model and shows that it can amplify the training data exposure by four to eight times compared to the reference models. The paper also analyzes the extracted samples and discusses potential mitigations and future research directions.",
        "strengths": "1. Originality: The paper introduces a novel attack scenario where an adversary fine-tunes a pre-trained language model to amplify the exposure of its training data. This strategy differs from prior studies by aiming to intensify the model\u2019s retention of its pre-training dataset. The paper also proposes a two-step approach to achieve this goal, involving pseudo-labeling based on machine-generated probabilities and reinforcement learning with self-generations. To the best of my knowledge, this is the first work to explore such an attack strategy and demonstrate its feasibility and effectiveness.\n2. Quality: The paper is well-written and provides sufficient technical details and empirical evidence to support its claims. The paper follows the standard structure of an ICLR submission and adheres to the formatting guidelines. The paper also discusses potential mitigations and countermeasures against the proposed attack, as well as open questions for future research. The paper uses appropriate references and citations to acknowledge previous work and situate its contribution in the literature.\n3. Clarity: The paper is clear and easy to follow. The paper defines the threat model, the adversary\u2019s capabilities and objective, and the main steps of the attack strategy in a precise and coherent manner. The paper also explains the rationale and intuition behind each step of the attack, as well as the challenges and assumptions involved. The paper uses figures, tables, and equations to illustrate the key concepts and results. The paper also provides qualitative analysis of extracted samples and discusses the limitations and implications of the attack.\n4. Significance: The paper addresses an important and timely problem of training data extraction attacks on neural language models, which pose serious privacy risks for both data owners and model users. The paper demonstrates that such attacks can be amplified by adversarial fine-tuning, which can increase the exposure of sensitive training data by up to eight times. The paper also provides insights into the factors that affect the vulnerability of language models to such attacks, such as model size, training dataset type, and perturbation function. The paper contributes to advancing the understanding and mitigation of privacy threats in language modeling.",
        "weaknesses": "1. The paper does not specify how the adversary evaluates the effectiveness of the TDE attack, and what are the assumptions and limitations of the attack scenario. The paper also does not compare or contrast its attack strategy with existing TDE attacks in terms of feasibility, scalability, and practicality.\n2. The paper relies on a single zero-shot machine-generated text detection method (DetectGPT) to pseudo-label the self-generated texts, without considering other possible methods or evaluating the robustness and reliability of DetectGPT. The paper also does not explain how the perturbation discrepancy correlates with the membership probability or the presence of training data in the generated texts. The paper does not account for the potential confounding factors or sources of bias in its experiments, such as the choice of prompts, sampling methods, hyperparameters, datasets, and evaluation metrics.\n3. The paper does not discuss the ethical and social implications of its attack strategy. The paper proposes a novel form of TDE attack that can amplify the exposure of sensitive and private information from pre-trained LMs, but does not address the potential harms or risks that such an attack can pose to individuals, organizations, or society at large.",
        "questions": "1. In Figure 1, perturbed LM generations are divided into two classes: \"good answer\" and \"bad answer,\" based on the value of d(x). Was the threshold for d(x) chosen empirically?\n2. In Table 1 for Epoch 1, the three values with the lowest test accuracy are highlighted. In contrast, for Epoch 2, the highlighted values represent the top-3 highest test accuracy. There are no highlights in Epoch 0 and Epoch 3. Should the highlighting approach be consistent, or was this variation done intentionally for a specific reason?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper focuses on amplifying training data memorization in terms of the extraction attack performance. The goal is to put the target model in a state where it is more likely to regurgitate training data.\n\nMore specifically, the authors propose a fine-tuning method, using reinforcement learning, text generation and machine-text generation detection to condition the model such that it is likelier to regurgitate its training data. They do this with restricted whit-box access to the model, and no access to the training data. They attempt to achieve this by doing the following steps: 1) generating many samples from the model 2) using detectgpt to give scores on how likely each generation is to be human written, intuition being that human written text is more likely to have been pre-training data. 3) create pairs of training/generation data 4) training a reward model to distinguish between the generation and pseudo training data. 5) fine-tune the target model using the reward model. 6) taking samples from the new model and comparing tot the non-trained reference model.\n\nThe authors then test the performance of the proposed method by taking samples from the fine-tuned model and then measuring exact matches with training data and reporting the values. They compare these numbers to those of a non-fine tuned model. They also study the performance of the reward model separately.",
        "strengths": "1. The approach/way of looking at the extraction problem is novel, prior work usually focuses on coming up with post-hoc extraction and not fine-tuning-based methods, where the decoding process is modified such that it incentivizes training data extraction. This paper however, tries to change the model so that its more likely to generate training data.\n\n2. The problem is also an important problem, as current extraction methods are not very successful, most of them demonstrating low extraction rates.",
        "weaknesses": "1. Lack of enough experiments and ablations to support the main claim of the paper, that the method amplifies memorization. See questions 1-3 below. This is my main concern with the approach, as the model might as well just be regurgitating the same set of n-grams, over and over and as the reported is not measured over deduplicate generations based on n-grams (it seems like the only deduplication performed is wrt to full matched strings with training data), nor is there a diversity metric reported. Intuitively, I would assume that the fine-tuning is going to get the model to collapse on the set of generations used for RM training/FT. I also wonder why the authors did not use a metric similar to BLEU.\n\n2. The structure of the paper is hard to follow and its not really well written. Some of the results are not explained well, also the way the deduplication is performed is not fully clear.  See questions 3 and 4 below.\n\n3. Section 5.2 only shows how well a reward model can learn to differentiate between machine generated and human written text. It does not provide any evidence to support the claims of the paper regarding training data. It is simply an ablation. I am not sure what it is included as one of the first results. The fact that the reward model can differentiate between different texts does not necessarily translate to it being better at incentivizing the target model to regurgitate training data.",
        "questions": "1. Can the authors disentangle how much of the extractions overlap with the generated text that they fine-tuned with, and how much of the extracted text is non-overlapping and actually a generation of the model that is due to the amplification. Right now the main remaining question is does this method actually reinforce memorizations or is it just overfitting to the pseudo labeled data? (this corresponds to weakness 1 from above)\n\n2. How many of the generated samples after fine-tuning differ from the reference model generations? as mentioned in question 1, if the model is collapsing, the new generations that the fine-tuned model has would overlap a lot with the generations from the refenrece model. it would be interesting to see if that is the case, or if there are any entirely new generations.\n\n3. One main problem with the results is that the generation deduplication is happening on a full string level, and not n-gram overlaps. Same as point 1, I think there is probably huge overlap, what is the diversity of generations? There are no ablations here. We need a lot more ablations on the experiments. \n\n4.  section 5.2 please elaborate on the duplicate token overlaps, and the intervals. I went over the text multiple times but did not realize what the point of that experiment is.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper presents a novel attack strategy aimed at increasing the vulnerability of pre-trained language models to training data extraction attacks. By adversarially fine-tuning the LMs, the authors claim to amplify the exposure of sensitive pre-training data. They propose the use of pseudo-labels to help fine-tune the model in a way that favors text likely to have originated from the pre-training dataset. Their experiments suggest that this approach can lead to a significant increase in training data exposure, particularly in large models with over 1 billion parameters.",
        "strengths": "1. Generally, the paper is well-written and easy to follow. \n2. The paper introduces a unique and unexplored attack vector that goes beyond the traditional post-hoc data extraction methods.\n3. Given the widespread use of large LLMs, the paper addresses a timely and significant issue of data privacy.",
        "weaknesses": "1. The paper assumes the availability of restricted white-box capabilities, which may not always be the case in real-world scenarios.\n2. Although the author provided extensive empirical study results, I'm still curious about the underlying mechanism behind the attack. Could the author elucidate how the proposed adversarial fine-tuning method effectively amplifies data exposure? It might be helpful to use a naive linear classification task as an illustrative example.",
        "questions": "How would the efficacy of this adversarial fine-tuning approach change if some form of differentially private training was already applied to the pre-trained language model? Would the attack still be as effective, or would it require significant modifications?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "rGvDRT4Z60",
    "title": "FairPATE: Exposing the Pareto Frontier of Fairness, Privacy, Accuracy, and Coverage",
    "reviews": [
      {
        "summary": "The proposes a framework to integrate fairness into PATE. The proposed method is a simple adaptation of PATE which incorporates fairness constraints into the model's query rejection mechanism.",
        "strengths": "- The paper tackles a highly relevant issue in ML, addressing both theoretical and practical implications of fairness and privacy.\n- The proposed framework is a simple adaptation of the existing PATE. Simplicity is a plus in my book.",
        "weaknesses": "- Fairness is \"enforced\" by adding parity constraint within the aggregator which acts as a rejection sampling step on the basis of fairness. The general idea was proposed in several other works in the past, including the ones cited by the authors and against which the authors compare. It is thus difficult to understand what is new in the proposed framework. An explicit mention would help.\n- A discussion on when to use the proposed framework in contrast to other frameworks is absent (see also my questions below).\n- The experimental analysis should be improved. Some figures are misleading, e.g., same colors used for different algorithms (see questions below).",
        "questions": "- I can't judge what is the impact of IPP (the rejection step added at inference time) on the overall results. Can you provide some ablation study showing how the framework performs on various datasets with different majority/minority distributions with and without IPP? \n- How does the framework work in case of some distribution shift? This is especially important in the context of my question above. \n- For the other datasets reported in the appendix the trends shown reverts, e.g., DP-Fermi produces better tradeoffs than FairPATE. Can you discuss why? What feature of the dataset makes this possible?\n- Fig. 2 and 3 use orange colors for two different algorithms (Tran et al (Fig 2) and Jagielski et al. (Fig 3)). The authors should report all algorithms in all figures or justify their absence.\n- Why Tran et and Jagielski et al. are not reported for the UTK-dataset experiment? \n- Paper [Learning with Impartiality to Walk on the Pareto Frontier of Fairness, Privacy, and Utility](https://arxiv.org/pdf/2302.09183.pdf) discusses a similar topic (although the contributions from this work are different) and it could be added to your Related work section.\n\nMinor comments:\n\nA lot of the cited papers have appeared in conferences. But the authors cite their arxiv version. I suggest to update the references accordingly.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The work considers the inclusion of fairness constraints into a method for differentially private\n(DP) training (or data generation from private data) based on transfer learning. The paper argues\nthat in this \"PATE\" approach which accounts of privacy concerns using DP, there is only one\nsensible place to incorporate fairness using an intervention (i.e. adjusting what/whether) data\nproceeds to subsequent PATE steps. This step is the point after the transfer from an ensemble of\nteachers is made. The paper puts a mechanism there that will reject some queries/instances if they\nresult in violations of fairness which is a function of all of the prior decisions of the\nmechanism. The work evaluates this approach relative to 2 other DP-based systems that incorporate\nfairness showing mostly preferable trade-offs between fairness, accuracy, and privacy; though this\nbenefit is small.",
        "strengths": "+ Fairly well written and easy to follow.\n\n+ The points of intervention discussions give a nice overview of the PATE approach and ways in\n  which additional mechanisms can be independently injected. Note, however, the independent\n  intervention assumption is a weakness below.\n\n+ Rejection for fairness does give additional options for achieving fairness though this too comes\n  with a weakness below.",
        "weaknesses": "- The implications of rejecting for fairness are not considered. Rejection for privacy has\n  implications in terms of privacy budget and likewise rejections for fairness come with\n  implications and ignoring them might be responsible for the observed gains on the Pareto\n  frontier. Consider the noted rejection example:\n\n    \"If at inference-time a decision cannot be made without violating a pre-specified fairness\n     metric, then the model can refuse to answer, at which point that decision could be relegated\n     to a human judge\"\n\n  The important implication here is that there will still be a judgement; it is just that the model\n  will not be making it. Regardless of whether the result of the human judgement will produce fair\n  or unfair overall statistics (that consider ultimate judgement whether by model or human), those\n  decisions need to be incorporated into subsequent fairness calculus. Even if a query is rejected\n  due to privacy, and if a decision is made for it subsequently, it would need to be accounted for\n  in subsequent fairness decisions.\n\n  Suggestion: incorporate ultimate decisions, whether by model or human, into the rejection\n  mechanism; i.e. update counts m(z, k) based on human decisions. Given that humans might put the\n  group counts into already violating territory, it may be necessary to rewrite Line 7 of Algorithm\n  1 to check whether the fairness criterion is improving or not due to the decision and allow\n  queries that improve statistics even though those statistics already violate \u03b3 threshold.\n  Handling rejection in experiments will also need to be done but unsure what the best approach\n  there would be. Perhaps a random human decision maker?\n\n- In arguments for intervention points, assumptions are made which preclude solutions. They assume\n  the intervention need to be made independent of other mechanisms in PATE. That is, they cannot\n  consider information internal to decision making that is not described by Figure 1 like\n  individual teacher outputs. This leaves the possibility that some fairness methods might be able\n  to integrated with PATE in a closer manner than the options described. One example is that they\n  might include the teacher outputs instead of operating on the overall predicted class like\n  Algorithm 1 assumes presently. C3 in particular suggests that some interventions will not account\n  for privacy budget correctly due to special circumstances and suggests at Point 4, they can be\n  budgeting can be handled correctly. Nothing is stopping a design from refunding privacy budget if\n  a query is rejected subsequently to an intervention point.\n\n  Suggestion: rephrase arguments for why some intervention points are bad to make sure they don't\n  also make assumptions about how the interventions are made and whether they can interact with\n  privacy budget.\n\n- Results in the Pareto frontier show small improvements, no improvements, and in some cases worse\n  results than prior baselines.\n\n  Suggestion: Include more experimental samples in the results to make sure the statistical\n  validity of any improvement claims is good. This may require larger datasets. Related, the\n  experiments show error bars but how they are derived is not explained.\n\n- Comparisons against methods in which rejection due to fairness is not an option may not be fair.\n\n  Suggestion: either integrate suggestion regarding accounting for rejection above, or incorporate\n  some form of rejection (or simulate it) in the existing methods being compared to. It may be that\n  the best methodology is not FairPATE but some existing baselines if adjusted to include fairness\n  rejection option.\n\nSmaller things:\n\n- Rejection rate is not shown in any experiments. One could view a misclassification as a\n  rejection, however. Please include rejection rates or view them as misclassifications in the\n  results.\n\n- The distribution whose fairness need to be protected is left to be guessed by the reader. For\n  privacy, it is more clear that it is the private data that is sensitive and thus privacy\n  budgeting is done when accessing that private data as opposed to the public data. For fairness,\n  the impact on individuals in the private dataset seems to be non-existent as the decisions for\n  them are never made, released, or implemented in some downstream outcome. I presume, then, it is\n  the fairness needs to be respected on the public data.\n\n  Algorithm 1 and several points throughout the work hint at this. However, there is also the\n  consideration of intervention points 1,2,3 which seem odd as they points seen before any\n  individual for whom fairness is considered is seen. That is, fairness about public individuals\n  cannot be made there, independent of any other issues such as privacy budgeting. Further, Theorem\n  1 discusses a demographic parity pre-processor which achieves demographic parity on private data\n  which I presume is irrelevant.\n\n- The statement\n\n    \"PATE relies on unlabeled public data, which lacks the ground truth labels Y\"\n\n  is a bit confusing unless one has already understood that fairness is with respect to public\n  data. PATE also relies on private labeled data to create the teachers.\n\n- The Privacy Analysis paragraph could be greatly simplified to just the last sentence regarding\n  post-processing.\n\nSmallest things:\n\n- Double \"violations\" near \"violations of demographic disparity violations\".\n\n- The statement \"DP that only protects privacy of a given sensitive feature\" might be\n  mischaracterizing DP. It is not focused on features or even data but rather the impact of\n  *individuals* on visible results.",
        "questions": "Question A: Is reasonable to ignore downstream decisions from queries rejected due to fairness\n  (i.e. contrary to my suggestion in the weaknesses above)?\n\nQuestion B: C1 makes a point that adding privacy after fairness may break fairness. What about in\n  expectation? Were one to view the demographic statistics defining fairness measures in\n  expectations, wouldn't they remain fair?\n\nQuestion C: Theorem 1 makes a statement about a pre-processor inducing privacy parameter\n  degradation but FairPATE (or PATE) appears to fit the definition of a pre-processor. If the point\n  of the Theorem is to argue against pre-processors, isn't it also arguing against PATE/FairPATE?\n  Unrelated, what is \"ordering defined over the input space X\" and why is it necessary?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper discusses the problem of interactions between fairness, privacy, and accuracy constraints for PATE (Private Aggregation of Teacher Ensembles) type algorithms for differentially private learning. PATE style of algorithms first uses the private data (partitioned into several small partitions) to train base classifiers (teachers). Then, the algorithm uses these teachers to label some public data in a privacy preserving way. In particular, it cleverly chooses which points it can label without sacrificing too much privacy. Then another classifier (student) is trained on this newly privately labelled dataset, which is then released to the user. In this paper, this labelling step is used to also incorporate privacy constraints. Finally, the paper uses empirical evidence to suggest that their algorithm achieves a better privacy fairness accuracy trade-off than Loewy et. al. 2023.",
        "strengths": "* The paper is written quite clearly and is easily readable. The arguments of the authors come out clearly without ambiguity and the reader can easily follow the train-of-thought. I appreciated that very much.\n* I also found the main algorithmic idea of this paper quite nice. The idea of that the algorithm chooses which points to label not only on the bassi of the privacy constraint but also the fairness constraint is quite neat and could be useful in other contexts. I appreciated this.",
        "weaknesses": "Despite the interesting idea of the paper, I am unable to support this paper for acceptance. The four main reasons are as follows (in decreasing order of severity).\n\n1. __W1__ Significance: The paper aims to convey the significance of its contribution through experimental results (and I don't think there is anything wrong with it and in general support extensive empirical results), but the experiments present a rather bleak picture of the advantages of FairPATE. \n    * **Minimal improvements** Most importantly, there are rarely any results where the improvements of PATE over baselines is larger than 1\\%. For example in 1. Credit card dataset and 2. parkinson's dataset, there results differ by less than $1\\%$.\n    * **Several examples of underperformance** Several examples also show that FairPATE performs significantly worse than competitor. Examples include Demographic Parity for Adult dataset and UTK Face ($\\epsilon=5$).\n    * **Misleading regarding diversity of experiments** In the introduction, the paper sells itself regarding performing a wide range of experiments but results on nearly half of these datasets are hidden away in the appendix without any mention in the main text and without comparisons. Experiments on **CheXpert, CelebA, FairFace, and Retired-Adults** are not available in the main text and it is very hard to interpret the results presented for this in the appendix.  In fact, there are **no results of FAIR-PATE on CheXpert** in the paper \n    * Please show comparison on these for demographic parity and equalized odds (similar to Figure 2,3 with comparison to Loewe et. al.'s algorithm) on these four datasets. In addition, there are results in the literature that run DP algorithms on CelebA and CheXpert. Comparisons should be made to them to show what is the sacrifice being made compared to state-of-the-art.\n\n2. __ W2__ **Wrong Conclusion from Theorem 2** I did not go through the detail of Theorem 1 but I assume it is correct and follows from Group privacy arguments. However, the sentence above Theorem 1 (Point C2) claims that the result proves that  \" pre-processing ... will necesarrily degrade the guarantee of the .... private learning mechanism\". How ever this is not what the Theorem shows. The theorem only proves a privacy guarantee of $M\\odot P_{\\text{pre}}$ not that this is the tightest privacy guarantee possible for the composed mechanism. Am I missing something ?\n\n3. __W3__ **Abstaining from prediction for fairness reasons** The introduction justifies this as _\"if a decision cannot be made without violating a pre-specified fairness metric, then the model can refuse to answer at which point the decision can be relegated to a human judge\"_. If I have understood this correctly, this is a flawed argument. For example, consider the situation where there are group of data points from the majority group, on which if the algorithm predicts correctly the fairness will be violated and hence the algorithm abstains. Nevertheless, the prediction is easy for this group and the judge nevertheless predicts on them correctly and the overall fairness is still violated. Isn't this pointless then to relegate this to the judge ? Intuitively, it appears that any problem can be made fair this way by simply refusing to predict on certain majority groups thereby artificially boosting the fairness of the algorithm. The correct fairness solution should aim to improve performance on the minority group instead.\n\n\n4. __W4__  **Unfair Comparisons** Fair-PATE  and Loewy et. al's algorithm do not work under the same restrictions of differential privacy. Specifically, Fair-PATE uses public unlabelled data and Loewy et. al doesn't and we know that (even a small amount of) public data can severely help in improving accuracy of DP models (perhaps fairness too). Hence, it appears to me that Loewy et. al. uses a significantly stricter notion of privacy and achieves nearly comparable result and in some cases even better (for tabular datasets, there are no comparison on vision datasets with Loewy et. al.).",
        "questions": "* **Motivation** I understand that there are several works showing that privacy incurs a sacrifice in fairness. However, one possible approach to this problem is simply improving the accuracy and perhaps the resultant accuracy also leads to high fairness. In fact Berrada et. al. (2023) makes this argument with some experiments in their paper. I did not see an argument in this paper why this approach is not expected to solve all problems. Why should there be a trade-off between privacy and fairness ? Is it known in the literature and are there theoretical studies arguing about the necessity of a trade-off ?\n\n* **Missing baselines** Why is there no comparison with the algorithm of Zhang et. al. (2021), Kulynuych et. al. (2022) and Berrada et. al. (2023) ? They are mentioned in one or two sentences at the very end of the paper but without any comprehensive empirical comparison.\n* **FairDP-SGD\" What is FairDP-SGD ? It doesn't seem to have been defined anywhere ? Is it an existing work ? Where is FAIR-PATE's result on CheXpert ?\n\n* In addition to this, please also also address __W1,W2,W3,W4__.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "w73feIekdO",
    "title": "Real-time computer vision on low-end boards via clustering motion vectors",
    "reviews": [
      {
        "summary": "The paper focuses on a tracking algorithm that takes as input motion vectors obtained from standard video encoders.  The main contribution is the leveraging of the notion of coresets applied to segments, obtaining representative clusters and tracking. The bulk of the paper is on the extension of coresets for point sets to segments.  The tracking algorithm result is illustrated in two examples - big buck bunny video example, and 3D map estimation from drone video.",
        "strengths": "The main claim of the paper is in the generalization coreset ideas for points to segments and in the derivation of a tracking algorithm that is computationally efficient.  Certain claims are made about generalization of previous theoretical work (that I am not fully familiar with and cannot comment).",
        "weaknesses": "While I understand the rationale and setup of the problem for translating motion vector inputs as coresets and tracking,  the  results on the two datasets are not convincing.  While the paper talks a lot about how this approach is substantially better in comparison to neural-net based methods, it fails to refer to any of the classic methods in tracking where clustering, robust statistical methods are used.  The paper does refer to a review paper and states that there are over 1000 articles on the subject.  However, if the central aim of the paper is to demonstrate the advancement in tracking algorithms the paper should demonstrate the effectiveness of the algorithm designed by comparing it with at least one alternative (e.g. mean-shift based tracking ,  Comaniciu et al (CVPR 2000)).  I note that the mean-shift based tracker performed in real-time in low computational power settings for given candidate regions in a video over two decades ago.",
        "questions": "I have several questions that will help me identify what the central contributions are and on how the proposed method outperforms over other methods in the state of the art.\n\n1) Is your contribution mainly the extension of coreset idea to segments?   There has been work on coresets for sets of lines (e.g. Coreset for Line-Sets Clustering, Lotan et al, 2022).  Please elaborate on how your method is different.\n2) Have you compared your tracker with other methods in opencv and if so, what was the outcome? You refer to OpenCV in your paper and it is not clear from the paper how it was used in your experiments.\n3) Can you elaborate on the tradeoff between computational complexity of your technique and (epsilon, delta) choices during coreset construction?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper introduces innovative computer vision techniques that integrate classical machine learning strategies to enhance efficiency and robustness. The authors showcase the practical impact of their clustering method in video tracking and map creation from video, successfully executing it in real-time on micro-computers. The contributions of the paper encompass a novel clustering algorithm for motion vectors, a coreset-based approach that reduces the computational complexity of the clustering algorithm, and the implementation of the clustering algorithm on low-end boards, enabling real-time performance.",
        "strengths": "S1. The paper is well-written and most of the content is quite easy to follow. \nS2. The main contribution of this work is significantly interesting by incorporating traditional machine learning techniques in the age of deep learning. \nS3. The proposed vector clustering is theoretically sound, I tried my best to examine most of them and did not find obvious errors. \nS4. Overall, I have significant concerns regarding the experimental section of the paper. Firstly, the proposed method is only validated in three application scenarios, and the experimental results are not extensively reported or analyzed, neither in the main text nor in the supplementary material.",
        "weaknesses": "W1. The proofs in Section 2 are rather obscure and difficult for readers without relevant background knowledge to comprehend. Additionally, many crucial steps are relegated to the supplementary material, greatly impacting the readability of this paper.\nW2. This paper lacks an introduction and discussion of related works, making it challenging for readers unfamiliar with the field to fully understand the contributions of this article.",
        "questions": "Please check the weaknesses listed above.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper introduces a fully polynomial randomized approximation scheme for the clustering of motion vectors, which is then applied to the motion vectors produced by standard video encoders to the problem of visual tracking. The approximation scheme is an adaptation of the results of Feldman and Schulman (2012), which is concerned with robust clustering of points in arbitrary metric spaces, to *segments* as defined by the paper. Specifically, points on segments are sampled at uniform intervals, under a condition on the number of points $\\epsilon'$ such that the approximation in Feldman and Schulman (2012) is preserved.",
        "strengths": "# Originality\nThe idea of directly using vector motions produced by video codecs as inputs to computer-vision tasks is interesting, as it is the broader approach of designing FPRAS for computer vision problems.\n\n# Quality\nThe paper brings a broad review of the literature and is self-contained, including detailed proofs of its several lemmas and theorems.\n\n# Clarity\nEvery term is defined, and the illustration in Figure 2 helps the reader to understand the geometric meaning of the cost function defined in Equation 1.\n\n# Significance\nThe paper brings to the attention of the computer-vision community an important class of \"probably approximately correct\" algorithms, as in the title of Valiant's book.",
        "weaknesses": "# General\n\nThe paper is not well organized. The first two sections of the Introduction, titled \"Video Tracking\" and \"Motion Vectors,\" do not describe the problem addressed by the paper. The subsection \"Our Approach\" does not describe the approach at all but introduces and illustrates the definition of a cost function which is discussed only much later in the paper. The subsection \"Coresets\" brings a definition of coreset, followed by an unusually long quote from the paper by Denisov et al. (2023). That section makes a reference to a \"segment clustering problem stated in Section 2.1\" that has a small coreset, but I was not able to parse the remaining of that paragraph. The references to Jubran et al. (2021) and Rosman et al. (2014) seem unnecessary, as they refer to exceptions (or so I understood) to the stated goal of having coresets which are weighted subsets of the inputs.\n\nAlgorithm 1 should be replaced for the simple formula that computes $\\epsilon'$. This value is then used to produce samples at uniform intervals on the motion vectors. It is not clear how the claimed novelty of Algorithm 1 generalizes, as stated, previous work by Rosman et al. (2014), which is concerned with fitting segments to points, rather than sampling from segments.\n\nThe structure of Algorithm 2 is not at all illustrated by Figure 3, as attempted. A key component of that algorithm (Feldman and Shulman CORESET algorithm (2012)) was replaced in Figure 3 with a different method (Bachem et al. (2018)) for \"easier implementation.\"\n\n# Evaluation\nExperimental evaluation is insufficient. There is scant comparison, and no quantitative evaluation other than an unusual computation of frames-per-second (FPS). It is not valid to subtract all computing times but clustering from the pipeline, divide the number of frames by whatever remains and claim that as an FPS.\n\nThe role of Artuhr and Vassilvitskii (2007) in the empirical evaluations is unclear since the output of Algorithm 2 should be a clustering of the segments. One the other hand, there is no mention of Algorithm 2 in that section, only of Algorithm 1.\n\nThe steps of the video tracking method are unclear. The is no explanation for what \"Add for each motion vector its degree to (0, 10 and (1, 0)\". The is no discussion of how one moves on beyond $k = 2$.\n\nThe jump from clustering of motion vectors to map creation leaves a gaping hole in the paper. The empirical evaluation of 3D map creation follows similar steps, which are repeated almost verbatim and should be omitted.\n\nThere are citations that are unusual to the computer-vision community: the OpenCV library, the Python 3 reference Manual, an Ubuntu Linux guide, the Rasberry Pi user guide, Vigdear manual, CutstomTkInter, and others.\n\nThe Conclusion section of the paper cannot be moved to an appendix.",
        "questions": "- It is curious that the number of samples on a segment does not depend on the length of the segment, according to Algorithm 1. Is there any intuition for why?\n\n- Still in Algorithm 1, it is correctly stated that $r$ is defined in Definition 2.3; however, given the comment on the second paragraph following the description of the algorithm (\"Note that $r$ in Algorithms 1...\"), it should be provided as an input, since the function $D$ to which $r$ corresponds is not.\n\n- I assume the word \"tracing,\" which appears twice in Section 3, is at typo, and \"tracking\" was meant instead?\n\n- Was Algorithm 2 used at all? What is the purpose of using Arthur and Vassilvitskii (2007) if Algorithm 2 already produces a clustering? How is it possible for Arthur and Vassilvitskii (2007) algorithm to have been implemented in Bradski (2000)?\n\n- How is a motion-vector clustering algorithm applied to map creation? Why computations on Raspberry-Pi and utilization of gyroscope contribute to \"fair comparison\"?",
        "rating": "1: strong reject",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper proposes a clustering approach based on the idea of coresets. It is demonstrated in the paper that the proposed formulation helps perform tracking and 3D map creation from videos in real time. Few experimental results are shown to demonstrate the claims made in the paper.",
        "strengths": "* Real-time solution to a couple of popular computer vision problems.",
        "weaknesses": "* Not a well-written paper. So many typos and grammatical mistakes.\n* The paper widely discusses the existing literature in theory and emphasizes less of the actual contributions of the paper other than making few methods real-time.\n* The results are poorly demonstrated. I am unable to conclude how good of a map is obtained using the proposed method.\n* Also confusion about video tracing and tracking \u2014see Sec. 3. \n\nRefer Questions section for more comments.",
        "questions": "## Abstract:\n* To this end, we utilize motion vectors and clusters. What clusters authors are referring to. I believe it should be clustering algorithms/methods.\n\n* with real-time running time -> that gives real-time performance.\n\n## Introduction\n* A meta-survey on such approaches Zou et al. (2019) states that in recent years -> kindly use \\citep{} to put parentheses for citation or rewrite this line.\n\n* \u201cfool\" -> use `` and \u2019\u2019 for the apt quotes.\n\n\n* Figure 1 -> the blue motion vector is hardly visible. Furthermore, kindly use a different color for the blue motion vector as it correlates with the flower in the background. \n* Figure 2 -> figures are placed side to side, whereas captions suggest top and bottom. Kindly correct.\n\n\n* There are many grammatical mistakes in the paper. Kindly improve the writing of the paper.\n\n \n\n\n## General Comment:\n\nWith all due respect, tracking and map creation is not computer vision. These are a couple of  problems studied in computer vision. Kindly modify your paper title.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "kmn0BhQk7p",
    "title": "Beyond Memorization: Violating Privacy via Inference with Large Language Models",
    "reviews": [
      {
        "summary": "The authors show how LLMs (trained with information across the information) can utilize syntactic cues in written text to identify semantic (and personally identifiable) attributes of users. They demonstrate the feasibility of their approach on a custom-curated dataset of posts from Reddit.",
        "strengths": "1. First paper demonstrating feasibility of such an attack.\n2. Reasonably well written (though the paper contains formalisms that are quite honestly unnecessary, and punts  a lot of relevant details to the appendix).",
        "weaknesses": "1. Irreproducible\n2. Implications are a function of how good the humans are i.e., if the golden labels are inaccurate (e.g., how can I be sure that the age attribute is within error tolerance), all conclusions need to be made with a grain of salt.",
        "questions": "I enjoyed reading the paper. It demonstrates a variant of \u201clinkability attacks\u201d in LLMs and empirically validates it. \n\n1. Apart from the fact that one can launch such an attack, this reviewer has gained no new technical insight from this work. While this demonstrates \u201cfeasibility\u201d and that is of merit, what do follow-up works look like in this area?\n2. The authors motivate their work by stating that identifying certain attributes is potentially hazardous for people since these attributes can be cross-referenced with public databases to de-identify users. This reviewer believes this claim is a stretch; could the authors highlight how one can deanonymize the users that were present in the dataset they considered? While these claims are \u201ctrue\u201d from an academic sense, making these threats practical requires a lot of additional work which the authors do not factor in.\n3. The reviewer agrees with the authors that the LLM can be used to coerce users into sharing more private information. However, In the adversarial interaction scenario, the attack is easy to thwart. Users could perform prompt injection (as noted in this thread: https://x.com/StudentInfosec/status/1640360234882310145?s=20) and can read the instructions. Given how brittle LLMs are to such forms of attacks, how reliable can such \u201ccoercion attempts\u201d be made?\n4. The notion of \u201cdefenses\u201d against such attacks also seems slim. But should this be something that we need to actively defend against? Sharing posts (as done in the status quo) intrinsically contains some notion of utility that will be removed if the deducible information is scrubbed. Can the authors comment on the same?\n5. While the LLMs are certainly faster than humans, I don\u2019t believe the numbers in this study are the very best humans can do. Could the authors describe how their human baseline can be improved? My understanding is that few humans were tasked with identifying attributes using web search (without much training on this front).",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "The paper presents the privacy risks of LLM to infer personal attributes from user-written text. Empirical results show that the current LLM can infer a wide range of personal attributes from text with proper prompts.",
        "strengths": "1. This is the first work showing LLM could effectively infer sensitive attributes from user-written text. This work could have a high impact on the community. \n2. The authors have conducted comprehensive experiments to substantiate the key statement presented in the paper.\n3. The paper offers a novel perspective on the study of Language Model Models (LLMs).",
        "weaknesses": "1. Some experiment setups should be justified. For some attributes (e.g., MSE for age), accuracy is not the correct metric.\n2. Using sensitive topics and need additional ethics review. For example, whether the study is  IRB approved? \n3. Quality checks of the synthetic data generation is missing. In the paper, the author fails to mention what types of quality checks they performed on the collected synthetic data, weakening the soundness of the paper. \n\nMinor:\n 1. Typos: Mititgations -> Mitigations, exampels -> examples",
        "questions": "Please provide a response to the weaknesses mentioned above.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper focusses on extracting personal attributes of Reddit users based on the comments they left on a subset of reddit communities. The methodology involves prompting SOTA LLMs",
        "strengths": "The paper opens up a really interesting problem, and conducts thorough experiments to demonstrate that LLMs can be used to infer personal attributes from online comments. This is an important and novel research topic. \n\nThe experimental set up is really convincing. I really appreciate the rating of the difficulty of attribute assignment and the anonymisation experiment.",
        "weaknesses": "1. The presentation could be clearer. One of the main contributions of the paper is the release of a synthetic data set. However it is not clear how this data set was created. This should be discussed in the main part of the paper. But also the presentation in the appendix does not make it obv how to reproduce the data set creation.\n2. Re the findings on the ACS data set, I wonder whether it is obv that the LLMs have not seen and memorised the ACS data.\n3. I wonder how much of the results are due to memorisation. While the authors have controlled for memorisation on long comments, I am not sure how convincing the methodology is. It would be interesting to see the subreddit prediction performance of LLMs of a comment for instance. \n4. Do the authors release results on the synthetic examples? Since the experiment is not reproducible, it would be important to have result s on the synthetic data so future work can build upon the results of this paper.",
        "questions": "1. How was the synthetic data set created?\n2. What is the baseline in Fig. 25?",
        "rating": "8: accept, good paper",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper discusses novel privacy threats resulting from inference capabilities of LLMs in two different settings :- \n- They show that LLMs can infer personal user attributes from their online activity. \n- They also discuss how malicious chatbots can steer conversations to uncover private information. Experiments on 9 state-of-the-art LLMs demonstrates their effectiveness in inferring personal attributes from real-world Reddit data.\n\nThey show that common mitigation methods like text anonymization and model alignment are currently ineffective at protecting user\nprivacy against these attacks",
        "strengths": "- Novel privacy threats emerging from the strong inference capabilities of current state-of-the-art LLMs in a zero-shot setting are discussed.\n- A full release of a dataset of 525 human-labeled synthetic examples to further research in this area.\n- Ineffectiveness of current mitigation methods against these attacks is discussed",
        "weaknesses": "- Labelling procedure for obtaining ground truths for the dataset should get multiple labels for each profile to make the results statistically significant. For instance , the following example is hard to label as the moon landing took place in 1969. \n> \u201doh... I remember watching the moon landing in 1959 with my father. he picked me up from school and we went home and watched it on television. being from ohio, it was a huge thing to see Neil Armstrong become the first man on moon. funnily, this is the only specific memory I have from first grade in primary school, was a looong time back, eh\u201d Age: 70 years",
        "questions": "- Labelling procedure - It seems only one human label was obtained per example as there is no mention of how final labels are aggregated. Is that the case ? \n- More discussion on how you obtained these numbers?\n> achieving up to 85% top-1 and 95.8% top-3 accuracy at a fraction of the cost(100\u00d7) and time (240\u00d7) required by humans.",
        "rating": "8: accept, good paper",
        "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The authors demonstrate how LLMs can be used as to infer sensitive information from comments and text, such as location, occupation, place of birth, education, etc. The attack they propose involves prompting the LLM by asking them to be \u201can expert investigator\u201d tasked with recovering these sensitive attributes from unstructured textual bodies. They formulate two kinds of attacks: a passive attack where the LLM is fed this information and an active method where the agent is presumed to be assisting the user while simulatenously trying to recover personal information. They try and mitigate their attack using a client-side anonymization method and via provider-side alignment.",
        "strengths": "The paper is well organized, and presents a new and rising privacy risk. Such an attack was not feasible when a human was tasked with having to recover facts manually, and so the contribution is timely and well motivated. They surface important privacy-related risks and demonstrates that much more work needs to be done to mitigate these kinds of attacks.",
        "weaknesses": "Further analysis into how recovery of different kinds of PII was correlated would have been appreciated.",
        "questions": "- Have you considered using LLMs to \"rewrite\" inputs in a privacy-preserving manner?",
        "rating": "8: accept, good paper",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Accept"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "p4B7rl1UFA",
    "title": "AdaLomo: Low-memory Optimization with Adaptive Learning Rate",
    "reviews": [
      {
        "summary": "This paper proposes AdaLomo, a low-memory optimization method for large language models that provides an adaptive learning rate for each parameter while maintaining memory efficiency. The key ideas are using non-negative matrix factorization to estimate the second-order moment for the adaptive learning rate, and employing grouped update normalization to stabilize training. Experiments on instruction tuning and further pretraining of LLaMA models show AdaLomo achieves comparable results to AdamW while significantly reducing memory requirements.",
        "strengths": "* Tackles the important challenge of reducing memory footprint for large LM training. The motivation is well articulated.\n* Empirically analyzes differences between SGD, Adam and LOMO highlighting the role of second-order moments. Provides insight.\n* AdaLomo integrates sensible ideas - NMF for second-order moment estimation and grouped update normalization - to offer adaptive learning rates with low memory.\n* Experiments cover instruction tuning and further pretraining with solid results on par with AdamW and LoRA. Reduced memory requirements demonstrated.",
        "weaknesses": "* The main ideas borrowed from prior work like Adafactor and grouped normalization limit novelty. Contributions appear incremental.\n* The two core components of AdaLomo are the use of non-negative matrix factorization (NMF) for estimating the second-order moment and the grouped update normalization. However, the paper does not contain ablation studies to directly demonstrate the benefits of each component.\n* Convergence plots during pretraining could be insightful to compare optimization behavior.\n* Lack of comparisons to related memory efficient methods like SM3, ZeRO, and 8-bit optimizer.",
        "questions": "* Have you experimented with other ways to estimate second-order moments besides NMF? How did they compare in terms of memory and performance?\n* How sensitive is AdaLomo to the hyperparameters? Any guidelines for settings based on model architecture or task?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes the AdaLOMO optimizer for training large language models. Specifically, the work 1) takes Adam and removes the second moment buffer, 2) factors the second momentum buffer of each parameter group into a Rank 1 matrix (outer-product of two vectors) and re-scales the second moment update to have a similar magnitude to the inverse RMS of the previous iterations parameters in the case where the updates grow very large. Numerical experiments are provided with LLaMA instruction tuning, and further LLaMA pretraining.",
        "strengths": "### Significance\n* This paper studies an important problem, namely how to improve the memory efficiency of optimizing large language models.",
        "weaknesses": "### Originality\n* The proposed method is EXACTLY Algorithm 5 in Shazeer et al., 2018. The only difference is that the gradient of a layer is deallocated once it is used to compute the gradient of the next layer so as to save memory.\n  * Adafactor does already propose using Adam with a factored second moment. Similarly, they remove the first moment buffer. The RMS normalization is also taken directly from Adafactor, where it is motivated as a strategy for preventing very large updates when using slow decay of the second order buffer in the absence of a first order buffer.\n\n### Quality\nNumerous mathematical issues in terms of clarity + a few minor mathematical errors which are probably typos.\n* RMS on page 5 is incorrect, terms inside summation should be squared. However, $u$ is a matrix, so unclear what this computation involves. \n* In equation 9 it should be $v_{t,i} = r_{t,i} c_{t, i}$\n* In equation 10, unclear what $g_{t,i} / v_{t,i}$ involves, since $g_{t,i}$ and $v_{t,i}$ are matrices of size $m \\times n$\n* Used $\\theta_{t,i}$ to refer to a \u201cparameter\u201d but this is described as matrix of size $m \\times n$, should it is not just a single parameter.",
        "questions": "What are the novel contributions of AdaLOMO compared to Adafactor?",
        "rating": "1: strong reject",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "This paper presents the low-memory optimizer with adaptive learning rate (AdaLomo) for training large language models. The optimizer combines LOMO with the first/second-order moment estimations used in adaptive methods such as Adam. Computing the second-order moment estimation uses Non-negative matrix factorization. This paper shows numerically that AdaLomo is comparable with AdamW and reduces memory requirements.",
        "strengths": "The strength of this paper is to show numerically that the proposed method, AdaLomo, is comparable with AdamW and reduces memory requirements.",
        "weaknesses": "This paper numerically studies the performance of AdaLomo that can be obtained by combining the existing methods such as LOMO and Adam. It seems that AdaLomo has the best of both LOMO and Adam. This paper lacks theoretical explanations why AdaLomo performs better than the existing optimizers, such as LoRA, AdamW, and LOMO.",
        "questions": "In general, I am not very familiar with this topic. Although this paper studies mainly practical numerical comparisons, I think that it needs theoretical explanations and evidences to emphasize the usefulness of AdaLomo. In particular,\n\n- There have been convergence analyses of Adam. Is it guaranteed theoretically that AdaLomo converges to a (local) minimizer and does not fall into the worst local minimizer (since Figure 1(b) shows that Adam decreases the value of the loss function more than SGD and SGD with momentum)? \n\nMoreover, I have the following concern. \n- The optimizers use that a batch size $b$ is 128. I do not know why the setting is appropriate. In intuition, the optimizers with a smaller batch size than 128 decrease the value of the loss function. Please compare the performance of using $b=128$ with the one of using smaller/larger batch sizes than $b = 128$. I would also like to check the performances of the optimizers using a cosine annealing step-size and a step-decay step-size. Could you compare the optimizers using constant step-sizes (Table 3) with the ones using cosine annealing step-sizes/step-decay step-sizes?  \n\nTypos and minor comments:\n- Page 1, Line -9: identifie $\\to$ identify \n- Page 4, Line -14: What is \"Adafactor\"?\n- Algorithm 1, Step 9: $s_{t,i}$ is not defined? \n- Page 5, footnote 1: $\\sum_{i=1}^{i=n} \\to \\sum_{i=1}^n$",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This manuscript aims to provide a low-memory optimizer for LLMs.",
        "strengths": "* This manuscript studies a crucial problem in the field.\n* This manuscript considers fine-tuning LLaMA with various model sizes",
        "weaknesses": "* The novelty of the AdaLomo is limited. It is very close to the design of Adafactor, while no performance comparison can be found in Table 2, Figure 2, and Figure 3.\n* The convergence of AdaLomo has no theoretical guarantee. \n* Some statements are weak, as no corresponding supports can be found. For example, in the sentence ``Through our ablation study on Adam, we found that its second-order moment estimation has a significantly greater impact on its convergence than the first-order moment estimation'', the ablation study refers to which table/figure?\n* Some design choices have no justification. For example, why it is a good idea to consider $u_{t, i} / \\max(1, RMS(u_{t, i})) \\times \\max(\\epsilon, RMS(\\theta_{t-1, i}))$ (though it is borrowed from AdaFactor)? Compared to other gradient clipping ideas, and gradient normalization techniques, why current design choice is a better idea? Some theoretical justifications or empirical evidence should be provided.\n* LoRA is a parameter-efficient fine-tuning method, while AdamW and AdaLoMO are optimizers. It looks unfair to directly compare LoRA with AdamW and AdaLoMO as they are orthogonal. \n* Some other baseline optimizers need to be considered. e.g., Lion [1] and Adan [2]; or even some other memory-efficient techniques should be evaluated with any other adaptive optimizers.\n\n## Reference\n[1] Symbolic Discovery of Optimization Algorithms\n\n[2] Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models",
        "questions": "* What is the exact definition of ``SGD with variance''?\n* What is the choice of optimizer used for LoRA?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "cQgjz0mf0r",
    "title": "Deep Network Partition Density Exhibits Double Descent",
    "reviews": [
      {
        "summary": "The authors propose a method to measure the complexity of deep neural network classifiers. In particular, the measure approximates around any given input the number of convex regions that the ReLU activation induces in the input space. Empirical results demonstrate the behavior of the proposed measure in several settings of deep classifiers.",
        "strengths": "- The proposed measure seems to be useful for understanding the local complexity of the classifier while being simple and general enough to be used under different settings.\n- Many empirical results about the behavior of the measure in different settings.",
        "weaknesses": "- I think that the writing of the paper can be improved, as in many parts it was quite hard to understand the actual information. Also, in some figures, some extra information is necessary, for example, in Fig. 6 what is the difference in each panel?\n- Even if the proposed measure seems to capture the local complexity of the classifier, apart from some connections to related works, I think that a thorough analysis is missing.",
        "questions": "I think that the proposed measure is an interesting and simple approach to approximate the number of convex regions (in some sense the complexity) of the classifier around the training data. However, I do not understand how it should be used and how it helps to analyze the actual behavior of the deep classifier.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This work builds upon the Max Max/Affine Spline line of works from Balastriero/Baranuik. It shows that the partitions derived from those ideas can be used to calculate summaries that exhibit double descent phenomena during training dynamics. Experimental evaluations are presented on CNNs on MNIST, CIFAR type datasets. Grokking and batch normalization effects are also discussed.",
        "strengths": "1. The overall rationale of the work is clear. Deriving a better characterization of the training dynamics beyond inspection of the loss is generally valuable. The paper shows that repurposing the affine spline formulation does show a double descent behavior. \n\n2. The experiments are satisfactory:  a number of different architectures and datasets are used to demonstrate that the local partition complexity summary is useful. \n\n3. On the practical side, some of the heuristics proposed here make splinecam calculations faster and GPU friendly.",
        "weaknesses": "1. While I appreciate the main double descent observation and some of the experimental findings supporting it, I find the extent of daylight between this work and some of the published results a weakness. The paper does acknowledge clearly that the development will rely on the affine spline. This is not a problem, but except the double descent observation, much of the development described here veers too close to the splinecam paper at CVPR 2023. It is not obvious whether to view this paper as an empirical evaluation of the splinecam work in the context of double descent. Even several figures from that work appear in this submission directly. \n\n2. If the technical adjustments and modifications to the splinecam work are significant, it would be desirable to identify this more explicitly in the text to help the readers assess the distinction clearly. \n\n3. In the absence of new theoretical findings, the paper would also be better served by a deeper analysis of some of the settings mentioned in passing in the Introduction (e.g., self-supervised). What does the proposed characterization of training dynamics reveal in that setting?",
        "questions": "1. Can this work be viewed as applying splinecam with some moderate adjustments, and deriving a summary to check double descent behavior?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The authors propose an approximation for computing continuous piecewise affine operators in deep (ReLU, I believe) networks and then study how the (approximate) partitions evolve during model overtraining.",
        "strengths": "Overall, I think this paper is well written.",
        "weaknesses": "Overall, I think that this paper has a number of significant shortcomings. To summarize, I think \n\n1. the motivation is weak\n2. the authors dodge the hard central research question of how to make the continuous piecewise affine (CPA) operator perspective useful at scale\n3. the method is not well explained and is based on an approximation that, to the best of my ability to discern, goes untested\n3. the experiments are too simple (e.g, 1k samples from MNIST) or odd (e.g., training MNIST for 100K training steps, which is massive overkill, or changing how the MNIST targets are encoded to induce grokking)\n4. the experimental results are messy and at times unclear, with dubious connection to double descent\n\nIn detail:\n\n## Motivation\n\n> No other statistics about the DN has been found to be as informative as the loss func-\ntion\n\nI think this claim is untrue. My understanding is that there is work in the deep kernel literature in both lazy learning and feature learning regimes, e.g., [1, 2] and mechanistic interpretability literature, e.g., [3, 4] about studying DN learning dynamics using more granular statistics than the loss function.\n\nIf the authors do wish to advocate for a CPA perspective, which is valid, they should make a case of (1) what properties we want deep network learning statistics to reveal, (2) why other existing approaches are better and (3) why CPA is the right way to go. But I don't see this, and thus I am left wondering \"Sure, we _can_ take a CPA approach, but what are we looking for that we don't already have and that CPA can provide?\"\n\n[1] Bordelon, Canatar & Pehlevan ICML 2022. Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks.\n\n[2] Bordelon & Pehlevan NeurIPS 2022. Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide Neural Networks.\n\n[3] Nanda, et al. ICLR 2023. Progress measures for grokking via mechanistic interpretability.\n\n[4] Liu, Kitouni, Nolte, Michaud, Tegmark, Williams. NeurIPS 2022. Towards Understanding Grokking: An Effective Theory of Representation Learning\n\n> In this study, we provide a novel statistic that measures the underlying DN\u2019s\nlocal complexity, exhibiting two key benefits: [...] (ii) it is informative about the training loss and accuracy dynamics.\n\nPrevious work gave loss error bounds as a function of the number of non-overlapping regions in continuous piecewise affine operators in DN [1] and studied their performance empirically, so this manuscript\u2019s second main claim (that changing local complexity results in changing loss and changing accuracy) seems unsurprising.\n\nAt a minimum, I would recommend the authors cite [1]. I also happened to attend a talk by the first author of [1] and Professor Shai Ben-David in the audience said that the authors of [1] were ignoring significant amounts of prior work from the 80s-2000s; while I myself don\u2019t know the correct citations, I suspect that the authors of this manuscript might also want to do an older literature search. (Note: I am unaffiliated with [1] and with Professor Ben-David.)\n\nI should also note that this manuscript\u2019s Fig 2 almost exactly matches [1]\u2019s Fig 1b.\n\n[1] Ji, Pascanu, Hjelm, Lakshminarayanan, Vedaldi CoLLAs 2022. Test Sample Accuracy Scales with Training Sample Density in Neural Networks. \n\n> In fact, our development will heavily rely on the affine spline formulation of DNs\nBalestriero & Baraniuk (2018). Such formulation is exact for a wide class of DNs which naturally\narise [...]  nonlinearities such as max-pooling, (leaky-)ReLU.\n\nI might be mistaken, but does the CPA perspective apply to more modern nonlinearities? Balestriero and Baraniuk 2018 studied ReLU, Leaky ReLu and absolute value, but many modern models use newer nonlinearities like GeLU and SwiGLU, used in ViT and LLMs e.g. Llama 2. I guess my question is: to what extent is CPA applicable only to certain classes of nonlinearities?\n\n## Method\n\n> Moving to deep layers involve a recursive subdivision Balestriero et al. (2019) that goes beyond the scope of our study.\n\nMy understanding is the key reason why the CPA perspective has struggled is because of the combinatorial complexity. Waving this aside amounts to waving aside the key research challenge with CPAs.\n\n> Equation 3\n\nWhat is the notation $\\partial \\Omega$? Is equation 3 a definition?\n\n> The key insight we will leverage however is that the number of sign changes in the layer\u2019s pre-activations is a proxy for counting the number of regions in the partition. To see that, notice how input space samples who share the exact same pre-activation sign effectively lie within\nthe same region \u03c9 \u2208 \u03a9 and thus the DN will be the same affine mapping (since none of the activation functions vary). Therefore for a single layer, the local complexity for a sample in the input space can be approximated by the number of hyperplanes that intersect a given neighborhood V which is itself measure by the number of sign changes in the pre-activations that occur within that neighborhood.\n\nI think this is a key point that should be explained in more detail, with examples and/or figures and/or equations.\n\nAlso, doubling back to my question, I\u2019m unsure of whether the insight still holds with depth. One would imagine that multiple regions at layer $i$ might be mapped to the same region at layer $i+1$ or $i+2$.\n\n> Note that for deeper layers, our complexity measure is actually computing the number of hyperplane intersections with the convex hull of the embedded vertices instead of the convex hull of the vertices in the input space.\n\nThis comment is somewhat concerning. This comment suggests that the quantity one desires (the convex hull of the vertices in input space) has subtly shifted to a different quantity (the convex hull of the embedded vertices) and how these two are related (if at all) is not analyzed, discussed or explored mathematically or empirically.\n\n> We control the size of the local neighborhood by controlling the diagonal lengths via the r parameter mentioned in section 3.2.\n\nI cannot identify an $r$ parameter in Section 3.2, and this $r$ parameter seems to be important for subsequent experiments.\n\n## Experiments\n\nBefore delving into the experiment, the proposed approximation (Section 3.1 & 3.2) is not yet validated. One would first want to know: how well does this method approximate the full (and extremely expensive) partition computation? How many orthogonal vectors are necessary to get a good approximation, and how does this depend on the data, architecture, and other implementation choices? What effect does the parameter $r$ have? As best as I can tell, there is no answer to these questions.\n\nThe closest answer I can find is Section 3.3, which compares this method against SplineCAM in 1 architecture (depth 3 width 200 MLP) on 500 MNIST samples. This feels inadequate to me for two reasons:\n1. I want a comparison to an exact baseline. But whether SplineCAM is exact is unclear. The authors call SplineCAM both an approximation (\u201cwith the local partition density approximated via SplineCAM\u201d) and exact (\u201cSplineCAM is an exact computation method\u201d). SplineCAM also appears to be limited (\u201cSplineCAM can only be used to compute the local complexity for 2D neighborhoods\u201d), which an exact method should not be.\n2. Even if SplineCAM is exact, I see no characterization of how the number of orthogonal dimensions, or $r$, or architecture, or dataset plays a role.\n\nConsequently, I am left with no understanding of how good this approximation is or under what conditions the approximation is good. This makes me skeptical of the subsequent experimental results.\n\n> We perform experiments on MNIST with fully connected DNs and on CIFAR10 with CNN and Resnet architectures\n\nDespite this claim, it appears to me that _most) of the experiments focus on a subset of 1k data from MNIST (Figures 1, 3, 6, 7, 8, 9, 10). The CIFAR experiments, while fewer and less prominent, are performed on 2.5k data. In 2023, such small networks trained on such simple data feels too inadequate. Moreover, the training diets seem bizarre. Most of the models appear to display high plateau accuracy within ~100 optimization optimization steps, but training continues till 100000 training steps without motivation or explanation. Models are known to exhibit strange behaviors with such long training diets (e.g., neural collapse) so I am skeptical that we should be studying networks in such late atypical stages. I personally have never seen anyone train MNIST to 100k gradient steps unless they're looking for atypical model behavior.\n\n> For the MNIST and CIFAR10 experiments with fully connected and convolutional networks, we use p = 25 as the dimensionality of the hypercubes that define the neighborhood.\n\nI don\u2019t know why p=25 was chosen, and it would be good to see some sensitivity analysis to how much $p$ affects the results.\n\n> As depicted in the top-right figure, the amount of region near training samples follow a double descent curve ultimately falling until training is stopped\n\nThere are two oddities with the Figure 1 result. \n\n1. Double descent is almost always observed as a function of parameters to data, not optimization steps.\n2.  The _train_ loss peaks, even though double descent is characterized by the _test_ loss peaking.\n\nNow, perhaps the authors do not mean \u201cdouble descent\u201d in the way that is commonly used. If so, I would urge them to avoid such terminology. But if not, this needs clarification.\n\n> For all the depths, the accuracy on both the train and test sets peak during the first descent phase. \n\nGiven that train and test accuracy plateau seemingly within ~10 gradient steps, I am confused why the models are trained to 100,000 gradient steps. Moreover, most fluctuations and interesting patterns of LC occur beyond ~100 gradient steps (typically past the point that accuracy has saturated), leading me to be skeptical why we are looking at such extremely late training dynamics.\n\n> Figure 3:\n\nWhy is the training LNL so spikey but the test LNL so smooth? \n\n> Figure 4: Effect of Batch Normalization on Double Descent\n\nI see no divergence of the test loss near an interpolation threshold. What does this have to do with double descent? And again, double descent is a phenomenon typically described with data to parameters, not gradient steps.\n\n## Minor:\n\n> \u201c As such, as pose the following question,\u201d\n\nAdd a subject to this sentence e.g.,  \u201cAs such, we pose the following question,\u201d\n\n> which naturally arise form the\n\n\u201cform\u201d should be \u201cfrom\u201d",
        "questions": "Most of my equations are integrated into Weaknesses. To extract a few:\n\n1. Is Equation 3 a definition? What is the $\\partial \\Omega$ notation?\n\n2. What is the parameter $r$? \n\n3. Is SplineCAM an exact method? If so, why does it only work in 2D?\n\n4. Broadly, what do you mean by double descent?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes a new measure of the local complexity of functions that deep networks (abbrv. DN) learn throughout training.  The authors develop this measure as a follow up to work establishing a large class of DNs as a composition of max-affine spline operators, which distinguishes their model of DNs from those that uses information theoretic tools.  They use their measure of complexity to examine different phenomena exhibited by DNs during training (grokking, double descent, memorization), and explain them in light of their local complexity formalism.",
        "strengths": "- This paper is well written, and builds solidly on prior work by [Balestriero et al.](https://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf). \n- The motivation of the theory is well developed in section 3.1\n- The experiments are well motivated also, and address some of the most relevant phenomena observed in DN training dynamics.\n- Many other papers that attempt to explore local representations of deep network points usually rely on a trust region about a point, and make assumptions about the geometry of a latent representation space.  It's interesting to me that the authors instead use a convex hull to construct the neighbourhood, though they might want to spend a bit more time motivating this choice (if it's the best choice given their [earlier work](https://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf)., another citation would not go amiss here).",
        "weaknesses": "- The biggest weakness in the paper seems to be that a critical part of it is missing.  The experimental setup in section 4.1 states \n> We control the size of the local neighborhood by controlling the diagonal lengths via the $r$ parameter mentioned in section 3.2\n\nBut section 3.2 makes no mention of a parameter $r$, and it is difficult to make a full evaluation of the experiments in section 4 absent a definition of $r$.\n\n- There is a line of prior work that seems closely related to the authors' own proposed work, which is the idea of polytope lenses by [Black et al.](https://arxiv.org/abs/2211.12312).  Briefly, this work attempts to look at polysemy of neurons by using ideas from casting neural networks as compositions of splines, though they are chiefly interested in interpretation rather than complexity.  I think this paper would be made stronger by contrasting the ideas in Black et al to this work's own, by showing the benefit of viewing DNs as splines has multiple uses.\n\n- The lack of a need for labels makes this measure ripe for helping to help explain the effects of self-supervised learning.  I'm a bit surprised that the authors don't include experiments for why (e.g) BYOL can work by measuring the local complexity of teacher & student networks as they train, and iteratively replace each other.\n- This is a minor point, but it would be helpful for the authors to spend a few words about why the cost of computing the $P$ orthonormal basis vectors for each $x$ either isn't prohibitive, or why it might be in certain cases. \n- Re-reading section 3.1, I'm surprised to see no characterization of the properties of $[\\mathbf{v}_1, \\dots, \\mathbf{v}_P]$ other than they form an orthonormal set, and that $x$ is within $conv(\\mathbf{V})$.  This latter point is implied but not stated.  Maybe 3.1 could do with some more care in specifying the relation between $\\mathbf{x}$ and $\\mathbf{V}$?  \n\nOther minor points:\n- italicized sentence at the end of the second paragraph of the introduction has some typos.  But it's compelling!\n-  If this sampling procedure is for each sample input, it\u2019s going to become really expensive computationally.  How do they compute a succession of P orthonormal vectors, is this by Gram-Schmidt (or similar procedure?). Is there any way to amortize this complexity?  I think it would help make this measure more practically helpful",
        "questions": "- How stable is local complexity about a point $\\mathbf{x}$ as a consequence of the choice of $\\mathbf{V}$?  And choice of $\\mathbf{P}\"?  These seem like important questions to answer.\n- The authors intentionally leave out extension of this to deeper networks, as a clear continuation of this line of work.  But I think the conclusion would be strengthened by spending some more of the word budget to help lead the reader into how the authors plan to do so.\n- Do the authors have any conjecture about how the partition migrating dynamics relate to the phenomenon of neural collapse?\n\nTo conclude, I think this is a good paper that needs a bit more work and polishing to become a really good paper.  If the authors will consider the points I've raised here (and in the weaknesses section), I'm willing to raise my score.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "i8PjQT3Uig",
    "title": "Locality Sensitive Sparse Encoding for Learning World Models Online",
    "reviews": [
      {
        "summary": "The paper introduces a model-based reinforcement learning approach that utilizes a sparse representation-to-representation model. The use of sparse representation aims to address the challenge of catastrophic forgetting in a reinforcement learning (RL) setting, where data generation constantly shifts. The architecture employed for model-based reinforcement learning is Dyna. The proposed method involves learning nonlinear sparse features and building a model based on this sparse representation. To enhance computational efficiency, a method for updating model weights using sparse representation is presented. Empirical experiments are included to demonstrate the effectiveness of this approach.",
        "strengths": "1. The paper targets an important topic of learning a model in RL \n\n2. I do not see many related works of building sparse representation-based models.",
        "weaknesses": "I will list below main weaknesses for improvements, centred around the main contribution of the paper. \n\n1. Is there any reason for why the particular sparse representation learning method is chosen? Furthermore, in the experiments part, FTA should also be compared as a baseline. It is unclear why you compare it in a supervised learning setting but omit in a RL setting. The performance on a SL setting does not invlidate/validate another. As an empirical paper, I think a rigorous comparison is necessary. \n\n2. Could you clarify do you update both your model and representation every environment time step? \n\n3. There is a critical weakness in the paper: the paper claims to develop a sparse representation-based approach for model learning, but it is not justified the reported benefits come from the use of the sparse representation for policy learning or for model learning. Note that the former has been extensive studied. in general, a full replay method should be the best in mitigating catastrophic forgetting, but the empirical results reported that the proposed algorithm can sometimes even outperform full replay. That raises a natural question that the benefit mainly comes from the policy learning part by using sparse representation, rather than the proposed model learning part. \n\n4. other issues. \n\nAlg 1. it is better to be specific, use the title Dyna architecture, rather than MBRL, as there are numerous MBRL algorithms and not everyone is as Alg 1 described. \n\nAlg 2, line 4 & 5: shouldn\u2019t it be outer product? Please specify the dimension of the matrices capital Phi and letter phi. This is nontrivial as it affects the understanding of the algorithm. \n\nThe term \u201cworld model\u201d might intrigue the readers to see much more challenging tasks than the paper presented, this can be seen by other papers using such terms. It is better to rephrase it to be more precise.",
        "questions": "see above.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper presents a method for the online learning of a world model for model-based reinforcement learning (MBRL). To obtain efficient updates to the world model, the world model is expressed as a linear combination of a set of spare features. This efficiency allows online learning at a constant computational cost.",
        "strengths": "The work is well motivated in the introduction and a sufficient and clear background is provided for non-expert readers in the preliminaries section. The algorithms, definitions, etc. are mathematically rigorously presented. \n\nA comprehensive set of experiments has been conducted demonstrating the efficacy of Losse-FTL",
        "weaknesses": "Significant discussion around catastrophic forgetting was mentioned in the introduction but little discussion is presented in the main text and left in the appendix.\n\n\u201cExample 3.1\u201d could be a regular paragraph. Formatting this as an Example does not improve readability and is, in fact, the only Example in the entire paper.",
        "questions": "In figure (1): d(s_(t+1), f(st, at)) and \\delta were not defined in the caption or anywhere obvious in the main text.\n\nIn eq (3), does || . ||^2_F denote the Frobenius matrix norm? It is only stated so after eq (5). It helps to have the notation introduced earlier here. Especially since \u201cF\u201d is the dimension of the feature space",
        "rating": "8: accept, good paper",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper presents a world model for model-based reinforcement learning (RL) which can be learned online and does not\nrequire full retraining on all previous data.\nThe authors highlight that training world models is subject to issues arising in continual learning.\nThat is, each sequential data set can be interpreted as coming from a new task and thus the world model needs to be retrained\nafter each agent-environment interaction.\nThis is because the data collected via agent-environment interaction is non-stationary.\nThey propose a world model based on a linear regression model which uses high-dimensional nonlinear features.\nImportantly, the linear model can be updated given new data whilst retaining good predictive performance on old data.\nThey compare their feature encoding method to other feature encoding techniques in an image denoising task on MNIST.\nThey then evaluate their method's ability to handle training data covariate shift in an artificial online learning experiment.\nFinally, they evaluate their method's ability to combat non-stationary data in model-based RL.",
        "strengths": "This paper addresses an important problem in model-based RL, which is likely a problem that must be solved for developing lifelong agents.\nThe method for updating the linear model online is simple but appears to be effective.\nThis is also the first time I have seen a non-trainable encoder used for world models.\nIt is very common to see world models with NN encoders and NN transition models operating in the encoder's latent space.\nTypically the dynamic model operates on a latent state which is lower dimensional than the high-dimensional observations.\nPerhaps I am not aware of the relevant literature, but this seems like an interesting and original idea.",
        "weaknesses": "This paper has two main weaknesses.\nFirstly, there is no comparison to state-of-the-art MBRL strategies that use world models, e.g. Dreamer/TD-MPC.\nAs such, there is no experiment highlighting the main issue that the paper is trying to address:\nthat NN-based world models suffer from catastrophic interference due to non-stationary data.\nSecond, all of the RL experiments are in simple RL environments.\nFrom the current results, it is impossible to know how practically useful this world model is.\nThere is no discussion about its limitations nor is there a comparison to other model-based RL algorithms that use world models.\nSure the proposed method works on some simple RL environments but can it scale to difficult environments like humanoid and can it handle image-based observations?\nIt is OK if the method cannot do this but it should be addressed in the text.\nMoreover, it should be made clear what benefit it does have over other world model methods (like Dreamer).\nFor example, I'd like to see a state-of-the-art world model method (like Dreamer) performing poorly/failing because it cannot handle non-stationary data.\n\nI also have questions regarding the training of the NNs in the experiments.\nDid the full-replay experiment involve resetting the neural network's weights? If so, what initialization was used?\nWhen was the NN training stopped? Was the data split into train/validation sets and used to stop training when the\nvalidation loss stopped improving?\nThe paper needs more details to explain exactly how this was implemented.\nIn my experience, these steps are important to ensure the NNs don't overfit on early data sets.\n\nI am also unsure why the full-replay strategy (which is model-based), does not appear to have better sample\nefficiency than the model-free experiment. Am I missing something here?\nPerhaps this is an interesting point for discussion. Do the high-dimensional features sacrifice sample efficiency\nin favour of formulating a linear model which can handle the non-stationary data?\nI'm not sure if this is correct.\nMy main point here is that the paper has not answered all of my questions about the method.\n\nThe experiments tell the first part of a nice story.\nTable 1 compares to other encoding methods and Fig. 3 clearly shows how the method handles covariate shift better than NNs.\nFig. 4 also acts as a nice ablation for comparing the method to other CL strategies within the same set-up.\nHowever, the experiments section lacks a comparison to other MBRL strategies which use world models.\nIn particular, there is no experiment highlighting the main issue the paper is trying to address.\nThat is, there is no MBRL experiment failing due to the non-stationarity of the training data.\n\nMinor comments and corrections:\n- The abstract is very long. I would recommend shortening it.\n- Sections shouldn't lead straight into subsections (Section 4/4.1, 5/5.1, B/B.1, C/C.1). There should be text explaining what the reader can expect to read in the section.\n- In the first paragraph of Section 2.2, the reward function is defined as $R(\\mathbf{s}, \\mathbf{a}, \\mathbf{s}')$ but then in the optimal policy equation you use $R(\\mathbf{s}, \\mathbf{a})$.\n- Fourth line of Section 2.2 the initial state distribution is $\\rho$ but earlier it is $\\rho_0$.\n- Third paragraph of Section 2.2 - \"We firstly formulate\" should be \"We first formulate\".\n- Section 2.1 - \"When the input is a convex set $\\mathcal{S}$, the prediction a vector $\\mathbf{w}_{t} \\in \\mathcal{S}$\". This sentence doesn't read properly.\n- $\\rho$ is used to denote the initial state distribution and to denote the dimension of the grids in Section 3.2.\n- What is the value of $\\delta$ in Fig. 1?\n- What are $\\pi_0$, $\\pi_t$ and $\\pi_{t'}$?\n- The first sentence of the abstract says model-based RL has better sample efficiency. Better than what? It's model-free counterparts?\n- It is unusual to end the paper with a section titled \"Summary\". I recommend changing this to \"Conclusion\".",
        "questions": "- What are the limitations of the proposed method? Can it handle image observations? Can it scale to difficult environments like Humanoid?\n- Why haven't you compared to any other world model algorithms? E.g. Dreamer, TD-MPC.\n- How was the NN full-replay experiment implemented? Did the full-replay experiment involve resetting the neural network's weights? If so, what initialization was used? When was the NN training stopped? Was the data split into train/validation sets and used to stop training when the validation loss stopped improving?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Accept"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "e47RxA52sT",
    "title": "Towards Relaxing the Unbiasedness Condition of Doubly Robust Estimators for Debiased Recommendation",
    "reviews": [
      {
        "summary": "This paper proposes User-DR, Iten-DR, and User-Item-DR for unbiased recommendation. The proposed methods have both strong theoretical guarantees and improvement in comparison with the baselines.",
        "strengths": "1. Strong theoretical guarantee on the proposed method\n2. The experimental studies are solid. I would like to point out that a ~10% improvement in NDCG@5 is very significant for unbiased recommendation. Note that the machine learning model is not changed in this paper. To be more accurate, only the debiased method is different from the baselines if I understand correctly!",
        "weaknesses": "1. Some baselines are lacking introduction. For example, the best baseline, ESCM-DR, is not introduced in detail.\n2. The running time (or time complexity) is lacking in analysis in the paper. I think this paper can be improved if ESCM-DR is slower than the proposed algorithms.\n3. The evaluation matrics, AUC, NDCG, and F1, are missing clear definitions (can be in the appendix).",
        "questions": "1. Can the authors provide some detailed explanations for ECSM-DR and Multi-DR?\n2. Any record of the running time (or time complexity) can be provided?\n3. Can the authors provide a rigid definition for F1 measure?\n4. Can the authors also provide the experimental results similar to Table 3 for NDCG and F1 @ other values in the appendix? At least for Coar and music datasets, Top-1 should be also an important measure.",
        "rating": "8: accept, good paper",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper presents a study on the challenges and potential solutions associated with debiasing the recommender system models due to the sampling selection bias in the process of data collection. The authors propose several novel doubly robust estimators that are unbiased.\nThese estimators are unbiased for arbitrary user-specific, item-specific inductive bias, and even both. Authors also theoretically prove these estimators\u2019 unbiasedness. Besides, they propose a propensity reconstruction learning approach that adaptively updates the constraint weights to meet the constraints of the proposed UIDR estimator.",
        "strengths": "(1) The authors introduce a series of innovative double robustness (DR) estimators through a rigorous theoretical framework. These estimators maintain their unbiased nature even when pseudo labelings diverge from the true labels, accommodating arbitrary and unknown biases specific to users, items, or a combination thereof. This represents a significant stride in addressing user-specific and item-specific inductive biases, showcasing the adaptability and robustness of the proposed methods.\n\n(2) In a further extension of their work, the authors present a principled propensity reconstruction learning strategy, which adeptly utilizes an attention mechanism to adaptively update the constraint weights. This approach not only enhances the adaptability of the model but also ensures that the variance of the DR estimators remains within controllable and manageable bounds. This aspect of the work underscores the authors\u2019 commitment to developing robust and reliable estimators, contributing to the stability and efficacy of the proposed methods.\n\n(3) The paper\u2019s empirical validation is robust, encompassing semi-synthetic experiments that attest to the effectiveness of the proposed methods in scenarios involving arbitrary user-specific and item-specific inductive biases. This is a notable achievement, as previous methodologies have fallen short in providing unbiased estimates of the ideal loss under these conditions. Additionally, the authors extend their validation to real-world contexts, conducting comprehensive experiments across three real-world datasets. These experiments serve to highlight the tangible advantages and superior performance of the proposed methods, solidifying the paper\u2019s contributions to the field.",
        "weaknesses": "(1) While the theoretical foundation appears robust, there is a potential concern regarding the complexity and practicality of implementing such estimators in real-world scenarios when we have large U and large I. The paper could benefit from a more detailed discussion on the potential challenges and limitations associated with these novel DR estimators, providing a more balanced and critical perspective.\n\n(2) The introduction of a principled propensity reconstruction learning approach, utilizing an attention mechanism to adaptively update constraint weights, is indeed a novel contribution. However, the claim that the variance of the DR estimators is highly controllable and manageable warrants a more rigorous scrutiny. Can we see any tradeoff between the bias and variance, since sometimes we want to minimize the MSE in the ML community when you mentioned controllable and manageable.",
        "questions": "1. In section 2, it seems that $r_{u,i}$ in [0,1] rather in R, which is the rating/\n\n2. After corollary 1, \u201cthe biases of the proposed DR estimators are still strictly smaller than the previous DR\u201d , Is this toy example realistic? Could you please show a real example here?\n\n3. For the optimization problem, do we have a constraint that $\\tilde{p}$ < 1? \n\n4. What is A? What is b? What is $s_{u}$ and $t_{I}$? How do we learn it? Why $s_{u}$ has been applied tanh but $t_i$ is not been applied?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper presents a new doubly robust estimator for the missing-not-at-random bias.\nThe authors propose constraints on propensity scores to handle pseudo-labels deviating from the true value with the user-specific bias.\nThey provide theoretical analysis and practical experiments, showing how their approach outperforms benchmark methods.",
        "strengths": "- the solution (a constrained propensity model) is simple yet effective.\n- the authors provide theoretical analyses on the unbiasedness and the variance of the proposed estimator.",
        "weaknesses": "- the target problem is too specific and minor. The authors noted that UIDR can effectively alleviate the \"inaccurate pseudo-labeling problem\" in the previous DR estimators. However, they only treat the situation where the pseudo-labelings deviate from the true labels with arbitrary user-specific inductive bias. This assumption looks quite unrealistic as the user-specific inductive bias is assumed to be equivalent for every item.\n- the proposed procedure is not well-motivated. The authors put constraints on the propensity model, not the imputation model, in order to tackle the inaccurate imputation model. If the imputation model is inaccurate the straightforward remedy would be either adjusting the imputation model itself or designing a new loss function robust to the inaccurate imputed errors. If we adjust the propensity model for the imputation model, the accuracy of the propensity model can be harmed.",
        "questions": "- please refer to weaknesses.\n- ex) If we adjust the propensity model for the imputation model, how does the accuracy of the propensity model become?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper introduces a novel doubly robust estimator to address observational bias in collaborative filtering.\\\nIt focuses on the effectiveness of the method, particularly in handling inaccurate pseudo-labels. \\\nThe authors propose debiasing techniques with constraints on propensity scores, aiming to ensure unbiasedness when the pseudo labels deviate from the true labels with an arbitrary inductive bias. \\\nThe paper combines theoretical analysis and experimental evaluations to demonstrate the method's effectiveness in comparison to benchmark approaches.",
        "strengths": "1. Comprehensive Background: The authors provide a well-explained introduction and extensive coverage of prior related work, enhancing the paper's accessibility to readers by providing context and a clear understanding of the research landscape.\n\n2. Novel and Effective Method: The proposed method effectively addresses the issue of pseudo-labels deviating from true values with specific inductive bias.\n\n3. Theoretical and Empirical Validation: The paper combines theoretical analysis with empirical results, covering both semi-synthetic and real-world datasets, demonstrating the method's technical soundness and its superior performance compared to existing approaches.",
        "weaknesses": "1. Limited Motivation: The paper may lack novelty in the central idea. Is there any empirical evidence that existing pseudo-labeling suffers from user/item specific inductive bias? If users have an inductive bias in the training set, the user should have the exact inductive bias in the test set.\n\n2. Strong Assumptions: The assumptions regarding inductive biases for users and items might not be realistic. The paper assumes constant inductive biases for users across all items, which may not hold true in real-life scenarios. Users typically exhibit varying preferences for different items.\n\n3. Unclear Propensity Score Calculation: The paper lacks a clear description of how propensity scores were calculated. There is a need for a more detailed explanation.",
        "questions": "1. Personally, I cannot understand the intuitive concept of the experiment with the synthetic dataset. Can you explain the intuition?\n2. Is there any empirical or theoretical evidence for the motivating inductive bias problem?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "JWrl5pJCnl",
    "title": "Instruct2Act: Mapping Multi-modality Instructions to Robotic Arm Actions with Large Language Model",
    "reviews": [
      {
        "summary": "The paper looks at the problem of generating control programs for robotic control with the help of foundation models. Part of the functionality that can be leveraged in the program are based on visual (SAM) and visual-language (CLIP) foundation models. The programs themselves are obtained by prompting an LLM. The prompt is equipped with external libraries, function descriptions and example programs. The method is tested on benchmarks with text only instructions as well as text-visual instructions and performs competitively. Extensive ablation studies show the importance of individual elements of the prompt and how the choice of foundation models impacts performance. The model shows OOD capabilities, that cannot be achieved by prior methods.",
        "strengths": "- Extensive ablation studies that showcase specific abilities of the model (types of OOD generalization), investigate the role of the foundation models and study the importance of the components of the prompt. \n\n- Removing the dependence of engineered perceptual models from the CaP method by using foundation models.\n\n- Slight improvements over CaP via the different prompting method.\n\n- The methods and results are presented in an understandable manner.",
        "weaknesses": "- Standard Errors: The VIMABench experiments were run over three random seeds for each meta-task but results are reported without any standard errors? In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?\n\n- Choice of baselines: For the VIMABench I find the choice of baselines not insightful. On the one hand the baselines make use of a large set of training trajectories, but on the other hand these methods train policies that choose low-level actions. The presented method chooses action primitives such as \"PickAndPlace\" but does not need much training data (apart from the examples). I think adapting CaP to the VIMA benchmark would be a more insightful baseline. \n\n- I think it makes sense in the comparison with CaP to compare using an oracle object detector, but one of the main novelties of the work is replacing the perceptual modules of CaP with foundation models. Therefore it would be interesting to see how this affects performance, i.e. just run the method on the CaP benchmark without the oracle.\n\n- Too much detail in related work: I think the related work section is too long and just a list of papers rather than helping to place the work in the research area. I would shorten it and move interesting results from the Appendix to the main paper.",
        "questions": "- Paragraph 4.4: What does RR stand for? \n\n- Are the example programs in the prompt fixed for every task or do they depend on the task ?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The proposed methodology introduces a way to utilize existing off-the-shelf vision and language foundation models for solving robotic tasks. The framework can be conditioned on language and or visual input, and produces Python programs for completing the given task. Experiments in both simulation and the real world demonstrate that the proposed system can outperform baselines.",
        "strengths": "- Well-written. The paper is very well-written and easy to follow. The figures very much aid in understanding the paper.\n- Ablations. Ablations are conducted to better understand various design choices of the proposed methodology.",
        "weaknesses": "- Unfair comparison to baselines.\n  - CaP\n    - The proposed work's claimed distinction with CaP is unclear. The authors write \"Unlike existing methods such as CaP (Liang et al., 2022), which directly generates policy codes, our approach generates decision-making actions that can help reduce the error rate when performing complex tasks.\" But, the proposed methodology also uses LLMs to generate Python programs, so the distinction is unclear. Furthermore, about CaP, the authors write: \"However, its capabilities are limited to what the perception APIs can provide, and it struggles with interpreting longer and more complex commands due to the high precision requirements of the code.\" This seems to be a limitation of the proposed methodology as well, which also relies on a finite number of available APIs. Hence, again, the distinction between the proposed methodology and CaP is unclear.\n    - Why is the oracle version of the proposed method used when comparing to CaP, instead of the non-oracle method? This seems to be an unfair comparison.\n    - Even then, the performance gap seems trivial. Is there any evidence to suggest that the gap in performance is non-trivial?\n  - PerAct\n    - The authors write: \"For simple 3D tasks, such as stacking objects, we introduced an additional parameter to indicate the current occupancy. For more complex tasks, such as opening a drawer, we added some heuristic movements to ease the execution.\" PerAct was able to operate without such simplifying assumptions, which makes this comparison unfair. \n    - Even then, the performance gap is very small. How do we know this is a non-trivial gap in performance? Is there a trend of tasks / cases where the proposed methodology succeeds and PerAct fails? What is the intuition behind the proposed methodology outperforming PerAct, which was trained directly for the task at hand? \n  - Decision Transformer\n    - How was comparison to DT done, as DT doesn't take in language instructions?\n    - What is the intuition behind the page gap in performance between the proposed methodology and DT?\n- Simplistic Tasks.\n  - The tasks considered for evaluation seem limited in complexity, e.g. are simply pick-and-place like tasks. These are tasks which can be very easily solved. More complex tasks have not been explored.\n  - Furthermore, as the \"Generated Policy Code\" in Figure 3 depicts, there is an API for pick-and-place, which the system simply calls upon. This simplifies the already simple problem quite a bit, by abstracting away the more difficult low-level control.\n  - Finally, a lot of processing / engineering is done to get the system to work (e.g. applying a gray threshold filter followed by a morphological closing operation, a morphological opening operation, Non-Maximum Suppression, etc.). If all of this engineering was required to get a simple task like pick-and-place to work (which is further simplified with the use of a pick-and-place API), then I find it difficult to see how the proposed methodology could be extended to more complex manipulation tasks, thereby limiting its utility.",
        "questions": "- \"Although the language models may occasionally generate incomplete or incorrect code, such as missing brackets, punctuation, or mismatched cases, the Python Interpreter can detect these errors and prompt us to generate new code.\"\n  - What is done in these situations? Is the LLM simply prompted a second time, with the hope that the output will not contain incomplete or incorrect code?\n- How much prompt engineering went into this when evaluation? Were the prompts the same across tasks, and across methods (ie when comparing to the baselines)?\n- How computationally expensive / slow is the framework? Can the tasks be solved in real-time?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper presents Instruct2Act, a framework that leverages Large Language Models (LLMs) to convert multi-modal instructions to sequential actions for robotic manipulation tasks. It uses pre-defined APIs to access multiple foundation models. Its approach is validated in both simulation and real-world experiments.",
        "strengths": "1. Instuct2Act represents a whole pipeline from utilizing multimodal instructions to actions. This is meaningful in embodied ai domain.\n\n2. It can handle a diverse range of task types.\n\n3. This paper includes suckers and gripper in simulations, and conducts real-world experiments.",
        "weaknesses": "1.\tThe embodied ai plus LLM develops too fast. It seems that this paper a little bit lacks of novelty. Instruct2Act seems like the combination of VIMA and CaP.",
        "questions": "1.\tI think the author should add GPT-4 api and Codellama in ablation? \n\n2.  What\u2019s the main improvement of Instruct2act? Could the authors list some difference between Instruct2act and VIMA, except for using foundation model to detect the objects?\n\n3.\tFor the franka manipulation, as the paper mentioned: 'Our method is presently limited by the basic action primitives, such as Pick and Place.' So, the franka-based tasks also uses the action primitives?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This study targets the challenge of robotic manipulation tasks utilizing a Large Language Model (LLM) guided by multi-modal instructions. The efficacy of this approach has been tested with various instructions across different benchmarks including VIMABench and the CaP benchmark.",
        "strengths": "1. This system conducts experiments on diverse benchmarks such as VIMABench and the CaP benchmark.\n\n2. Detailed ablation studies are also provided, highlighting the efficacy of 'Library API Full Examples' and different segmentation methodologies.",
        "weaknesses": "1. Important related work RT-2 [1] is missing, likely because it is too recent to be included and discussed. \n\n2. The improvement in performance is not robust. Figure 5 showcases results from evaluations on VIMABench. However, the baseline VIMA-200 performs slightly better than the suggested approach across all tasks. Although the authors argue that VIMA requires large-scale pre-training, their proposed method also depends on large-scale pre-trained foundation models, such as SAM. It would be beneficial for the authors to demonstrate performance gains on tasks where VIMA has not been trained. Furthermore, the performance gain of 3% over PerAct and 1% over CaP in Table 1, is also not significant. \n\n3. Although employing cursor clicks to create point prompts and guide SAM\u2019s segmentation is clever, applying this approach for the Pick and Place task seems unnecessary. If you have the camera extrinsics, you can easily obtain the 3D location of the click by projecting from the image space to the 3D space, given the depth or known height. In this case, there's no need for SAM. In fact, other example tasks should be selected to better highlight the advantages of the proposed method.\n\n\n[1] Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K., ... & Zitkovich, B. (2023). Rt-2: Vision-language-action models transfer web knowledge to robotic control. arXiv preprint arXiv:2307.15818.",
        "questions": "This work mentions the utilization of two types of LLMs: text-davinci-003 and LLaMA-Adapter. Could you provide an explanation on the performance differences between these two?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "uvYgx8raPO",
    "title": "Trust-Region Method Based on Probabilistic Models for Multi-Objective Optimization",
    "reviews": [],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "jUNSBetmAo",
    "title": "Beyond Disentanglement: On the Orthogonality of Learned Representations",
    "reviews": [
      {
        "summary": "This paper considers the question of evaluating the quality of disentangled representations with respect to the orthogonality of factors. The authors propose latent orthogonal analysis used to devise a new metric called importance weighted orthogonality. The method is evaluated on several datasets and shows promising results.",
        "strengths": "The research question is strong and to the best of my knowledge this problem is still open at large, and so any advancement on this front is highly important. Another strength is the relative simplicity of the approach, involving basic neural networks and standard linear algebra operations. The results are also compelling, although somewhat basic, in my opinion.",
        "weaknesses": "The main weakness of this submission is the clarity of exposition. In particular, Sections 2 and 3 could be improved significantly. For instance, the illustration in Fig. 1 is unclear. I believe the authors could do better by considering a 2D case instead of 3D, minimizing the use of colors and angles in the figure. Further, several crucial algorithmic components are described in a minimal fashion with supporting equations,illustrations, or pseudo-code. For example, the text above Eq. (2) and the text above Eq. (4). Given that the proposed method does not seem to be overly complex, I find it disappointing that its description is somewhat vague.\n\nAnother weakness is the evaluation section. Evaluating disentangled factors is a long-standing problem in representation learning. In particular, there are established benchmarks and papers focused on this particular problem. While I am not an expert on this issue specifically, I would assume that suggesting a new metric that is arguably better than others should be motivated better and empirically justified with more than two real-world datasets and a few toy examples.",
        "questions": "See above",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "A new assessment scheme is introduced to measure disentanglement in latent space in terms of orthogonality between subspaces. The assessment builds on an decomposition methodology which projects the original latent encodings into incrementally smaller subspaces through linear neural models. The empirical analysis validates the proposed assessment scheme against existing disentanglement metrics on synthetic and benchmark datasets.",
        "strengths": "S1) Motivations behind the paper are solid: too strict definitions of disentanglement as projection into single orthogonal dimensions are bound to fail in realistic settings. The idea of broadening the definition to orthogonal subspaces, while not being completely novel, is developed here through an approach which is original.\n\nS2) The technical contribution seems also solid, modulo some points which are not made entirely clear in the presentation. However, the overall methodology is convincing from the perspective of correctness and adequacy of the technical solutions. \n\nS3) The paper is well organized and mostly of good presentation quality.",
        "weaknesses": "W1) While presentation quality is generally adequate, the paper misses to convey all the necessary details to facilitate reproduction of the method and of the study. This lack of technical detail in the main body is not compensated by the availability of appendices, supplementary materials or code. One key aspect that is unclear to me is how one is expected to identify the generative factors set $z_1,\\dots, z_K$ and how such $K$ is determined in general. The method involves training a potentially large amount of regressors and little information is provided on how this is done in practice (e.g. how much should the training be pushed in terms of regression error? What are the stopping conditions? How are the linear model initialised?).\n\nW2) The positioning with respect to the literature is on the weak end. The paper misses to discussion and cite works formalising weaker forms disentanglement [A, B, C]. In particular, it would seem relevant to discuss the relationship between the proposed approach and those building on (and measuring) linear symmetry-based disentanglement [B,D].\n\nW3) While the experiments are generally well-designed, the evidence they provide does not seem enough to support the major claims of this paper. As long as one departs from the ideal setting, it is difficult to assess the added value of IWO over DCI and MIG. Additional experiments are needed on more challenging datasets, such as ModelNet40 and COIL-100, possibly enlarging the scope of methods to compare with by including those in [B,D]. It would also be of help to qualitatively explore the impact of the proposed methodology, e.g. by exploring the effects of manipulating the representations over the relevant subspaces \u201csuggested\u201d by the metrics. \n\nW4) The proposed methodology seems very computationally involved. I am using the word \u201cseems\u201d as the paper lacks a comparative assessment of the cost of the method. This should be done while considering more realistically sized problems, involving latent spaces of non-trivial size.\n\n[A] https://proceedings.neurips.cc//paper/2020/file/9a02387b02ce7de2dac4b925892f68fb-Paper.pdf\n\n[B] https://proceedings.mlr.press/v162/tonnaer22a/tonnaer22a.pdf\n\n[C] https://doi.org/10.1109/IJCNN55064.2022.9892093\n\n[D] https://arxiv.org/pdf/2011.13306.pdf",
        "questions": "Q1) Can the Authors please clarify how generative factors  $z_k$ are selected for the purpose of implementing the method in general (see W1)?\n\nQ2)  Can the Authors please discuss the relationship with linear symmetry-based metrics?\n\nQ3)  The empirical analysis would be substantially strengthened by adding new experiments on as ModelNet40 and COIL-100, considering also computational costs? \n\nQ4) I am a bit puzzled by the negative correlation values in the experiments: is this classical linear correlation? Because some methods seem to be highly negatively correlated (which is still somehow a form of correlation).",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "In this paper, the authors first propose Latent Orthogonal Analysis(LOA), a method that can identify latent subspaces for different factors of variation from data. To estimate the mutual orthogonality between subspaces learned with LOA, they then propose importance-weighted orthogonality (IWO), a metric that can do the measurement on disentanglement by investigating the magnitude of the projections from different subspaces onto each other. This is achieved by multiplying the basis matric of one subspace with a diagonal matrix that defines the importance of each dimension w.r.t. the other subspace.\n\nThey empirically evaluate IWO on multiple datasets that are commonly used in disentangled representation learning, and they show that their metric that can outperform prior metrics such as MIG or DCI-D.",
        "strengths": "This paper is well-structured and clearly written. It is easy to understand what problem they try to tackle in this paper. Even though the metric study on disentangled representation learning is not a completely new field, I believe it is still worth thinking of how we evaluate the orthogonality between different subspaces that encode different factors of variation. \nIn their methodology, the authors provide detailed and sound math derivation on their LOA and IWO approach.",
        "weaknesses": "My main concern is about the insufficiency of evaluation. Give that $\\beta$-TCVAE was a few years ago and there have been a large number of variants of VAEs that do disentangled representations, I would hope that the authors can implement a few more models for comparison. In addition, there are also very commonly used datasets that were not considered here, e.g. CelebA, Shape3D, Clevr, etc. I would like to see results on these more complex data.",
        "questions": "1. I wonder why the $\\Delta$ L can be used to measure the importance. Could you justify it in more detail?\n2. Is the reason that you choose to only apply linear projection using $W_{1:L}$ is technical difficulty or indeed conceptual purpose?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The authors propose a novel metric for evaluating disentanglement of learned representations. The method consists of training a Linear Neural Network, essentially an MLP without nonlinearities with decreasing dimensionalities, for each ground truth factor. The objective function involves training (potentially non-linear) predictor heads on top of each hidden layer. Using QR decomposition on the learned NN weights together with loss estimates from each predictor, the authors estimate basis vectors for each ground-truth factor, together with their importance weightings. By computing such vectors for each g.t. factor they estimate both the subspaces in the learned latent space and compute a measure of orthogonality between subspaces for dfiferent g.t. factors.\n\nUsefulness of the metric is evaluated on both synthetic and real data.",
        "strengths": "- IWO can be used in scenarios where a ground truth factor can be aligned with exactly one latent dimension\n- the proposed metric actually correlates with downstream task performance",
        "weaknesses": "- only 2 datasets and models (as compared to e.g., Locatello et al. 2019) are compared in Section 4.3. Please consider using all the 7 datasets from *disentanglement_lib,* otherwise the choice seems a bit arbitrary\n- Figure 1 is quite difficult to grasp. I understand that the concept is not trivial to present (and the caption is already lengthy), but maybe you could consider extending/rewriting the caption to make it clearer? Perhaps in a step wise manner (multiple figures). I find it crucial for conveying the idea of your paper. If you lack space I believe figure 3 could be compressed/removed instead",
        "questions": "The sub-optimal performance of Explicitness for the perfectly disentangled case could stem from overfitting. How do the authors handle this problem with their metric? What were the train/test splits used for the experiments? How sensitive is the metric to smaller sample sizes?",
        "rating": "8: accept, good paper",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "7QlKLvfVge",
    "title": "Directional Rank Reduction for Backdoor Defense",
    "reviews": [
      {
        "summary": "The paper proposes a rank reduction based defense against backdoor attack. Specifically, it first gives a feature-based objective to show the optimal solution to achieve the best defense effect. He then discussed the previous defense's problem based on the given objective and proposes DRR, the rank reduction based defense where aims to find a vector that would maximize the 3rd central moments of the mixed distribution. The proposed method have been verified in CIFAR10 with several backdoor methods. The result shows the proposed method could achieve a little better performance with the state-of-art defense.",
        "strengths": "1. The paper is well-written and easy to follow with only several typos.\n2. The proposed method has some good theoretical analysis and could be meaningful for the future work.",
        "weaknesses": "1. Some of theoretical analysis might be not accurate. The utility function is defined using ||R-\\gamma_r (R)|| and also ||R||-||\\gamma_r (R)||. However, these two value is not strict equivalent. It also happens in the definition of E(R).\n2. It is unclear why the 3rd center moment would show the best performance to measure the difference. In other words, would 2nd order moment or 1st order work as well? Since 3rd order is the main metric selected, the author should explain the choice in detail.\n3. The experiment is pretty insufficient. It only covers one datasets with only one poisoning rate. I suggest the author to give a more comprehensive experiments to show their proposed method's effectiveness. Some standard setting in https://github.com/SCLBD/backdoorbench is recommended.\n\nMinor typo:\nMissing \\hat{x} in the definition of E(R(l).",
        "questions": "Please refer to the weaknesses part. To sum, \n1. Why does ||R-\\gamma_r (R)|| =||R||-||\\gamma_r (R)|| along with  E(R)?\n2. Why does 3rd central moment is selected?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper presents a fascinating new method for backdoor defense in neural networks. The key idea of projecting the \"toxic direction\" that maximizes the difference between clean and poisoned features is novel and seems promising.\n\nThe theoretical analysis provides valuable insights into the limitations of standard neuron pruning approaches. Framing the problem as rank reduction along arbitrary directions rather than fixed neuron directions is a significant conceptual shift.",
        "strengths": "1. The idea of maximizing the third central moment is enjoyable. This idea yields a novel insight.\n2. The connection between neuron pruning and rank reduction is also an exciting topic.\n3. The visualization of the separation constant C provides good justification for the theoretical assumptions.",
        "weaknesses": "1.\tMore experiments can be conducted (BadNet, Blended, CLA, WaNet, and IAB are insufficient.) The authors can consider attacks like SIG [1] and low frequency (Smooth) [2]. Since your method also took latent separability as an assumption, Adapt-blend and Adapt-patch attacks [3] should also be considered. Evaluating robustness to adaptive attacks that try to evade the defense would be useful to understand limitations.\n2.\tThe references and notations should be clarified. For example, what is the reference to Proposition 1? \n3.\tAlso, the readability and organization of this paper need to be improved. It is better if an algorithm is provided.\n\n[1] A new backdoor attack in cnns by training set corruption ICIP 2019\n\n[2] Rethinking the Backdoor Attacks\u2019 Triggers: A Frequency Perspective ICCV2021\n\n[3] Revisiting the Assumption of Latent Separability for Backdoor Defenses, ICLR 2023",
        "questions": "1.\tThe memory and computational complexity could be analyzed more thoroughly, especially how the approach scales with larger datasets/models. Are there ways to make the optimization more efficient?\n3.\tHow many extension directions v_i have you used?\n4.\tModifying the weight matrix may cause a performance drop in many cases. How can your projection keep the performance?\n5.\tThe proof needs to be more rigorous. Why use the consequence of the proof in the middle of the proof?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposes a novel backdoor defense method, which utilizes rank reduction to mitigate backdoor in the model. The idea of rank reduction is interesting and brings a new insight into the area.",
        "strengths": "1. The idea is novel and provides a new insight.\n2. This paper is technically sound and easy to follow.\n3. The experimental results demonstrate its effectiveness in backdoor defense.",
        "weaknesses": "1.Although this work is interesting, it has a limitation. This paper assumes the defender can get access to the backdoored image. However, this is hard to get in actual situations and thus limits its use greatly. I wonder whether it works without these backdoored data.\n2. The backdoor attacks that this paper test is not enough. I suggest the authors to test the newest input-specific backdoor attacks in 2022. It's important to identify whether this method can achieve SOTA.",
        "questions": "1.Does it work without the attacker's backdoored data?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper argues that existing pruning-based defense methods can be ineffective at times and introduces Directional Rank Reduction (DRR) to identify toxic directions. In this study, the method approximates the target direction by maximizing the third central moment, supported by rigorous theoretical justification, and constructs a projection matrix to eliminate the toxic direction. DRR demonstrated outstanding performance in terms of both accuracy (ACC) and adversarial success rate (ASR).",
        "strengths": "1. This study shows an interesting finding that the backdoor trigger effects are not always aligned with fixed dimensions of the feature space, pruning-based methods are usually ineffective.\n2. The proposed DRR method performed well on both ACC and ASR compared to other methods.",
        "weaknesses": "1. In the first equation on Page 3, it seems feasible to do the defense by reducing the norm of the residual matrix to align the benign and poisoned features seems feasible. The features from benign examples move towards the backdoored features. Does the movement hurt the model's clean performance?\n\n2. The last equation on Page 4 has a strong assumption that all the clean examples are centered around the mean of them. Namely, the method assumes that the distances from all the clean examples to the example center are the same. The examples marked as yellow in Figure 1 are distributed like a circle. However, the real-world data distribution often deviates from the assumption. The distribution could be elliptical-like. In this case, the obtained v is not optimal anymore.\n\n3. In the third row of Table 2, DRR achieves a better trade-off. Why it demonstrates a higher accuracy (ACC) instead of a lower ASR?\n\n4. This approach requires the optimization of a vector in each layer, which could be expensive. \n\nminor: All the equations are not numbered!",
        "questions": "1. \"How the direction vector v is initialized in the paper, and do different initialization methods lead to varying results?\n\n2. In Figure 2, the value of C for certain layers is not significant. Is it possible to skip some layers when computing v?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "yacRhge4zQ",
    "title": "Regulation Games for Trustworthy Machine Learning",
    "reviews": [
      {
        "summary": "This paper studied the problem of multi-agent and multi-objective machine learning (ML) regulation games where there exist separate regulators enforcing privacy and fairness constraints on the learning model. Prior work in trustworthy ML often implicitly assumes that a single entity is in charge of implementing these different objectives, which is not realized in practice. The authors instead proposed SpecGame, a general framework for ML regulation games between three agents: model builder, fairness regulator, and privacy regulator. Since the agents' privacy loss is difficult to estimate in post-processing, the authors also proposed ParetoPlay, i.e. using a pre-calculated Pareto frontier as common knowledge among all agents, to simulate the interactions between agents in a SpecGame and recover equilibria points. Finally, the authors provided experimental results to show the suboptimality of the single-agent model in trustworthy ML and answer questions on how the regulators can achieve the desired equilibrium by changing their incentives after the game has converged.",
        "strengths": "Strengths: \n- The proposed model of multi-agent multi-objective is novel and interesting to study. \n\n- The proposed scenario of SpecGame is well-defined and makes sense.",
        "weaknesses": "Weaknesses:\n- The assumption of a pre-calculated Pareto frontier as common knowledge does not have theoretical proofs and the discussion around the empirical evaluation in Appendix J is lacking. \n\n- Throughout the main body, the authors sometimes refer to notations that were not defined previously. For example, in Section 3.2, notation c_i^{(t)} and L_i^{(t)} are the first time the \"(t)\" superscript is used. In Equation 4, the notation \\nabla_s is used without a definition. \n\n- The discussion of the experiments in Section 5 is confusing. At the end of Section 1, the author claimed that the experiments would highlight the suboptimality of studying trustworthy ML in a single-agent framework. However, in Section 5, the first research question shows that multi-agent setup leads to sub-optimalities. \n\n- Figure 1 does not have a legend. Overall, most figures are hard to read and the captions do not provide sufficient description of the experiments. \n\n- Minor typos: \\ell_build(w) instead of \\ell_b(w) on page 5 under Equation 3.",
        "questions": "- Can the authors clarify the assumption of a pre-calculated Pareto frontier as common knowledge?\n- Can the authors clarify the discrepancy between RQ1 and the contribution claimed at the end of Section 1? \n- Can the authors provide a more detailed description of the experiments in Section 5, as well as the reasoning for choosing the hyperparameters described in Appendix I? Particularly, the step size discount factor and the loss function weightings \\lambda_fair and \\lambda_priv?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper is concerned with trustworthy ML. The main contribution is to model the setting as a game (SpecGame) between the model builder and the regulator who is interested in fairness and privacy. An algorithm ParetorPlay is introduced and it is shown that the agents remain on the Pareto frontier.",
        "strengths": "-The idea seems interesting and novel and one can think of it as modeling a wide set of problems.\n\n-The paper is also concerned with an important problem (trustworthy ML).",
        "weaknesses": "1-I think the main contribution of the paper is to model the dynamic interaction between the model builder and the regulator. Accordingly, it is more reasonable to think of only fairness or privacy or to possibly even abstract/lump both issues into one. I don't see how having these two considerations has added to the model. One can also consider the safety of the model or its robustness to adversarial manipulations as part of the regulator's concern for example. \n\n2-Why is the paper searching for Pareto Optimality instead of a Nash Equilibrium? Both agents (builder or regulator) are interested in their utility and as a result would deviate to increase it which is what would be captured by a Nash Equilibrium\n\n3-The section \u201cMaking a uniform strategy space.\u201d on page 6 is very unclear. What does \"consistent\" mean? It seems to suggest that the strategies are fixed. Further, it seems that the horizon is n. If that is the case the why does the utility in section 3.2 sum to infinity? \n\n4-Why is a correlated equilibrium and correlation device well-motivated in this setting? Also the paper mentions that \u201c This is known as a correlation device. If playing according to the signal is a best response for every player, we can recover a correlated equilibrium (CE). We leave the theoretical proof of this conjecture to future work.\u201d But doesn\u2019t Theorem 1 prove that you have a correlated equilibrium so is it a conjecture?",
        "questions": "Please see Weaknesses above.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper studies the trade-off in trustworth ML, specifically that between fairness, privacy and model utility, by formulating it as a multi-agent game (called SpecGame) among two regulators and a model builder. The authors design a method called ParetoPlay to search for an equilibrium on the Pareto frontier. Experiments show that the designed method can be instantiated to two existing trustworth ML algorithms and demonstrate the trade-off between fairness vs. privacy vs. utility achievable by the designed method.",
        "strengths": "- The problem of trade-off among different important criteria in trustworth ML is important.\n\n- The formulation of the interaction as a multi-agent game is intuitive.\n\n- The theoretical analysis and empirical results demonstrate the interaction among the agents in the game, which can be useful in understanding the (possible fundamental) limitations when designing new trustworth ML algorithms.",
        "weaknesses": "- A key assumption is the common-knowledge of a pre-calculated PF among the \nconsidered critera, specifically privacy, fairness and model utility. This can be difficult to satisfy in practice.\n\n- There are several (simplifying) assumptions made (which can take away the pratical feasibility of the work). For two examples,\n    - > We assume that regulators are able to give penalties for violations of their respective objective which they formulate as a utility (or value) function.\n\n    - > We assume the regulators hold necessary information about the task at hand in the form of a Pareto Frontier (PF) which they use to choose fairness and privacy requirements that taken together with the resulting accuracy loss are Pareto efficient:\n\n- The writing can be improved (for details, see the questions below).",
        "questions": "1. In Section 1\n    > This is because nowadays ML models are trained, maintained, and audited by separate entities\u2014each of which may pursue their own objectives.\n\n    Are there references or real-world use-cases where this is true or implemented?\n\n2. In Section 1,\n    > ... that assumes shared knowledge of a pre-calculated PF between agent objectives.\n\n    Can this PF be realized in practice? i.e., how to accurately obtain it? and if only a somewhat inaccurate one can be obtained, what are its implications?\n    \n    \n3. What is $i\\in I$ in Definition 1?\n\n4. In Section 3,\n\n    > In this work, we do not consider a competition between regulatory bodies since both are assumed to be governmental agencies.\n\n    Even though the regulatory bodies are not set out to compete with each other, the inherent tension between the objectives can lead to competitive strategy profiles and actions, right?\n\n    In that case, what is the significant distinction of \"not considering a competition between the regulatory bodies\"?\n\n\n5. What is $\\\\{c_{i}^{(t)} \\\\}^t$ in the overall discounted loss in Section 3.2 ?\n\n6. In Section 4,\n    > However, ...the highly non-convex nature of agent losses in $\\texttt{SpecGame}$\n\n    How is the non-convexity addressed?\n\n7. In Section 4,\n\n    > for $t>1$, we assume a mapping from the penalty values in S to trustworthy parameters values $s_{reg} = (\\gamma, \\epsilon)$\n\n    (How) can this assumption be satisfied in practice ?\n\n8. What do the colors represent in Figure 4a?\n\n9. Are the experimental results averaged over multiple trials? If so, is there an analysis of the variation?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "rEQ8OiBxbZ",
    "title": "3D Molecular Pretraining via Localized Geometric Generation",
    "reviews": [
      {
        "summary": "The paper presents a novel pre-training approach for 3D molecular datasets, building upon TokenGT. By augmenting TokenGT with 3D attributes, the proposed method harnesses 3D molecular data to enhance its generalization capabilities across various tasks.",
        "strengths": "1. Segmenting 3D structures into distinct local components is an insightful approach.\n\n2. The reconstruction method for these local structures is intriguing and presents a unique strategy.\n\n3. There is a marked novelty in the concept of pre-training 3D molecules through local structures, despite the base model being a straightforward extension of TokenGT enhanced with 3D coordinates.",
        "weaknesses": "1. The base model's simple strategy of appending 3D features to token embeddings may compromise the essential equivariance of 3D molecules.\n\n2. The description of the training objective section lacks clarity. I have outlined specific inquiries in the subsequent Questions.\n\n3. Given that the model is training on the reconstruction of molecular conformations, it would be beneficial to disclose the reconstruction accuracy on the pretraining dataset to demonstrate the model's learning efficacy.\n\n4. The experimental comparisons should encompass additional 3D molecular datasets such as QM9 and GEOM-drug, considering the model's pretraining on 3D structures. Nonetheless, the paper confines its reporting to the OGBLSC-PCQM4Mv2 dataset and the observed performance significantly lags behind SOTA methods. The explanation provided for this underperformance does not sufficiently account for these results.\n\n5. The layout of the paper requires revision. The Algorithm should be positioned before page 10 or on a separate page designated as an appendix, rather than following the references on page 12.",
        "questions": "1. What exactly constitutes the input for TokenGT-3D? Is it the original molecules, or do you utilize each local structure segmentation after masking and perturbation? Or is it the masked and perturbed local structure segmentations of a single molecule, or something else entirely?\n\n2. Given the proposed method centers on pre-trained representation learning, what form do the learned representation embeddings take for downstream tasks?\n\n3. Could you elaborate on how the local structures are reconstructed? What serves as the input for this process: a single embedding from the TokenGT-3D output, or a collection of embeddings from local structure segmentations within a single molecule?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposes a self-supervised pre-training strategy for 3D molecular structures, based on partitioning molecular structure into tetrahedra that can then be masked and reconstructed.",
        "strengths": "The empirical performance is OK for some of the fine tuning tasks, although still not consistently solid.",
        "weaknesses": "The geometrical justification of tetrahedra as simplest polyhedron might make sense, but in chemistry it makes a lot less sense. The authors literally show benzene in Figure 1b, which has 120-degree bonding pattern (so called planar-trigonal in chemistry) that is NOT a tetrahedron at all, and has very different local symmetries. \nThe ablation studies are unconvicing. Why not evaluate the role of the actual innovations introduced ? Tetrahedra vs. point-wise generation. Evaluate the role of edge information ? \nWhat happens for atoms with more than 4 bonds (sulfur, phosphorous, etc) ?",
        "questions": "\"We attributethistothedifferent3Dstructuresmoleculesexhibitinliposomecompounds.\" What does this mean ? What are these structures different ? \nAll the biochemistry prediction tasks are actually properties of the graph, not the 3D structure, What 3D structure is being used ?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper describes a pretraining process on the 3D structure of small molecules. The method splits a molecule into tetrahedrons of a few atoms each and learns to reconstruct them in 3D using knowledge of the graph structure of the input molecule. The authors apply the model on downstream property prediction tasks and compare to public benchmarks.",
        "strengths": "The main method in the paper is interesting conceptually and somewhat original as it combines a graph token representation with a decomposition of a small molecule into smaller 3D structural units. The downstream application on MoleculeNet is significant, and the application on the open graph benchmark is useful for context, although the particular table 2 is misleading. The introduction is reasonably clear, however, other parts of the paper have problems with the language or formalism.",
        "weaknesses": "The paper can use a lot of rewriting in the methods and experimental results sections.\n\n\nTable 1 does not correctly highlight the best and second best results (see column for BACE when 2 of the 2D models perform better than LEGO).  Table 2 is missing the vast majority of best performing models from the opengraph benchmark large scale challenge.  Interestingly, the comparison in table 2 misses the top two entries which are models included in Table 1; if I count correctly the LEGO model would rank 9th in the validation metric with a substantial gap compared to unimol published in last year's ICLR.  It would be useful if the authors submitted their model to the benchmark to see the performance on the test set.\n\nThe text has a lot of rushed / unclear sentences.  The first sentence on page 8 (\"All this baselines involves...\") does not make sense as written.  Small errors and lack of clarity starts earlier in page 5 (undefined d_p), page 6 (\"way to increase the and generalizability\"), page 7 (\"... is enough to valid our method\", \"...graph representation an pass it...\", \"...an important properties...\", \"...proved to be close related...\"), probably more.",
        "questions": "Although the current method is not directly inspired by this work, I believe that the RL reconstruction of molecular geometries from 3D fragments in Flam-Shepherd et al (https://arxiv.org/abs/2202.00658) relates closely to the core inspiration of this method and might warrant discussion in the intro. (In contrast, some of the discussion of the atom-bond inconsistency problem is potentially possible to skip as it doesn't add meaningful insights.) Did the authors think of extending their tetrahedral segmentation approach to use a similar fragment-based approach instead?\n\nCan the authors comment on the disparity of the approach of their validation scores on moleculeNet vs those on the large-scale challenge?  \n\nThe ablation study is not helpful: the perturbation of the model is too limited, and table 3 suggests strongly that the parameters are actually not optimal.  The random perturbation pretraining of table 4 is not described in a clear enough fashion.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper introduces a 3D molecular self-supervised learning approach that leverages the geometric information of molecular local structures, in the way of orientation prediction and arrangement generation. The atom-bond inconsistency issue has been identified and tackled through a joint modeling of the graph as a set of nodes and edges. The method has been benchmarked on MoleculeNet and OGBLSC-PCQM4Mv2 datasets to verify the efficacy of proposed designs.",
        "strengths": "1. The paper is well-motivated through the concept of molecular local structure and the introduced approach yields good novelty.\n\n2. The presentation is mostly clear and the method is easy to follow.",
        "weaknesses": "1. The experimental results seem to be insufficient to support the empirical superiority of the proposed approach. In particular, the method could be further improved either through a more careful design of the backbone or enhancements of the training objective to make the results stronger.\n\n2. If the results are difficult to improve, the authors may also be suggested to try other benchmarks or setups, e.g., QM9, MD17, where a better utilization of the 3D structural information would bring more benefits. In the current shape the quality of the experimental evaluations may not meet the bar of ICLR.",
        "questions": "Q1. I am curious whether the proposed SSL objective can be combined with other backbones or even other pretraining objectives. If so, it would be interesting to see how the method can benefit different backbones which may be an evidence of the extensibility of the approach.\n\nQ2. How does the method perform on datasets like QM9?\n\nQ3. For the ablation study, it would also be interesting to see how the proposed 3D TokenGT helps to boost the performance since one of the claim in the paper is that the atom-bond inconsistency problem is tackled by modeling graph as a set of nodes and edges.",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "UVSKuh9eK5",
    "title": "CLIP Exhibits Improved Compositional Generalization Through Representation Disentanglement",
    "reviews": [
      {
        "summary": "In this work, author examine the compositionally generalization in vision language model. By adopting different combination of disentangled attribute in training dataset of CLIP, author generate a authentic test set that is unseen by model but share the same disentangled attribute. Author also argue that the level of feature disentanglement is high correlate to model generalization by presenting various analysis.",
        "strengths": "1. This paper propose a high quality test set measuring compositional generalization with generative model. This benchmark provide a simply and more straightforward measurement for compositional generalization of Top1 accuracy for synthetic dataset, over prior measurement like using Visual Genome, or captions perturbation. This could be significant to the community exploring model generalization.\n2. Author have conducted various analysis over the relationship between compositionally and feature disentanglement, demonstrate the potential influence of the proposed dataset at a large scale.",
        "weaknesses": "1. In 3.2, the statement 'We interpret these findings as strong evidence that the inclusion of language supervision, particularly during CLIP training, positively impacts the model representation quality' might be too strong of a claim. As explored in prior work(\"Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP)\") , language supervision might not be the sole reason for model generalization. There're multiple variance between VLM and other modality and author should not attribute such improvement solely on language supervision. \n2. Conclusion are less convincing due to the limited candidate in each experiment. For instance, in Table 1, it will be interesting to shows the NMI for a subset of LAION with the same number of data to other dataset. Also in table 2, there's only 4 results, please consider adding more variance of dataset and CLIP architecture . \n3. The narrative after section 4 is a bit too rush, it's hard to follow the method and results. For instance, what is 'dimensions' in 4.1 stands for? And more context over 'switching dimension' would be helpful. Moreover, I cannot tell how the conclusion of 'A higher level of accuracy in the image retrieval task indicates that the model embeddings are more disentangled.' can be drawn from experiment in 4.2. \n4. There's some grammar and formatting issue, for instance in section 4, spaces were missing between sentences.",
        "questions": "Page 3: in the imrpoved generalization -> typo\nPlease refer to weakness. While this work could be potential significant to the community, the clarity could be further improve, especially on drawing the connection between compositionally and feature disentanglement.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper studies CLIP models under a different type of distribution shift namely compositional OOD generalization, where the objects and attributes may be individually seen during training, but their composition is unseen. A new dataset, ImageNet-AO is generated using DALL-E, containing such novel compositions for ImageNet classes. It is ensured that the generated compositions are not present in the CLIP training datasets. Key observations are - i) compositional diversity of the training dataset improves the compositional generalization of the CLIP model, ii) image/text representation disentanglement of objects and attributes improves generalization, iii) larger, more diverse datasets leads to better compositional generalization, iv) better disentanglement in representations leads to better compositional generalization.",
        "strengths": "- The experiments are well-designed \n- Conclusions drawn are very interesting and insightful \n- The dataset ImageNet-AO can be helpful for future study as well",
        "weaknesses": "- \"*the training dataset of the OpenAI CLIP has not been released, which makes designing a test set that has a truly different distribution from the training one challenging. We aim to address these issues in this paper, by focusing our attention on the compositional generalization\nin the single object setting, and designing an authentic test dataset to assess the training data characteristics and mechanisms in the models that lead to the OoD generalization.*\" -- This contradicts the following statement where the authors claim that they verify that the ImageNet-AO images are not a part of several CLIP training dataset -- \"*To ensure these combinations were not present in the CLIP training set, we conducted a thorough search and removed any combinations that were found.*\"\n- \"*By assessing the captions in the training sets, we guarantee that none of the captions in our test dataset or similar captions are included in the CLIP training data.*\" \n    - Is this check done for all the other datasets considered in the paper as well (LAION, YFCC15m, CC12m, and DataComp)?\n    -  A similar check should be done on images as well, it is possible that such images with different captions are present in the training set. Usually, captions from web sources are not exactly descriptive of the image.\n- \"*We also found that the CLIPs that show higher OoD generalization typically exhibit strong disentangled text representations. Furthermore, such CLIPs also enjoy a more disentangled image representation with respect to the attributes and objects as well.*\" -- the experiments in the paper do hint at the above statement. But this does not necessarily imply the following: \"*Specifically, a dataset with diverse compositions of attribute-objects facilitates a more disentangled text representation, which in turn induces a disentangled image representation through contrastive learning.*\" It could be possible that diverse images lead to disentangled image representations as well. \n- \"*To evaluate the degree of disentanglement in the training captions utilized by the CLIP, we conducted an analysis by measuring the normalized mutual information (NMI) between the object class and attribute tokens, whose domains are defined based on the captions in our generated dataset.*\" -- Could the authors explain how the domains are defined based on the captions in the generated dataset? More details on how the NMI is measured would be helpful.\n- Fig.4 - It is not clear how the disentanglement metrics are computed for the image encoder. \n- \"*We aimed for a diverse set of class names to enhance the complexity of the generated images.*\" -- It is not clear if all 1000 classes were used or only a subset. If a subset was used, how was this chosen?\n- \"*This dataset was produced by creating compositional images via a text-to-image model, using an Attribute+Object template.*\" -- could the authors give more details/ a citation for the Attribute+Object template?\n- Could the authors provide details on where the 30 adjectives were chosen from?\n- \"*Lastly, human evaluation was used to validate the generated images, with images not closely aligning with their prompts removed. After this process, around 12000 combinations remained, for which we successfully generated near 50000 accurate, high-quality images.*\" - The order of the two statements may have to be swapped? Could the authors provide details on how this human evaluation was done?\n- \"*For the test sets, all 1000 classes of ImageNet were used as the in-distribution set and expanded the number of classes to approximately 12000 for the OoD set.*\" -- could the authors share how the captions were created for the OOD set? Sharing some examples would be helpful. I believe the 80 captions are used only for the ID set, and single relevant captions are used for the OOD set?\n- In Fig.1, for a more fair comparison, the image-only models such as DINO-v2 and BEiT-v2 should also be trained on the datasets that were used for training CLIP (by using only the images, and ignoring the captions). Without matching at least the image datasets, there is not enough evidence to support the following statement - \"*We interpret these findings as strong evidence that the inclusion of language supervision, particularly during CLIP training, positively impacts the model representation quality, hence making it possible to generalize to unseen compositions, despite the absence of such compositions in their training data.*\"\n\nNitpicks -\n\n- citation format seems non-standard - (x) vs. [x]\n- inline citations should use the format xyz et al., rather than [x] \n- A citation for the work that defines \"compositional OOD generalization\" would be helpful",
        "questions": "- Although the experiments and conclusions in the paper are interesting and useful, several aspects of the paper need more clarity. These are mentioned in the weaknesses section. I will be happy to update my score based on clarifications provided by the authors. \n- Codes, models, and datasets must be open-sourced for the benefit of future research. Could the authors comment on this? Would these be released upon acceptance?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes a new dataset to benchmark the compositional capabilities of several CLIP models (OpenAI and OpenCLIP). This dataset is generated using DALLE, and covers the 1000 class names from the ImageNet dataset combined with 30 adjectives. Manual annotators validated the combinations, resulting in ~12k plausible compositions, from which they generated 50k images. The authors also propose to measure the compositional generalization via the normalized mutual information between objects and attributes, and use Z-Diff Score, DCI-Informativeness, Explicitness score, and DCIMIG metrics to evaluate the disentanglement in the embeddings from the models.",
        "strengths": "+ This paper proposes an interesting approach to measure the compositional capabilities of large-scale VL models, by leveraging a text-to-\nimage model to generate new images with specific attributes.\n\n+ The authors provide a large set of experimental results in the supplementary materials, showing that CLIP models struggle with their proposed dataset\n\n+ This paper is well-structured, easy to read and follow.",
        "weaknesses": "+ There is no description or motivation for the attribute selection, are those attributes randomly selected or generated? How do the authors guarantee that those attributes are not present or co-occur less in the training data?\n\n+ The human validation seems crucial in generating the proposed benchmark; however, there is no detailed description of how this was performed. \n\n+ In section 1, the authors claim: \"By assessing the captions in the training sets, we guarantee that none of the captions in our test dataset or similar captions are included in the CLIP training data.\" -- however, I couldn't find any empirical or theoretical evidence, nor existing reference for this claim.\n\n+ The human validation only asses for the plausibility of the noun-adjective composition, but are the images generated by DALLE following those compositions? Prior work has shown that Diffusion models \"struggle to understand the composition of certain concepts, such as confusing the attributes of different objects or relations between objects\"[1]. It is unclear if the generated dataset follows the attribute-noun composition, or falls into this category. See also [2].\n\n+ Most of the conclusions are prevalent in the literature (e.g., the diversity of training captions promotes compositionality [3]), and the mutual information analysis does not seem to provide additional insights [4, 5].\n\n[1] Liu, Nan, et al. \"Compositional visual generation with composable diffusion models.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.\n\n[2] Park, Dong Huk et al. \u201cBenchmark for Compositional Text-to-Image Synthesis.\u201d NeurIPS Datasets and Benchmarks (2021).\n\n[3] Doveh, Sivan, et al. \"Dense and Aligned Captions (DAC) Promote Compositional Reasoning in VL Models.\" arXiv preprint arXiv:2305.19595 (2023).\n\n[4] Radford, Alec, et al. \"Learning transferable visual models from natural language supervision.\" International conference on machine learning. PMLR, 2021. \n\n[5] Oquab, Maxime, et al. \"Dinov2: Learning robust visual features without supervision.\" arXiv preprint arXiv:2304.07193 (2023).",
        "questions": "Is there any particular reason why DINO-v2 and BEiT-v2 are mentioned briefly in the introduction, but no further analysis is done in the following sections?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "1XHzHMQfcK",
    "title": "Significance of Fairly Distributed Instances and Optimal Ratio for Validation Set in Machine Learning",
    "reviews": [],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "23OEmHVkpq",
    "title": "Disentanglement Learning via Topology",
    "reviews": [
      {
        "summary": "The authors of this paper present TopDis, which is a regularizer based on Representation Topology Divergence (RTD). In this approach, the objective to be optimized is a combination of \u201cclassic\u201d VAE loss and TopDis loss. Unlike the preceding approaches, topDis does not assume statistical independence between the factors of variations. Generally, introducing this loss term appears to further improve the current SOTA values for several disentanglement metrics (FactorVAE, MIG, SAP and DCI) across several different datasets (dSprites, 3D Shapes, 3D Faces, MPI 3D).",
        "strengths": "1. The paper is clearly written and easy to follow. In detail:\n\na. The authors explain the task of disentanglement rather clearly by providing a succinct overview of previous works.\n\nb. The motivation and contribution of the paper are also clearly defined with an intuitive explanation of the designed methodology.\n\n2. The authors provide a variety of experiments and ablations, helping to evaluate their proposed disentanglement regularization loss practically. In detail:\n\na. The experiments (Table 1) appear comprehensive (except for the vanilla VAE; we will explain in the weakness section our concerns).\n\nb. The authors also provide enough qualitative examples, comparing models trained with TopDis regularizer and without.\n\nc. The architecture is succinctly described in the Appendix\n\n3. Computational complexity is also discussed in the Appendix, which is crucial for ML algorithms nowadays.",
        "weaknesses": "1. One of the contributions the authors mention is: \u201cWe improve the reconstruction quality by applying gradient orthogonalization;\u201d - however, this contribution is only briefly mentioned in the conclusion and analyzed in the Appendix in greater detail. We suggest the authors to \u201cmove\u201d the gradient orthogonalization part to the main paper.\n\n2. As the authors explained, the RTD was defined in a previous work, but we believe it is important to be defined in the main paper.\n\n3. In section 4.1, bullets (2-4). In (2), g\\inG appears to be applied to both pixel and latent space. Later in (3,4), where decomposition G is defined, it seems that it can be applied only in the latent space. We believe the authors should re-write this part, clarifying how G can be applied in the pixel space or, if that is not the case remove from (2) the application of g in the pixel space.\n\n4. In equation (4) regularization parameter /gamma is defined. Later in the appendix Q, \\gamma_1, and \\gamma_2 are used in the ablation table. Does this correspond, instead, to the loss: \\gamma_1 L_{VAE-based} + \\gamma_2 L_{TD}.\n\n5. In page 5 footnote, the authors state that RPT can be computed in latent space instead of pixel space. Can the authors provide ablations in the appendix exploring this direction? Do the authors have insights into how this change can affect the final trained model?\n\n6. Finally, our main concern is whether the proposed regularizer contributes to the learning of the disentangled representation or the used base models (i.e., \\beta-VAE, Factor-VAE). Since, in the main paper, only the models with already disentanglement remedies are explored and not the vanilla VAE. More concerning in the ablation, VAE+TopDis is explored, but it seems that the training is not the same as the VAE reported in the main paper. Our guess is that the models in the ablation were trained for less number of iterations. We encourage the authors to include in the main paper VAE+TopDis trained under the same conditions (i.e. same number of iterations) as the reported VAE in Table 1. This will help readers understand to what extent the TopDis regularizer helps learn disentangled representations",
        "questions": "See above",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper proposed a disentanglement regularization term based on topology, to constrain the manifold relation between the latent points of original images and shifted images. The authors provided extensive experiments on VAE-based methods and showed the effectiveness of the proposed methods.",
        "strengths": "1.\tIt is important to explore the constrain in the manifold of latent space for disentanglement, due to the statistical arguments of Locatello et al. (2019). The paper explored a way from topology and proposed a regularization term, which can be easily optimized. \n\n2.\tThe paper provided a good formulation of the TopDis loss and how to optimize it in the VAE framework.",
        "weaknesses": "1.\tThe relation between the constrain on latent space and disentanglement is still unclear, the TopDis is based on VAE-framework, which is based on Probability, and the paper referred to the definition of disentanglement based Group. And the paper failed to connect the above two framework, and making the proposed TopDis only kind of an intuitive necessary condition, as shown in Figure 3. \n\n2.\tFrom Appendix L, the best performance hyperparameters are quite different across different methods and different datasets, is there any guidance or criterion to choose the hyper-parameter?",
        "questions": "1.\tMy main concern is the relation between the proposed TopDis and disentanglement, is there any theoretical guarantee or deduction?  \n2.\tThe authors applied the proposed TopDis to infer disentangled directions in a pretrained style-GAN, is there some quantitative results? Then dose the method can be applied to other disentangled methods?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposed a novel Topological Disentanglement loss (TopDis loss) that can be added to any VAE-type loss to improve the disentanglement by encouraging the preservation of topological similarity in the generated samples with shifted latent space. Experiments demonstrated the proposed TopDis loss increases the disentanglement performance of several SOTA methods for various disentanglement metrics and datasets.",
        "strengths": "(1) Inspired by [1], the proposed differentiable Representation Topology Divergence (RTD) as a loss for the VAE-framework looks promising to improve the disentanglement.\n\n(2) Rich experiments are conducted to evaluate the performance of the proposed TopDis loss for various VAE-based methods.\n\n[1] Barannikov, Serguei, et al. \"Representation topology divergence: A method for comparing neural network representations.\" ICML 2022.",
        "weaknesses": "(1) It is unclear how the hyper-parameters in Eqn (4) affect the performance. There are \u03b3_1 and \u03b3_2 in Table 9 (appendix N), but there is only one \u03b3 in Eqn (4). \n\n(2) In Table 1, it seems that some advanced disentanglement methods performed significantly worse than the vanilla VAE (e.g. FactorVAE on 3dshapes, and \u03b2-TCVAE on MPI3D, etc), making it a little suspicious for the experimental results and/or the model selections of baselines. Besides, two important evaluations of VAE+TopDis and \u03b2-TCVAE+TopDis are missing. \n\n(3) The evaluation of how the proposed methods handle the tradeoff between disentanglement and reconstruction is limited. Besides Table 4 and Table 8, the authors are encouraged to report the reconstruction errors of the proposed method with and without \"gradient orthogonalization\" for a complete comparison with the baselines. Did the \"gradient orthogonalization\" apply to the baselines as well?",
        "questions": "(1) The authors are encouraged to respond to the concerns above.\n\n(2) How the \u03b3 should be selected for different VAE-based methods? Does TopDis improve disentanglement when \u03b2 is already very large? How does the TopDis loss affect the optimization of the original disentanglement loss in those baselines (like the total correction in TC-VAE and FactorVAE)?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "In this paper, the authors propose a method, named TopDis (Topological Disentanglement), for learning disentangled representations via adding a multi-scale topological loss term. The experiments results show that the proposed TopDis loss improves disentanglement scores such as MIG, FactorVAE score, SAP score and DCI disentanglement score with respect to state-of-the-art results while preserving the reconstruction quality.",
        "strengths": "- This paper is the first to introduce the use of a topological regularization term in the field of disentangled representation learning.\n- The topological regularization term is shown to be effective across multiple VAE models and metrics.\n- The regularization term proposed in this paper is also demonstrated to be effective for discovering pre-trained StyleGAN models.",
        "weaknesses": "- The paper lacks a clear reasonable explanation as to why topological constraints are meaningful/effective for disentanglement representation learning.\n- The new loss function was already proposed in a 2022 ICML paper [a]. The main contribution of this work is applying it to disentanglement, making the explanation of the above issue crucial for this paper.\n- The experiments focus on models with some disentanglement capabilities, but the effectiveness of this regularization term on vanilla VAEs has not been studied.\n- The performance of vanilla VAEs presented in this paper show high DCI performance, but other papers [b] report poor performance instead. A reasonable explanation is needed, and it would be helpful to include evaluation code in the supplementary materials.\n\n[a] Representation Topology Divergence: A method for comparing neural network representations.\n\n[b] \u03b2-VAE: LEARNING BASIC VISUAL CONCEPTS WITH A CONSTRAINED VARIATIONAL FRAMEWORK\n\n[c] Disentangling by Factorising",
        "questions": "See weakness",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "iS7c9lkXuF",
    "title": "Object-Centric Noise Filtering in Neural Radiance Fields via Influence Functions and Segmentation",
    "reviews": [
      {
        "summary": "As there would be dynamic distractors in the scene which usually occlude the objects-of-interest, NeRF models could not reconstruct the 3D scene correctly. This paper adopts Influence Functions to evaluate each pixel in the training set and finds out the distractor pixels. To further improve the consistency in each image plane, it also integrates a segmentation method, i.e., SAM. The experimental results verify the feasibility of the proposed method.",
        "strengths": "This paper firstly adopts Influence Functions to find the distractors in the data for NeRF reconstruction, which provides a new method to alleviate this difficulty.\n\nThe paper is easy to understand and the presentation is acceptable.",
        "weaknesses": "-- The novelties are limited. As the key idea of this paper is adopting an existing method, i.e., Influence Functions, to improve the robustness of NeRF reconstruction, it is acceptable if the performance gain is remarkable. Unfortunately, this is not true according to the experiments.\n\n-- There are many confusing results and settings in the experiments, which significantly reduce their credibility. In Tab. 1, there are no results of RobustNeRF. Acctually, according to the RobustNeRF paper, it achieves better performance overall. In Tab. 4, the results of RobustNeRF are not consistent with the results reported by the RobustNeRF paper. Moreover, the results of Crab scene are missed.",
        "questions": "What are the principles of the experimental settings? Why are some results missed or inconsistent?\n\nThis paper has not reported the computation cost of the method. It seems really expensive to compute the Hessian matrix.\n\nI have not found the appendix.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper proposes a noise pruning pipeline for NeRF learning, aimed at training NeRF on images with distortion. Specifically, it proposes to first use inference functions to determine the potential pixels that are considered as distortion. Then, it segments out regions that include pixels considered as distortion using the SAM model. Finally, it removes the segmented-out pixels from the training images to reduce the inference of distortion. The paper then conducts experiments on the RobustNeRF dataset and a synthetic dataset.",
        "strengths": "1. Learning NeRF in a robust manner is important and useful.\n2. Using the inference function to determine the distortion seems reasonable.",
        "weaknesses": "1. I believe the proposed pipeline may have limitations in real-world applications. In real-world scenarios, noise and distortion can originate from various sources, such as inaccurate camera calibration, motion blur, out-of-focus blur, JPEG compression noise, and more. Simply discarding the information from these inconsistent pixels by segmenting out the entire region may result in significant information loss, especially in cases like inaccurate camera calibration and motion blur. I would recommend that the author reconsider this approach and seek to improve it.\n2. The presentation of the results is limited. It is challenging to assess the effectiveness of the approach based on the content in the current version of the paper. I suggest that the author include more qualitative results, as there is more than half a page remaining empty.\n3. The Method section is not well-written, containing numerous typos and mistakes. For example, the line following equation 5 states \"loss is defined as,\" but it proceeds to show how theta is computed. Additionally, the notion of I(r, r) appears to be unscientific.",
        "questions": "1. How does the SAM is actually prompted? Is there a non-maximum suppression process used on top of the selected pixels?\n2. What will happen if this approach is applied to clean images without any noise? Since it seems a fixed number of pixels are considered as noise in stage 1.\n3. What if this approach is applied to JPEG compression noise?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper presents a method to identify distractors during the NeRF reconstruction. With the help of SAM segmentation, it can effectively group the segments belonging to the same objects while ignoring the distractors. Experimental results shown that the proposed method is effective in improving the NeRF reconstruction quality.",
        "strengths": "The proposed method is simple, and it demonstrated better results on multiple NeRF dataset.",
        "weaknesses": "The proposed method is highly incremental and it is a straight forward extension of RobustNeRF with SAM segmentation. There are not much analyses why there are distractors and how sensitive is the proposed method against the segmentation accuracy. It basically assume the SAM segmentation is good enough such that the segments belong to the same object can be grouped successfully using the proposed method in Sec. 3. Although it demonstrate some good results, the scene are relatively simple which has only one dominant object. I am not fully convinced that the method proposed in Sec. 3 is general enough for handling complex scene with many objects. I am also not convinced that the proposed method can handle tiny objects effectively since the tiny objects are likely to be filtered out by the proposed method as distractors. \n\nConsidering the limited technical novelty and the potential problems on complex scene and tiny objects, I am not convinced that the submission has reach the bar of acceptance.",
        "questions": "Please provide additional experiments or examples to convince that the proposed method is effective in handling complex scenes and tiny objects.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "E5CMyG6jl0",
    "title": "Unified Language Model Alignment with Demonstration and Point-wise Human Preference",
    "reviews": [
      {
        "summary": "Language model alignment is a significant technique to align inference output to human preference and help performance improvement. Currently, alignment mainly involves two steps: supervised fine-tuning with designed instructions and then preference learning with pair-wise samples such as RLHF and DPO method. However, most of the existing preference data in the world are not just pair-wise but more fine-grained, i.e., preference data are voted by scores. In this paper, the authors propose a new DPO method to align LLM with point-wise preference data. Standing on the proposed point-wise DPO method, they incorporate supervised fine-tuning, unifie the whole alignment framework, and solve it as a one-step alignment problem. In their experiments, they compare with RLHF and vanilla DPO and validate the effectiveness of their proposed framework by achieving lower perplexity scores and higher preference scores.",
        "strengths": "* Originality: Several existing works to align LLM outputs to human preference have been proposed, such as RLHF and DPO. Standing on DPO, this paper devises a new approach for point-wise preference data to make alignments. Besides, they unify the alignment framework with supervised fine-tuning stage. These two contributions enhances paper\u2019s strength on originality.\n* Quality: Numbers in the experiments are solid and look promising, especially the improvements in complexity and preference score (harmful) compared to baseline RLHF.\n* Clarity: The presentation in this paper is easy to follow and well-organized.\n* Significance: A typical way to do preference learning is to treat generated samples with pair-wise binary relation which losses the granular information on voting scores, rankings, or preference levels. To fill the gap, this paper proposes a new DPO method to align LLM with point-wise preference data. They study the gradients between supervised fine-tuning and their proposed method then propose a novel unified framework to learn human preference. Empirically, their results validate the framework\u2019s effectiveness and show the significance of this work.",
        "weaknesses": "* Though the experimental results look promising to demonstrate framework\u2019s effectiveness, more human preference datasets to align LLM should be included, such as datasets provided and used in [1] and [2].\n* The proposed framework should be able to be generalized to more complex metrics (such as the discussion to handle continuous labels) but the datasets used in the experiment are only in binary classes, which is not enough to support the capability of its generalization. \n* The generalization to other metrics with positive and negative samples needs further description in details.\n\n[1] https://arxiv.org/abs/2112.09332\n\n[2] https://proceedings.mlr.press/v162/ethayarajh22a.html",
        "questions": "* What\u2019s the objective loss of ULMA for continuous preference labels? \n* In this case, how does the framework deal with positive and negative samples?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "In this paper, the authors propose a unified language model alignment approach. Their main idea is to address point-wise human preference. I like the idea of studying point-wise human preference. My main concern is that in many cases, there can be a mapping function between pair-wise preference and point-wise preference.",
        "strengths": "1. It is interesting to study the alignments on the point-wise human preference. \n2. It is great to compare the existing approach.\n3. Releasing more datasets is always great for the community.",
        "weaknesses": "1. In many cases, there can be a mapping function between pair-wise preference and point-wise preference. The authors do not discuss these cases. \n2. It would be great to have more experimental results in terms of more LLM-based tasks.\n3. There is no significance test in the tables.",
        "questions": "I like the idea of studying point-wise human preference. However, one essential issue is that in many cases, there can be a mapping function between pair-wise preference and point-wise preference. For example, from pair-wise -> point-wise: you can directly enumerate how many positive preferences have been received for each document, and then rank the documents according to the numbers and assign a ranking score to each document. Or, a simpler way is to use the number of (positive num \u2013 negative num) preferences as the point-wise preference. Therefore, to verify the idea of studying the point-wise human preference. Similarly, point-wise -> pair-wise, one document with higher scores can receive the positive preference. One must prove that these rule-based methods can not work well for the LLM. Also, to test the performance of an LLM, there are many evaluation metrics and many LLM-based tasks. Therefore, I expect the authors to test the LLM for more tasks and metrics. Also, more LLMs are expected. For the reported tables, many numbers are quite close, and it is necessary to have a significance test to see whether the proposed method is better (or you can report the mean and std for multiple runs). Overall, I like this idea, but this version may not be ready for publication. If you can answer the above question or point out my misunderstanding, I will be happy to raise my score.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper introduces a novel model alignment technique to user preferences. The authors have developed a simplified tuning method for point-wise preference data as well as human demonstration.",
        "strengths": "1. Detailed background and preliminaries section which serves as a refresher of the main LLM methodologies. This serves as a solid base and leads very well to the proposed methodology.\n2. Detailed mathematical explanation of the concept.",
        "weaknesses": "The experiments section is not very detailed. Expanding the methodology to more datasets would be nice.",
        "questions": "None",
        "rating": "8: accept, good paper",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper presents a unified framework that integrates the two traditionally separate processes in LLM alignment: SFT on demonstration data and preference learning on preference data. The framework is structured for point-wise preference learning, considering the intrinsic characteristics of real-world preference data distribution. Specifically, the authors treat the positive and negative samples differently, applying SFT loss to the former and adding an additional KL regularizer for the latter. They also justify this formulation via gradient analysis and comparison with DPO. Since the method enhances learning from the positive samples, the authors extend the Anthropic's Helpful and Harmless dataset by refining the positive responses using GPT-4, thus boosting their method with high-quality data.",
        "strengths": "Reward modeling is a crucial and challenging part in LLM alignment. Conventionally, preference data is collected through rankings and used as preferred\u2013dispreferred pairs for learning, as the human-annotated scalar scores on individual samples can be uncalibrated and noisy. However, the ranking-based reward model may fail to impose correct penalty, since it is trained based on binary relative signals, potentially compromising its precision on individual samples. In this case, I agree with the authors that pair-wise RM may inadequately capture the nuances of real-world preference data distribution, especially on the data where preferences are obviously polarized and scoring quality against specific criteria is unambiguous. Therefore, I think it is important to explore the point-wise RM for better preference learning in LLM alignment.",
        "weaknesses": "While preference learning from pair-wise data is challenging (as I briefly discussed above), it still applies to most cases in the real world. For example, toxicity is not a strictly binary metric as we can categorize samples to be _toxic_, _very toxic_, or just _pose risks of toxic content generation_ [1]. Also for verifiability, there can be labels such as _unhedged correct_, _hedged correct_, and _uninformative_. So I don\u2019t think the authors made a convincing argument regarding the superiority of their point-wise preference learning over the pair-wise methods. In fact, the binary signals could result in significant information loss, since the learning can only capture the data polarity, omitting the nuanced levels present in practice.\n\nAdditionally, the paper lacks empirical analysis with limited experimental results to justify the design of each component in Equation (9). It is hard to interpret how the win rates evaluated by GPT-4 correlate with human judgment or the actual quality. For example, if I understand it correctly, the baseline to compare against is the chosen answer in the dataset, which can be considered as the golden samples for preference learning. This makes the numbers of win-rates in Tables 1&2 somewhat weird and vague since there should be a big proportion of tie cases as indicated in previous works [2]. It\u2019d help to report on metrics that are consistent with existing works for clear and interpretable result comparison. It is also important to extend the evaluation to other benchmarks, _e.g._, RealToxicityPrompts [1], to compare their effectiveness at least in the domain of harmlessness.\n\n---\n[1] Gehman et al. Evaluating Neural Toxic Degeneration in Language Models. Findings of EMNLP 2020\n\n[2] Rafailov et al. Direct Preference Optimization: Your Language Model is Secretly a Reward Model. 2023",
        "questions": "A. Could the authors elaborate more on the design of point-wise preference learning, particularly regarding harmlessness and helpfulness? For example, how to deal with potential information loss when simplifing the label to be strictly binary?\n\nB. The win-rates, especially in Golden HH, are close to $100$%. Could you elaborate on the reasons behind these statistics and also provide information on the corresponding lose- and tie-rates?\n\nC. How did the authors obtain and evaluate the baseline results? For example, there isn\u2019t an official implementation of DPO, how did the authors ensure that their version of DPO is consistent with the original one, and how does their result align with the reported one in the DPO paper?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "AOSsLRKQrX",
    "title": "DisFormer: Disentangled Object Representations for Learning Visual Dynamics Via Transformers",
    "reviews": [
      {
        "summary": "This paper presents a new neural net architecture for decoupling objects from dynamics for the task of video prediction on simple scenes. Using several modifications to existing works, the authors encourage more decoupling of object features from other features like the position and dynamics of the inputs. The authors show improved accuracy on existing simple benchmark datasets over previous networks.\n\n\nMinor typos (did not influence review):\nPage 4: and is a hyperparameter of the model.\nPage 9: we swap the positions swapped the blocks corresponding to shape\n\n\nEDIT:\nI can't seem to comment, so I'd like to add my comments here to the author's responses\nThank you for your updated wordings. I think the paper is clearer now, though I still think some images of the learning problems earlier in the paper during the problem definition portion would make it even stronger.\n\n1. I see what you are saying, but I think of all the problems the only one that convinces me it could generalize to more complex scenes is CLEVR. The other experimental setups are too simple to be called \"visual.\" I'd like to see more evidence on CLEVR and even harder datasets (maybe something with a physics engine and more realistic objects like Ai2THOR).\n\n3. From the appendix: \"We found that even though the permutation\nmodule was trained on same time step object representations, it produces correct permutation matrix\neven for 10 time step apart objects.\" How can you say it's correct if you don't have ground truth permutations?",
        "strengths": "+ The authors show an improvement on the existing state of the art on several benchmark datasets\n+ The architecture accounts for several difficulties in training models to be disentangled in new/interesting ways\n+ The paper is generally well-written",
        "weaknesses": "Clarity:\n- I thought the explanation of the task and the actual problems came too late and were not depicted well enough for what the paper was trying to accomplish. 3 of the 4 datasets used I would call \"toy\" datasets of simple bouncing balls. The 3D dataset seems more visually driven, but even that uses CLEVR which is known to be visually simple. In the whole paper there is only a single picture depicting the actual task, and the tasks are only described in the experiment section. For a paper with \"Visual Dynamics\" in the title, I would have expected less toy problems, and more explanation to what the actual problems were. I think this could have been a stronger paper if it had foregone the visual component and worked directly with low level data.\n- I found several explanations in the paper to be confusing/lacking detail. One key concept in the paper was that of a \"Block\". Here is the explanation from the paper: \"Recently, (Locatello et al., 2020) in the paper on slot-attention proposed architecture for unsupervised discovery of objects via iterative refinement of what is referred to as a slot. Each slot binds to an object via attention over the entire image in their work. We extend their idea to the case of objects, where each slot now represents a block, which is iteratively refined by taking attention over a latent object representation\" - My rephrasing of this is \"rather than take attention over the entire image to get a representation, we first extract an object mask, and then take attention over that\". I'm not sure that is correct, and even if it is, I don't understand why they need attention if they already have a mask.\n- Another instance of this was the Permutation module. I did not understand the motivation behind it considering it is only used at training time. The authors say they learn a permutation to match up objects from one frame to the next, but that they supervise this permutation with ground truth knowledge. Then at test time, this component is removed. If you are already using ground truth information at train time, and at test time you don't use the module, why not just permute the features directly instead of learning a permutation matrix?\n- There were a few other small questions I had about some other phrases. \"All our object extractors are unsupervised and trained in a self- supervised manner. In our experiments, for 2D environments, we train an expert model similar to (Sharma et al., 2023b) to generate supervised data for Mask R-CNN.\" This seems to indicate the model is both unsupervised and self supervised, but then also trained with supervised data. That doesn't make any sense to me.\n\nExperiments\n- I thought the experiments in this paper were lacking in showing what the authors claimed. Predicting simple rigid body circle motion and even rigid body 3D synthetic CLEVR motion is not really convincing since it is such a problem removed from the complexities of the real world.\n- To convince me that there is a decoupling happening, it is crucial to have an experiment that directly probes this decoupling. The ablation study in 4.4 seems to do that in some way, but I don't understand the experimental setup from the explanations, and again, it is only on a toy setup so I can't say whether it would generalize to more complex scenes. It sounds like somehow the authors took the embeddings from one color setup and swapped them with another color setup to look at the output. I guess it seems trivially obvious that the output should change color, but does that prove that the dynamics module only encodes dynamics or just that masking a part of the image results in color features for that part of the image.\n- The DisFormer seems to be another reasonable ablation on paper but not carried out as well as I'd liked. Details are sparse, but it sounds like the entirety of MaskRCNN was replaced with an MLP, which doesn't seem like a reasonable substitution \"by replacing the object extractor (refer Section 3) by an MLP to create dense object representations\".",
        "questions": "I would like the authors to explain in more detail why the permutation model was necessary if it was only used during training. I would also like the authors to explain the DisFormer and experiment 4.4 better.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "In this work, a novel model is proposed for next frame prediction for videos of interacting objects. Building on previous architectures, the authors explore\nfurther structuring an object-centric representation into blocks that represent\nspecific object attributes such as shape or color. Object-centric representations are\nfirst obtained using a pretrained unsupervised segmentation model and a feature\nextractor. Slot Attention is used to decompose object representations into blocks. A\nTransformer than predicts the latent representation of the next frame which is converted into an image using an adapted Spatial Broadcast Decoder. The model consistently\noutperforms previous models on three synthetic datasets.",
        "strengths": "- Learning scene representations that are structured into objects and their attributes\n  is a very relevant topic. An unsupervised approach based on next frame prediction as\n  followed by the authors is applicable in a broad range of settings.\n- The proposed model consistently improves over previous methods.",
        "weaknesses": "The empirical evaluation has a strong focus on measuring quantiative performance\naveraged over entire datasets. Further insights into the inner workings of the model or\ncomponents necessary for outperforming previous approaches are hardly provided.\n- This paper proposes a range of novel model components, a detailed ablation analysis is\n  however missing. The only comparison is to a model that replaces the pretrained object extractor with an MLP. So it is not clear to which degree the different components\n  contribute to the improved performance of the model.\n- The paper does not discuss any particular success or failure cases of the proposed\n  model. Are there specific situations which are predicted better by the proposed model? How do these related to the model components introduced in the paper?\n- The model learns a constant concept space $C$. Do the concept vectors correspond to\n  interpretable attributes? Is there a separation of object attributes into those that\n  contribute to dynamics and others that do not, as asked in the abstract?\n- The disentanglement of object attributes is a core motivation behind this work. The\n  disentanglement is however not quantitatively evaluated.",
        "questions": "- In Phase I of the model, object masks are predicted and the masked objects passed\n  through a feature extractor. Why is this extra step necessary? Is it possible to use\n  the internal representation of the segmentation module directly?\n- In section 3.2: How exactly are block vectors projected onto the learnable concept\n  space? A mathematical description might be helpful here. Why does this project lead to\n  disentangled representations?\n- How were hyperparameters tuned for the DisFormer? How sensitive is the model with\n  regard to chosing hyperparameters?\n- Were the hyperparameters tuned for the baselines?\n- How are the predicted object positions obtained for all methods when evaluating the\n  position error?\n- I do not understand the transfer learning setup in section 4.3: Two variants of the\n  training set are created, are the models trained on both? How is it different from the\n  evaluation setting?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This manuscript introduces a novel approach to disentangled object-centric representation learning specifically tailored for video data. The authors present a method that distinguishes itself from prior work, particularly SysBinder, emphasizing its unique applicability to video data and asserting its capabilities in capturing essential knowledge for future prediction in a disentangled manner. Inspired by Slot-Attention, the method utilizes slot-attention on object-centric representations to delineate attributes per the object-centric representation. The model undergoes extensive evaluation across two 2D datasets and a 3D dataset, demonstrating superior performance in pixel-level reconstruction and position estimation over existing methods. Additionally, the authors subject their model to generalization tests in unseen environments, where it continues to outshine competing approaches.",
        "strengths": "- The motivation behind the study is intriguing and thought-provoking.\n- The exploration of disentangled object-centric representation for video data is innovative, unveiling new insights, particularly regarding the representation of essential attributes for future prediction from video data.\n- The model is intuitively designed, effectively leveraging slot-attention on top of the object-centric representations to disentangle representations.\n- Comprehensive comparative analysis, including ablation studies, robustly demonstrates the advantages of disentangled representation.\n- The figure for their model architecture is well-drawn and easy to understand.\n- The abstract, introduction and the proposed model section are well written except the permutation module section.",
        "weaknesses": "- The manuscript\u2019s clarity and organization can be improved. Specific suggestions for improvement are provided in the questions section.\n- A comparative evaluation with another disentangled object-centric representation learning method, SysBinder, is lacking, despite its mention in the text.\n- The visualization of disentanglement in the manuscript (Section 4.4) could be enhanced for better clarity and comprehension. Additionally, as they started this paper with the question, \u201cwould it help to learn disentangled object representations, possibly separating the attributes which contribute to the motion dynamics vs which don\u2019t?\u201d, if they can show the disentangled representation for the attribute which to contribute to predict the dynamic, it should be much better.\n- The quantitative results presented could be bolstered with more illustrative examples, showcasing scenarios where the proposed model excels in comparison to its counterparts.",
        "questions": "### Clarity and Presentation\n\n- In the introduction, could you incorporate a high-level architectural diagram or illustration of your model? This addition would facilitate a clearer and more immediate understanding for readers.\n- You\u2019ve described your permutation module as novel. Can you elaborate on its novelty, especially in the context of other existing methods, such as the approach used in the OCVT paper?\n- The Mask R-CNN in your methodology is trained using a labeled dataset. This seems to introduce a discrepancy since the other models under comparison do not utilize labeled data. Could you perhaps validate your model's performance using Slot-Attention or another slot-based model as a substitute for Mask R-CNN?\n- In Figure 1, \u201cNote that each block has its own set of concept vectors; thus, C = || rj=1C j where r represents the number of blocks.\u201d. Why? Shouldn\u2019t the input $mathcal{C}$ be shared for every block?\n- In section 3.2, \u201cwe project each resultant block vector onto the learnable concept space and update its representation as a linear combination of the concepts via projection weights (lines 9 - 12 in Algorithm 1). This step results in discovering the disentangled representation central to our approach.\u201d. Could you provide a more in-depth explanation or empirical evidence to support this assertion?\n- In Algorithm 1, what is $k$? In figure 1, C is consisted of $r$ concept vectors.\n- In section 3.3, \u201cLet the transformer encoder output be \u03b4\u02c6 s ti,b. \u201c For clarity, could you specify that this is the output corresponding to $s_t^{i,b}$?\n- Section 3.4 appears to be complex. To ensure my understanding is correct: is the process essentially projecting the concatenated block vectors through matrix $U$, calculating the Cosine Similarity, and then aligning the most similar representations as the same object? Further clarification and polishing of this section would be beneficial.\n- How is the object position estimated within your model, as detailed in the experiment section? You've mentioned that position error is not reported for SlotFormer due to its lack of explicit object mask handling; does your model operate in a similar manner?\n- Could you provide a deeper analysis of DenseFormer, particularly in comparison to Slotformer? Are there specific scenarios where DenseFormer is more prone to failure, and could you share sample outputs from both DisFormer and DenseFormer to illustrate these points?\n- In Section 4.3, the term \u201ctransfer learning\u201d is used. Based on my understanding, the experiments seem to be more about evaluating generalization to unseen environments rather than transfer learning. Would renaming this as generalization and providing a more comprehensive analysis, especially in light of the varied performance across different datasets, be more accurate and informative? For example, when comparing the results in Table 1, Slotformer performance deterioration for 2D-BC is not huge while Slotformer is worse for 2D-BS. This results can suggest that for more complicated environment, the disentangled representation is more helpful for the generalization.\n- The examples in Section 4.4 intended to illustrate disentanglement seem to be lacking. Instead of swapping both color and shape attributes, could separate demonstrations of each be more effective in showcasing the model\u2019s capabilities?\n\n### Methodology\n- Regarding Section 3.4, why is the permutation module utilized only during training and discarded during testing? Could its application during testing, potentially for aligning the input order of the Transformer module, lead to enhanced performance?\n- For the Dynamic loss calculation in Section 3.6, why is the comparison made between the weights of the concept vectors rather than the block vectors? Additionally, could you provide a definition for $\\hat{w}_t^{i,b,j}$? \n\n### Experiment\n- In Section 3.6, there is a training phase where only the block extractor, permutation module, and decoder are trained, followed by a phase focusing solely on the dynamic model. Could you elaborate on the reasons and potential benefits of this training strategy? Did it result in improved model performance?\n- The model training in Section 3.6 incorporates multiple loss functions. Have ablation studies been conducted to understand the impact of each loss function on the overall performance?\n\n### Additional Comments\nThe study presents an interesting investigation with noteworthy contributions to the field. However, to ensure a stronger impact and facilitate better understanding, a revision focusing on improving presentation, clarity, the comparison with the relevant work, and depth of analysis are recommended.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper proposes DisFormer, which extends Slot Attention and SlotFormer with \u201cdisentangled\u201d object representation for visual dynamics prediction. The disentangled representation is learnt by iteratively refining the slots over individual object representations (rather than the whole image representations), and regularizing the slots to be linear combinations of the concepts. To align the model output with the groundtruth, a permutation module is used to learn the ordering. Experiments are done on 2D Bouncing Shapes/Circles and OBJ3D to show the method works well in both in-domain and domain transfer settings.",
        "strengths": "1. The method is clearly motivated and clearly described. By learning slots representing blocks (which are iteratively updated to recover an object representation), and regularizing the slots/blocks to be a linear combination of concepts, the slots/blocks learn disentangled representations of objects.\n2. Related works, as well as their difference with this work, are well-discussed.",
        "weaknesses": "My major concern is that the experiments are not very persuasive. \n1. The datasets are simple toy datasets. The original SlotFormer has done experiments on dataset CLEVRER, which is harder than the 2D shapes/circles used in this paper. Are there reasons why CLEVRER, or CLEVRER with more complex textures, are used for experiments?\n2. No ablations are provided. The model contains multiple components, but there are no ablation experiments to study the effect of each component. For example, the effect of recovering object representation versus image representation, the effect of learning the slots to be a linear combination of concepts, the number of slots, number of concepts, etc. should be studied.\n3. Not enough experiments are shown to prove the representations are \u201cdisentangled\u201d. This disentanglement is the major advantage of the method. However, only several examples are shown in Fig. 2 to show the disentanglement. Quantitative results, or visualization of the learned slots (e.g. using t-SNE) would be preferred.\n4. Missing experiment details. The training details including the hyperparameters are not provided. Some critical parameters (e.g. number of slots/concepts, loss weights) should be discussed.",
        "questions": "See weakness. More details about experiments would be helpful.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "uEYxHVQJF4",
    "title": "Why are hyperbolic neural networks effective? A study on hierarchical representation capability",
    "reviews": [
      {
        "summary": "This paper studies a benchmark for evaluating the hierarchical representation capacity (HRC) of the hyperbolic neural network (HNN). The empirical study shows the HRC can be affected by the optimization objectvie and the training data. This observation facilitate to develop pre-training strategies to enhace the HRC of HNN, improving the learning capacity and performance of the neural network. This paper shows some interesting observations, but it lacks of the generalization of HNN to other tasks.",
        "strengths": "1-This paper first study the hierarchical representation capacity (HRC) of the hyperbolic neural network (HNN) and aim to answer how the HNN works.\n2-A benchmark, including data and metric, is proposed to evaluate the HRC.\n3-Three pre-training methods are proposed to improve the learning capacity and the performance.",
        "weaknesses": "1-This paper only studies the HRC in the graph dataset, the observation on text and graph data is missed.\n\n2-The experiments on pre-training method misses formulation of the losses. In addition, why the GD as objective function can attain good performance, please explain?",
        "questions": "1-This paper study the HRC for the graph data, there is another metric, called delta-hyperbolicity, can be used to evaluate the hierarchiy of the data, I want to see does the value of delta-hyperbolic matches the value of the metrics proposed in this paper.\n\n2-This paper only studies the HRC in the graph dataset, does the conclusion is also hold in text and image data?\n\n3-The proposed pre-training method should also be evaluated in other datasets.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper elucidates the scope and applicability of HNNs through quantitative analysis of their HRC. It provides guidance on enhancing HNNs by identifying factors that improve their hierarchical representation capability. In particular,\n\n- This paper proposes a benchmark (HRCB) to quantitatively evaluate the hierarchical representation capability (HRC) of HNNs. HRCB includes metrics to assess horizontal relationships (sibling nodes) and vertical relationships (parent-child nodes) in a hierarchy.\n\n- Experiments using HRCB show that HNNs do not achieve the theoretical optimal embedding in hyperbolic space. Their HRC is significantly lower than combinatorial construction methods.\n\n- Analysis reveals two key factors influencing HNNs' HRC: (1) Optimization objectives that help distinguish positional relationships between nodes, and (2) Training data structured as a complete n-ary tree.\n\n- The paper proposes pre-training strategies to enhance HNNs' HRC based on these insights. Experiments show improved downstream task performance from enhanced HRC, validating the analysis.",
        "strengths": "The author made a very interesting observation and conducted numerous experiments to support their findings.",
        "weaknesses": "There are several points of concern from me:\n\n- The HRCB metrics presented presume the root node is positioned at the highest point. Additionally, the authors assume that the root node should be close to the origin. This isn't accurate for all HNNs, as detailed in [1]. If these assumptions are invalid, the four evaluation criteria proposed might not be accurate.\n\n- The research primarily uses two datasets (Disease and Animal) for analysis. Including a broader range and real-world datasets would provide more robust conclusions.\n\n- The author's description of pre-training strategies isn't very clear. Could this be elaborated more?\n\n- The comparison is made with the GCN model, but the HGCN isn't considered. This is an omission.\n\n- While the findings are intriguing, there are various forms of HNN currently available, such as those based on the tangent space or being fully hyperbolic. The author doesn't seem to address this aspect.\n\n[1] Menglin Yang et al. Hyperbolic Representation Learning: Revisiting and Advancing. ICML 2023.",
        "questions": "1. Could you provide more details on the data generation process for the hierarchical structures?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper carefully examines the effectiveness of various Hyperbolic Neural Networks (HNNs) by measuring their Hierarchical Representation Capabilities (HRC), an evaluation process named as Hierarchical Representation Capability Benchmark (HRCB). The four metrics developed for HRCB include Root Node Hierarchy, Coordinate Origin Hierarchy, Parent Node Hierarchy, and Sibling Node Hierarchy, which altogether measure how well the hierarchical structure is embedded in hyperbolic space. The paper also proposes pre-training strategies upon improving a model's HRC, and empirically assess the relationship between HRC and downstream performance. Experimental results show that HNNs' HRC has a significant impact on downstream performance, and pre-training HNNs towards enhancing HRC can improve its performance.",
        "strengths": "- [S1] The motivation of looking back upon hyperbolic neural networks and closely assessing their effectiveness on downstream tasks with respect to theoretical work is very interesting, and I believe any insights would greatly benefit the geometric deep learning community.\n- [S2] The scope of experimentation is fairly comprehensive, covering various downstream tasks, hyperbolic manifold spaces, and neural network architectures.",
        "weaknesses": "- [W1] **The overall contribution is not clear within the writing and experiments.** Is the paper hoping to show why HNNs are effective? or that HNNs do not achieve theoretically optimal embeddings?. From the experiments, it seems the goal of the paper is that 1) there exist a gap in HRC between existing HNNs and theoretically optimal embeddings and 2) reducing the gap via pre-training helps boost downstream performance, yet the overall writing (e.g., abstract and introduction) makes it confusing on what to expect from the experiments: reasons behind HNNs' effectiveness or limitations of HNNs. \n- [W2] **The presented empirical observations in the text are unclear and somewhat misleading.** For instance, page 7 discusses how the LR target for NC \"does not need to distinguish the position relation\" among nodes, yet overfitting on LR helps improve HRC, which seems counterintuitive. Why is this the case? Furthermore, page 8 mentions how \"within the applicable scope of HNNs, performance can be improved by enhancing HRC\", with the node classification task being \"out of scope\". This is misleading considering that many previous work have shown performance boosts in node classification by leveraging hyperbolic models [A, B, C].\n- [W3] **The figures showing Friedman test and Nemenyi post-hoc tests are extremely hard to read.** It would be better to categorize results based on what the authors are hoping to convey through the experiment: as an example, for Figure 6(a), if the main observation is that GD, HR, and FD help HNNs learn position relation unlike LR, it would be better to simply draw a bar chart (or multiple bar charts, one for each manifold) with targets on the x-axis and the HRC values on the y-axis. That way, we can visually observe the orderings currently written as text within the plots.\n- [W4] **Downstream performance results are missing exact scores and are only compared in terms of rankings.** For Subsection 5.2.3, it would be better to simply present the downstream results in exact scores using the scoring metrics for each downstream task (F1 score for node classification, mAP for graph reconstruction and so on). This way, we can concretely estimate how much better/worse each method performed compared to another, and whether the results are within reasonable range compared to existing literature.\n\n[A] Chami et al., Hyperbolic Graph Convolutional Neural Networks. (NeurIPS 2019)\\\n[B] Liu et al., Hyperbolic Graph Neural Networks. (NeurIPS 2019)\\\n[C] Zhu et al., Graph Geometry Interaction Learning. (NeurIPS 2020)",
        "questions": "- [Q1] The Coordinate Origin Hierarchy metric $M_o$ seems to assume that the root node is located near the origin, while this constraint is not made explicitly during training of HNNs. Considering that Combinatorial Construction [D], on the other hand, trivially satisfies this assumption, would you still consider using this metric to be valid for fair comparison?\n- [Q2] Is the L strategy described in the beginning of subsection 5.2.3 equivalent to adding a weighted auxiliary loss to the downstream predictive loss? This seems very similar to how the HGCN paper used a link prediction regularization objective for node classification [A]. Thus adding a few discussion on this connection and giving the strategy a proper name rather than just \"L\" could help towards better clarity.\n\n[D] Sala et al., Representation Tradeoffs for Hyperbolic Embeddings. (ICML 2018)",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "1FWDEIGm33",
    "title": "Large Language Models as superpositions of cultural perspectives",
    "reviews": [
      {
        "summary": "This paper challenges the view of large language models (LLMs) as individuals and proposes a new metaphor: \"LLMs as superpositions of perspectives\". The authors conducted experiments that demonstrate unexpected perspective shifts in personal values, cultural values, and personality traits. LLMs changed their responses depending on contexts, and even context variations not related to the target topics led to significant changes in the values and personality traits they expressed. The authors also compared four different perspective induction methods (prompts) to assess whether they could control the models' perspectives (perspective controllability).",
        "strengths": "- This paper studies large language models (LLMs), which is a hot topic in the current society.\n- The paper challenges some existing views on LLMs trying to understand them better, giving some warnings of the potential danger of the existing views.\n- The paper explores if the \"perspectives\" could be controlled, by suggesting four induction methods.",
        "weaknesses": "I struggled to understand the importance of this problem, even after reading the paper. It is unclear what the implications and potential applications of this work are. The paper confirms that LLMs do not give consistent responses, and that LLMs are not like humans, as shown in Experiments and discussed in Discussion. However, it is not clear what the paper suggests (besides proposing a new metaphor) and why this is critical.",
        "questions": "1. Could you elaborate on the definition of a perspective in this paper? \"A perspective is conceptualized\nas a context from which a model is required to simulate a behavior\". \n2. it is not clear what the paper suggests (besides proposing a new metaphor) and why this is critical.",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper studies the ability of language models to answer psychological questionnaires. Past research has used these tests designed for humans to try to probe LLMs. The study tests model robustness in answering questionnaires under different contexts or conditions (e.g. writing code, prefixing with a random wikipedia page) which are unrelated to the question in the questionnaire and observe there are significant changes in responses. Further, the paper introduces the notion of perspective controllability and aims to test which models can be guided to answer questions in a certain way.\n\nThe conclusions are that LLMs are unreliable in answering trait questions, with unrelated perturbations leading to different results and that most models are not controllable, albeit some models exhibit some degree of controllability.",
        "strengths": "Sound methods for statistical analysis of results.\n\nCreative approaches to test robustness of models.\n\nAdequately challenges the assumption of 'LLMs as individuals' for measuring traits.",
        "weaknesses": "Primarily, I think the model needs to have more robust results to understand better what and which types of models behave in different ways. Namely:\n\nThe first experiment (Section 4.1) is only performed using a single model (ChatGPT).\n\nThe models can be better selected for experimentation to facilitate understanding the machanisms that lead to consistent or inconsistent results in Table 1. I think the key comparison directions could be along these axes: base model, models from the same series and different size, base vs. chat. vs. instruct vs. RLHF.\n\nI think the experiments lead into another metaphor than 'superposition of cultural perspectives'. For a perspective to hold, it would have to be consistent across inputs i.e. to produce consistent results when conditioned in the same way. The results show that the conditioning changes results in unexpected and inconsistent ways. Hence, my conclusion from these experiments would be that LLMs lack awareness or knowledge of a perspective.\n\nIn general, I consider using questionnaires about traits is a bit tricky or ill posed in this context. The questionnaires for traits are usually built as a proxy for behaviors e.g. 'make friends easily' loads on the intra/extraversion scale; so it would be perhaps more suitable (and robust?) to have these framed as test on a behavior e.g. at a party where you don't know anyone and some one is sitting also alone, do you approach to strike up a conversation with them? (yes - more likely extravert, no - more likely intravert).\n\nAnother aspect worth mentioning is that in addition to the test-retest validity which is brought up in the paper as stability over different ways of providing context before asking the questionnaire question, one could also measure the variance inside each questionnaire, as multiple questions load on the same factor and the variance across these should also be low by design (i.e. people would respond to questions about extraversion similarly).",
        "questions": "NA",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The authors make the case that LLMs show a sort of superposition of cultural perspectives, since their outputs, as measured by standard tests widely change according to the input. The authors consider value and personality tests in order to measure different \"cultural perspectives\" in LLMs. One of the goals of the authors is to measure the consistency of the outputs of the LLMs in an experimentally sound way. The evaluation is carried on several LLMs.",
        "strengths": "+ The paper is indeed timely, there is a lot of interesting ideas to explore around LLMs and this is indeed a good example of an interesting paper in the area.",
        "weaknesses": "- The study that the authors carried out is indeed interesting, but unfortunately, it seems to me that the actual assessment of the results is somehow \"hyped\": at the end these are probabilistic models highly dependent on the prompt and it is somehow expected that they exhibit a variety of personal values, cultural values, personality traits. The authors highlight the fact they observe \"unexpected perspective shift effects\". However, in my opinion, it would be more surprising to see consistency. \n- It is very difficult to understand which inputs led to a change of perspectives. In my opinion, this is a key problem of the paper since small variations might have a significant effects on the outputs. Also, for this reason, it is very difficult to judge the actual consistency of the outputs of the LLMs in the experiments carried out by the authors.\n- Superposition is a wrong term in my opinion given the probabilistic nature of LLMs. In fact, even the same input might lead to different outputs.\n- The term controllability appears to me inappropriate, since the authors are not measuring actual \"controllability\" of the outputs in my opinion.\n- The selection and the analysis of the application of the induction methods are not completely clear, especially with respect to the underlying research hypotheses at the basis of the study design.",
        "questions": "- What is the exact definition of cultural perspective you consider in the paper? What is the relation between cultural perspective and personal values?\n- Which kind of inputs did you use for measuring the change of perspectives? (the supplementary material does not consider sufficient material for reproducibility in my opinion).\n- It seems that the authors report the fact that LLMs are not \"coherent\" as the key finding of their paper. Indeed, it is always good to see measurement studies, but the reviewer wonders if this can be considered as something unexpected. After all, the models are trained on a variety of sources. Were the authors expecting a different result? \n- Do you have any data about the influence of the training datasets on the experimental results that you showed in this paper?\n- Can you discuss Formula (1) in details? How do you analyze the outputs of the LLMs? How do you calculate the mean in this formula?\n- It would be good to know the reasoning beyond the selection of the term \"controllability\". This appears an unusual choice for the phenomena you study in this paper.\n- Can you please discuss the effects of the induction methods in relation to their effects on the outputs of the LLMs?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "In general discourse surrounding the rise of LLMs, it is common to ascribe individual characteristics to LLMs. This paper challenges this tendency suggesting that it is more evident to view LLMs as a superposition of perspectives instead of as individuals. The paper provides empirical demonstrations to make this point. In particular, the experiments included show that LLM responses are context dependent in ways that differ from humans. The paper calls into question the use of psychological questionnaires to examine LLMs. The main contribution is the introduction of \"perspective controllability\" and an empirical demonstration to probe whether LLMs are robust to perspective shift effects and how different LLMs compare in terms of their perspective controllability.",
        "strengths": "(1) The experiments seem thorough and the paper states that reproducibility and transparency has been a priority.",
        "weaknesses": "(1) The framing of the paper needs significant improvement. The argument seems to go something like this: LLMs tend to be context-dependent. Humans tend to be stable across contexts. Therefore, LLMs should not be assumed to be human-like. Probing an LLM with questions derived from a field that assumes a human subject is flawed. Making general conclusions from results based on these questions is also flawed. LLM as a superposition not an individual is proposed is a new metaphor. This new metaphor motivated the study of perspective change in LLMs, which is the focus of this paper.\n\nNotice there are multiple jumps in this line of argument. First, the fact that LLMs are context-dependent needs to be reconnected to the point about LLMs being seen as individuals. You do not need to provide evidence that LLMs are not human-like to make this point. Second, the paper briefly argues that probing an LLM with questions derived from psychology is problematic but this point is not properly fleshed out or supported directly by results. Third, the point that general scientific conclusions are therefore problematic has not been properly made. Fourth, the reference to quantum mechanics is an interesting inspiration for said metaphor but is not a sound analogy in that language models do not operate in the quantum regime. Further, this inspiration is not necessary to make the argument laid out in this paper. Fifth, the main final point which is that studying perspective change in LLMs to study induction techniques is disconnected from the rest of these points and could stand as an interesting topic in itself.\n\n(2) Conclusions are overstated. The paper states \"we will see that discarding the old metaphor may question the interpretation of recent studies aiming at characterizing the values, personality traits, social skills or moral values of LLMs using tools developed to measure attributes of human psychology\". The current status of the argument has not led to this conclusion directly. The paper needs to reconnect and build out a cohesive careful argument in order to support this claim.\n\n(3) Exposition could be greatly improved throughout for clarity and precision. For instance, the related works section is written as part of the argument that recent work uses \"LLM as an individual\" metaphor, which should be discussed as such. The paper states \"There has been a lot of research studying large language models using tools from psychology...\" before the paper has fully developed the argument for what it means to view \"LLM as an individual\". It is more standard to use the related works section to contextualize this work in reference to existing literature not necessarily to support the content of your argument. Further, the paper states \"All these works aim to make general conclusions about LLMs\nbehavior, personality, or abilities, but they do not explore how personality traits expressed through\nbehaviour can change in unexpected ways over diverse unrelated contexts.\" which seems to say that the difference is in the focus on changes due to unrelated contexts. It would have been clearer to simply state that this work is related to other studies of personality traits but diverges in its focus on context-based shifts in performance. But for some reason, the section is written in a way that requires the reader to parse this out. \"At first glance, these might seem like examples of the unexpected perspective\nshift effect, however these effects are both common in humans, and their effect on the perspective\nchange is intuitive.\" This sentence is unclear and way too dense. And again, not exactly positioned properly in related work section if the function is to be part of the overall argument of the paper. The section continues with \"The second part of our paper studies how models\u2019 values and personality expression can be controlled, i.e., the expected perspective shifts due to context changes.\" This marks a shift in tone where the section is now describing the paper instead of the related work. Again, a sign of expository improvement needed.\n\n(4) The main focus is not clearly defined. The first sentence in the methods section states, \"This paper aims at uncovering the existence of unexpected perspective shift effects i.e. how context can impact the values and personality traits expressed by LLMs in unwanted, unexpected ways\". This is the definition provided. It is unfortunately unclear.",
        "questions": "(1) What is the technical definition of \"unexpected perspective shift effects\"?\n\n(2) How do you distinguish between expected and unexpected? Expected by whom?\n\n(3) What is the technical definition of \"perspective controlability\"?\n\n(4) What is the theoretical basis for equation (1) ?\n\n(5) How does this compare to other measures of predictive inconsistency? Why is \"context\" so specifically interesting in this paper?\n\n(6) How do you define induced perspective? Can you offer theoretical analysis to support your measure?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "hxAveMWogn",
    "title": "InstaTAP: Instance Motion Estimation for Tracking Any Point",
    "reviews": [
      {
        "summary": "The core idea of this paper is that points on the same object are physically bound and should share the same motion statistics. To achieve this, the authors propose to average the initial motion estimates of some points on the object as the motion of the whole object. Then crop the video frames along the object trajectory to achieve high precision point trajectory tracking.",
        "strengths": "1. The proposed scheme is easy and effective, and its improved performance is demonstrated on various datasets as well as on downstream tasks.",
        "weaknesses": "1. Eq 5 shows the present method takes average pixel displacements as the object motion and claims that it is a reliable instance-level motion estimation. But directly calculating the average pixel displacements is valid if and only if the object only translates in the image plane. This cannot be valid if the object is rigid and there is affine motion such as rotation, or if the object is non-rigid. I agree that such a naive assumption can be used as an initialization for model optimization, but I don't think it's an exciting innovation to elaborate on such great length.\n2. the model Seg, which produces the segmentation mask for the initial frame. This method uses SAM for preprocessing, is it only for the first image or for all video frames? How do the later frames establish associations with the points in the earlier frames? This procedure needs further clarification.\n3. InstaTAP can be built on top of any existing point tracker. But there is no discussion in experiments. \n4. Lack of computational complexity analysis. Looks like a very heavy optimization process.",
        "questions": "1. Does the proposed mechanisms require to retrain the existing point tracking models? Or just need to use publicly available pre-trained models?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This study tackles the challenge of accurately learning long-term trajectories for individual points in video sequences, such as the Tracking Any Point (TAP) task. Point-level motion estimation is hindered by the inherent uncertainty in comprehensive frame-wide comparisons. Existing models address this by using regularized comparison spaces like cost volumes, but they still suffer from noisy point-level motion, leading to tracking failures. To overcome this, the proposed method jointly tracks multiple points within a semantic object, leveraging the fact that points within an object tend to move together. By predicting object masks with Segment Anything Models (SAM) and implementing a two-stage procedure, the approach significantly improves tracking precision, surpassing state-of-the-art methods by up to 25% in accuracy on the TAP-Vid benchmark. Additionally, the approach demonstrates advantages in video depth estimation and frame interpolation by utilizing point-wise correspondence in these tasks.",
        "strengths": "Using Segment Anything Models (SAM) to enhance performance is a very interesting idea for motion prediction.",
        "weaknesses": "1. The main contribution is to exploit SAM to boost the performance of tracking. However, the SAM is an existing method so the contribution of this framework is limited. \n\n2. The proposed method's performance is closely tied to the effectiveness of SAM. If SAM encounters difficulties, such as producing inaccurate or poor segmentations, it can adversely affect the performance of the tracking framework. The quality of the object mask prediction by SAM directly impacts the tracking accuracy and robustness. Therefore, in scenarios where SAM struggles or fails to provide precise segmentations, the tracking performance may indeed experience a significant drop, highlighting the method's dependency on SAM's success in providing accurate object masks.",
        "questions": "Can you show some failure cases of the proposed method? Is that related to the SAM results?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper is about tracking every point (TAP). Basically, it adopts a point-prompted segmentation by Segment Anything Model(SAM) to enhance the performance of existing models by estimating the average motion within the segmentation mask followed by a refinement stage to get final tracking results. Finally the authors evaluated on TAP-Vid benchmark to compare with previous published methods and show its practical usage in other vision tasks.",
        "strengths": "1. The paper is in general well-written. It clearly pinpoints the limitations of existing methods, e.g. the failure cases of cost volume calculation, then proceed to the proposed method part.\n\n2. The idea of utilizing occlusion information within weighted aggregation, is reasonable, and demonstrates to be effective in the experiments.",
        "weaknesses": "1. I am not a fun of the overall idea. Basically, this work is about an \"A+B\" style and I don't see too much innovation behind simply adding segmentation masks produced by SAM model. If SAM can be used, then any other SOTA semantic/instance segmentation models can be adopted to yield better performance. So the contribution here is a bit too trivial.\n\n2. There are too many engineering stuffs in designing the tracker. For example, clipping, multi-scale operations. I don't see any \"learning\" stuff in the contribution side.\n\n3. Overall misleading claim. For example, in the abstract part, authors claim a SOTA performance \" For example, on the recent TAP-Vid benchmark, our method advances the state-of-the-art performance,\" But the performance is at least inferior to the paper [A] in TAP-Vid. For example, In Kinetics [A] has AJ 55.1, $\\sigma_{avg}$69.6 while this work achieves only AJ 51.4, $\\sigma_{avg}$65.8. On RGB-Stacking [A] has AJ77.5 and $\\sigma_{avg}$87.0 while this work gets AJ66.6 and $\\sigma_{avg}$81.8, this is also the case for DAVIS dataset. That is to say, the performance is NOT SOTA indeed, and it is hard to justify the usefulness of the overall idea.\n\nReferences:\n[A] Qianqian Wang et.al. Tracking Everything Everywhere All at Once. ICCV2023",
        "questions": "I wonder is it possible to add other metrics in TAP-Vid, such as OA, TC, for a more complete comparison with prior methods?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "dYjuJGTEbc",
    "title": "An Enhanced Gromov-Wasserstein Barycenter Method for Graph-based Clustering",
    "reviews": [
      {
        "summary": "The paper presents a Gromov Wasserstein (GW) Clustering Method based on a single marginal GW Barycenter : EGWB. The method also allows to add marginal or ambient metric constraints on the barycenter. Thus effectively showing that their method is a generalization of existing GW Learning methods. Later on more precise links are made with existing methods.\nThey first introduce a Monge type barycenter problem and a Kantorovich relaxation of it. It is shown that under appropriate conditions the two problems are equivalent.\nAn optimization algorithm relying on entropic regularization is presented. The convergence of the algorithm is shown.\nFinally their method is benchmarked against existing GW Clustering methods, on synthetic and real data. On all accounts EGWB outperforms existing GW methods.\n\nThe contributions are the following:\n- Introduced a generalization of existing GW Learning Methods\n- Demonstrated theoretically and empirically their algorithm for solving the problem converges and has state of the art performances",
        "strengths": "The paper presents a unifying framework for GW methods. It does so clearly.\n\nThe core idea is to introduce the GW barycenter problem and note that adding constraints recover existing methods. This problem seems novel in that context and they address with clarity the first questions one can have  : equivalence between the Monge and Kantorovich type formulations, link with other methods in GW Learning as well as in Graph partitioning.\n\nTheir algorithm is an alternating minimization one. However they address the non convexity of the transport plan update by using an interesting combination of existing regularization methods : entropic regularization, link with the Wasserstein Barycenter problem which has better structure.\n\nThe synthetic data example is informative of how the barycentric nature of the problem allows for more efficient clustering. In the analysis of the performance on real data the explanation of the performance in relationship with the structure of the data is appreciated.",
        "weaknesses": "In the paragraph about Kantorovich relaxation it is stated that the minimum is attained at an extremal point under some conditions which are detailed in appendix. This point is central to the use of the algorithm afterwards. Thus I believe the conditions should be put forward in the main text.\n\nIn theorem 3 it is unclear in which case the algorithm converges with entropic regularization, however this is central to showing that the implemented algorithm does converge.",
        "questions": "How does the result of theorem 3 relates to the convergence of the algorithm implemented in practice?\n\nAre there a stability result of the limit of the algorithm/solution of the problem with respect to the epsilon parameter?\n\nIn practice what are the optimal value used for the epsilon parameter for each datasets?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "In this submission, the authors propose a new graph partitioning framework EGWB, which relaxes the target structure and distribution constraints in Gromov-Wasserstein Learning (GWL) with a class of positive semi-definite matrices.\nIn particular, by learning the target structure matrix associated with the transport plan, the authors extend the GWL framework to a special GW barycenter problem (with only one graph), which enhances the flexibility of the GWL framework.\nThe proposed method is shown to be effective according to empirical results in various graph partitioning tasks.",
        "strengths": "Graph partitioning based on utilization of the Gromov-Wasserstein (GW) distance is an interesting and significant problem.",
        "weaknesses": "1. How to initialize $D\u2019(0)$? How to set the value of $K$?\n\n2. It seems the authors confuse the task of graph partitioning and that of graph clustering. They muddle up partitioning and clustering throughout this paper. \nI think the experiments in section 4.2 are more likely to be a graph partitioning task, rather than graph clustering, as is claimed by the authors. Please use one of the two definitions consistently in the paper.\n\n3. In the subsection of Results and Discussion, the authors say they employ five metrics, however, I only find AMI. If they take the results reported in appendix into account, then should clarify this in the main context.\n\n4. Are the datasets in section 4.2 asymmetric or symmetric? Do the authors symmetrize the directed graphs? \n\n5. What do the two axes in Fig.3 represent? It should be labeled in the figure.\n\n6. There are typos and careless statements and the authors need to polish this paper carefully. For example, 1) page 1, it should be $G_1(D_1,P_1)$ in the third row from the bottom, 2) page 2, the second paragraph, the second point of the limitations has grammatical mistakes, 3) What is EGWB an abbreviation for? The author put forward EGWB without any explanations in page 6.",
        "questions": "Please see above.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper propose a graph partitioning approach based on the Gromov-Wasserstein (GW) distance. This approach minimizes the GW distance between the target graph and an empty graph with fewer number of nodes. The optimization problem finds an optimal mapping, which determines the node clusters. It jointly optimizes node mass distribution and pairwise distance relations in the empty graph, the later constrained to be diagonal. The authors propose an algorithm which alternates the minimization of these variables and provide theoretical convergence guarantees.\n\nFurthermore, the authors establish connections between their approach and existing GW-based methods, as well as alternative techniques like Min-Cut. Finally, they empirically demonstrate the effectiveness of their proposed method.",
        "strengths": "The authors present an extension of previous GW-based clustering methods, while connecting them with other approaches such as the Min-Cut or Non-negative Matrix Factorization. In addition, they propose an algorithm with theoretical guarantees. In this regard, the paper seems to be theoretically well founded.\n\nAdditionally, their proposed algorithm showcases remarkable robustness against edge noise when compared to the competing methods outlined in the paper.",
        "weaknesses": "- Challenges in Readability: In certain instances, the meaning of the notation, although not formally introduced, can be grasped from the context (e.g., $mathbb{I}_K$ denoting the identity matrix with $K$ rows). However, there are situations where the notation becomes confusing, posing a challenge to the paper's readability. For example, in the discussion of the \"Monge's type Gromov-Wasserstein barycenter\" in Section 3, the optimal mapping matrix is denoted as $MGW(G, G\u2032)$, but this notation is also used as the objective in the minimization equation (7). The concept of minimizing a matrix raises confusion. In addition, the symbols $\\pi$ and $\\Gamma$ are interchangeably used to refer to the same object. For instance, three lines before equation (7), it states $\\nu=\\pi^T 1_N$, but in this context, as far as I did not misunderstand it, we are assuming a hard clustering mapping and therefore $\\Gamma$ should be the appropriate symbol. Furthermore, though it is not crucial, adding the labels to the x-axis and y-axis of the plots would also ease the readability of the figures.\n\n- The proposed method initialization depends on the results of other methods such as GWL and SpecGWL.",
        "questions": "- Initialization dependency: The paper mentions using a linear combination of GWL, SpecGWL, and joint distribution results as initial values for EGWB. However, it's unclear how the algorithm relies on this initialization. Could a less informed start, like the uniform distribution, yield comparable results or does one need to start from a relatively good initialization?\n- Computational cost: While the paper outlines the computational cost per iteration, the average number of iterations required for convergence remains undisclosed. Additionally, considering the initialization dependency, it's crucial to know the overall time needed to run EGWB, especially if solutions for GWL and SpecGWL must be computed beforehand.\n- Synthetic data: Figure 4 exhibits superior results for GWL and SpecGWL compared to Figure 2. Moreover, in Figure 4 GWL out performs SpecGWL given the true cluster size distribution. Is there any reason why is that the case? I am actually surprised that, for these apparently simple problems GWL and SpecGWL fail to retrieve the right clustering. Understanding the specific reasons for their failure is beneficial in order to comprehend why EGWB, in contrast, succeeds.\n- Number of clusters: A parameter that needs to be set is the expected number of clusters $K$. This is indicated by the number of nodes in the empty graph. How robust is the algorithm to the choice of $K$? Particularly intriguing is the scenario where $K$ exceeds the actual number of clusters. In theory, it is possible that the optimal mapping does not assign any mass to the extra nodes of the empty graph. In that case, the algorithm would still be able to retrieve the true partition. Does this happen in practice, and how does the algorithm adapt to such situations?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "Over a single input graph (D, h), authors study the problem of learning via the Gromov-Wasserstein loss (GW) a non-negative diagonal target structure D\u2019 and its masses h\u2019, in order to perform a partitioning of (D, h) via the underlying estimated (GW) transport plan. They propose to use a Block-Coordinate Descent algorithm that alternates between i) estimating a semi-relaxed GW transport plan using a mirror-descent scheme with an additional strictly concave regularization; ii) updating the diagonal structure D\u2019 in closed-form. Authors empirically study the concavity of the resulting problem, and provide proofs of convergence for their algorithm. Then, they connect this GW (diagonal barycenter) problem or simplified variants to well-known clustering methods such as Min-Cut based methods, NMF and Max-Dicut. Finally, they study the relevance of their approach for graph partitioning of synthetic and real-world datasets.",
        "strengths": "-\tIntroduce a novel GW-based transport problem to perform graph partitioning.\n-\tProvide first results on the concavity of this problem. Then provide an algorithm to and introduce a strictly concave regularization of this problem that might help for such tasks.\n-\tProof of convergence of their BCD algorithm.\n-\tInteresting but simple connections with existing clustering methods such as Min-Cut based methods , NMF and Max-Dicut.\n-\tBenchmark on GW-based and SOTA approaches for graph partitioning.",
        "weaknesses": "**Overall appreciation**: This paper tends to omit very similar recent works and the theoretical results seem either incomplete (analysis of concavity and relationships with existing graph partitioning/clustering methods) or incremental.\n\n*NB: I added comments after authors' rebuttal in italic for each point*\n\n- **1. Authors omit several recent contributions on GW**:\n     - **a)** [A] studies the complete (sr)GW barycenter problem where the target structure is not forced to be a non-negative diagonal matrix. This paper shows that it is a SOTA method for spectrum-preservation graph coarsening and provide strong theoretical contributions supporting its use.\n       **i)** These spectrum properties are also of particular interest for graph partitioning, hence the (sr)GW barycenter problem should be rigorously compared theoretically and empirically to the (sr)GW diagonal barycenter problem. **ii)** I believe that simple Stochastic Block Models (SBM) could provide a stress test over which the srGW diagonal barycenter problem fails contrary to the srGW barycenter problem : e.g using non-assortative SBM with a unique intra-cluster connectivity p smaller than inter-cluster connectivities $q_{cluster_i, cluster_j}$. Moreover I expect the diagonal structure to be more sensitive to contrasts within any SBM, i.e small variations between intra/inter-connectivities. Could authors perform such empirical sanity-checks ?\n\n        [*None of these points have been clearly addressed by the authors during rebuttal*]\n\n     - **b)** relations to srGW [Vincent-Cuaz et al, 2022] : **i)** The (sr)GW barycenter problem over a single input graph is a particular case of their dictionary learning. **ii)** The srGW solver proposed by authors is exactly the mirror-descent algorithm introduced in this other paper over which a concave regularization is added. These two points should be clearly stated in the paper.\n\n        [*None of these points have been clearly addressed by the authors during rebuttal*]\n\n     - **c)** On the proof of convergence for the algorithm: **i)**  [B, C] provide a scheme of proof to establish a non-asymptotic convergence of the regularized srGW solver. [*Not considered by the authors during rebuttal*] \n\n         **ii)** An overview of the proof strategy for Theorem 3 should be clearly state  [*Not considered by the authors during rebuttal*]. More importantly Lemma 2 should be clarified : as such it seems wrong/ incomplete to me, e.g differentiability issues at the border are avoided, limits are considered out of the domain, continuity arguments are used without defining any topology etc...\n\n         [*I am sorry I made a mistake on this matter, Lemma 2 is correct. As first suggested, an overview of the proof strategy would have helped for readability. Moreover authors follow a proof scheme from another more generic paper over which it would have been relevant to discuss relations. From my understanding, the first convergence proof for the srGW problem provides bounds involved in their finale convergence analysis. A sharper convergence proof - following B, C - could provide a sharper analysis and adaptive scheme for their regularization parameter.*]\n\n         **iii)** The overall learning algorithm seems to be a particular case of two-block BCD well-studied in [D]. [*Reference not considered by authors. It implies that more generic converge proofs already exist for their BCD.*]\n\n     - **d)** First parts of the supplementary materials: (minor) paragraph  \u2018Non-convexity of GW discrepancy\u2019 exposes known relations. (more important) paragraph \u2018Assumption of uniform distribution\u2019 seems to be a bad justification for the choice of input distributions that only translates the notion of weak-isomorphism discussed in [Chowdhury et al, 2019].\n\n        [*Rebuttal made by authors is not compelling.  My point is that this dilution of mass// duplication of points of the support is absolutely not a justification for assuming a uniform distribution. What matter is the total mass assigned to the original point of the support. Your justification is misleading and formally wrong if you rigorously acknowledge the support of the measure. You can say we pick uniform distributions because it is the most common choice, note that there are other options (degrees etc..)... Moreover the sensitivity analysis in the supplemetary material is really not clear, that would be better to see a complete benchmark with same hyper parameter validation with several cases as b = 0 / b =1 / b in ]0, 1[. Maybe that is a by-product of learning the diagonal/complete barycenter, or just of diverse regularization coefficients. \"which further validates our mass splitting technique.\" just does not make sense.*]\n\n\n- **2. The several concavity analysis done by authors are incomplete and not conclusive:**\n     - **a)** Could you detail the experiments illustrated in Figure 1 ? What is D\u2019 in this setting ? What Is the initial transport plan used for these experiments ? Are these findings consistent w.r.t these initial transport plans (should be validated using the MCMC sampler in SpecGWL) ? What are the solvers used for these experiments ? If entropically regularized ones, please compare results to exact solvers such as conditional gradient solvers. *[Partially addressed by authors]*\n    - **b)** Are these findings specific to heat kernels or do they generalize to PSD matrices e.g Laplacians  ? *[Misunderstood by authors - no time for discussions]*\n    - **c)** None of the theoretical studies on the concavity of the overall learning problem are complete or convincing: **i)** proof/paragraph: \"One common condition for extremal points\" only shows that for an optimal target masses nu*, the resulting GW problem is concave hence solutions are extremities of admissible coupling with marginals mu and nu*. It does not show that extremities of the set of semi-relaxed couplings with first marginal mu, i.e hard-clustering matrices, are solutions. *[Incomplete analysis by authors maybe we misunderstood each other on the term extremities, considering that they always assume the existence of corners for $U(mu, nu^\\star)$ no matter $nu^\\star$ .]*\n\n      **ii)** I do not see when the other condition in equation 19 could be applied, authors should discuss this point. *[partially addressed but still emphasises the strong specificity of this result]*.\n\n      **iii)** Remark: Overall, a too recent contribution [E] to be taken into account at the submission date deals with these concavity problems for srGW barycenters and could guide authors to derive an analog result for the srGW diagonal barycenters.\n\n\n- **3. Zero masses**: Authors do no mention the flexibility of this learning problem to get optimal target masses which are equal to zero and might allow to detect true number of clusters in some settings, as discussed in [Vincent-Cuaz et al, 2022]. *[partially addressed by authors]*\n\n\n- **4. Missing points in experiments**: \n    - **i)** Please benchmark methods in terms of running times too. Trade-off in terms of performances and speed should be explicit. *[partially addressed by authors]*\n    - **ii)** The strongly concave regularization with continuation scheme proposed by authors introduce several hyperparameters. Please conduct an ablation study over this regularization. Plus could you complete Figure 11  that shows that the method is quite sensitive to these hyperparameters, with other datasets ? *[Ablation study not considered by authors. Sensitivity analysis apparently completed but from the revised paper version we can not even know what is the dataset used in these experiments]*\n    - **iii)** Authors rely on other GW-based methods to get initial transport plans for their method. Whereas [Vincent-Cuaz et al, 2022] proposed to leverage k-means algorithm, which is a quite common technique in the clustering or graph partitioning literature. I guess, in concave setting solvers can be stuck at extremities, hence it would be relevant to force initial within the polytope e.g with kmeans + mu.nu^T. Could you further compare these choices ? *[not considered by authors]*\n\n- **5. Some parts in Section 3.3 are not clear** and should be clarified: **i)** srGW to Identity: \u2018This results in each cluster containing an equal number of data points.\u2019 It clearly does not seem to be the case. **ii)** relation to NMF: does it really coincide with the srGW diagonal barycenter problem or rather with the complete barycenter problem ? *[addressed by authors]*\n\n\n\n\n[A] Chen, Yifan, et al. \"A Gromov--Wasserstein Geometric View of Spectrum-Preserving Graph Coarsening.\" International Conference on Machine Learning. 2023.\n\n[B] Scetbon, M., Cuturi, M., & Peyr\u00e9, G. (2021, July). Low-rank Sinkhorn factorization. In International Conference on Machine Learning (pp. 9344-9354). PMLR. \n\n[C] Scetbon, M., Peyr\u00e9, G., & Cuturi, M. (2022, June). Linear-time gromov wasserstein distances using low rank couplings and costs. In International Conference on Machine Learning (pp. 19347-19365). PMLR. \n\n[D] Grippo, L., & Sciandrone, M. (2000). On the convergence of the block nonlinear Gauss\u2013Seidel method under convex constraints. Operations research letters, 26(3), 127-136.\n\n[E] Van Assel, Hugues, et al. \"Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein.\" arXiv preprint arXiv:2310.03398 (2023).",
        "questions": "I invite the authors to discuss the above-mentioned weaknesses and to answer the questions (potentially implying additional experiments) I have associated with them in order to complete my development.",
        "rating": "3: reject, not good enough",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      }
    ],
    "decision": "Reject"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "hcXfzlmg7Y",
    "title": "Trolley Problems for Large Language Models Across 100+ Languages",
    "reviews": [],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "kIZcruKmBg",
    "title": "Physics-informed neural networks for transformed geometries and manifolds",
    "reviews": [
      {
        "summary": "The work proposes a method to enhance Physics-informed Neural Networks (PINNs) by integrating geometric transformations, to address challenges posed by complex or non-euclidean geometries. \nThe method utilizes a diffeomorphism $\\phi$ that maps a reference domain $\\Omega_{ref}$ to the observation domain $\\Omega$, adapting the derivative computation in the physics-informed loss function. The approach was demonstrated through various problems: Eikonal equation on Archimedean spiral, Poisson problem on surface manifold, Incompressible Stokes flow in deformed tube. Finally, they show that their method can be applied to perform shape optimization according to a Laplace PDE loss.",
        "strengths": "The paper is easy to read and the geometric transformation seems reasonable to solve this kind of problem. The first three different examples each test a different geometric setting. The figures are pretty.",
        "weaknesses": "The method relies on the output transformation trick to enforce boundary conditions (BC), which is well suited for Dirichlet BC only. It would not be applicable as is for different kinds of BC, but the authors have a much more general claim.\n\nExcept for the last example, which we will discuss next, the diffeomorphism $\\phi$ is known a priori. Therefore the method in such case simply looks like a change in variable with a known function. How can you apply this method on a domain which is not equipped with such a transformation ?\n\nThe last example is very mysterious to me. I actually do not understand what the method is supposed to achieve by learning simultaneously to impose the PDE constraint and the geometric transformation. Do we know what target geometry the network should converge to ? Besides, the network that learns the transformation is not a diffeomorphism, so there is no guarantee that the optimization problem finds a correct solution. \n\nThe authors do not compare their method with any existing work. There is no literature review. As a result, we do not really understand why these problems cannot be tackled with existing methods. Why do they fail ?\n\nThe authors do not provide any numerical results for their methods, and even the qualitative results do not include the ground truth solutions. It is therefore impossible to judge the effectiveness of the method.",
        "questions": "What is the difference between $\\mathcal{L}$, $\\mathcal{L}_x$ and $\\mathcal{L}_y$ concretely for each example ?\n\n What does the following sentence mean ? \"transformed PINN finds the exact length with an error of = 0.1 \\%\" .",
        "rating": "1: strong reject",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "This paper employs physics-informed neural networks (PINNs) for addressing intricate or changing geometrical configurations. The primary technical innovation lies in the incorporation of a geometric transformation (diffeomorphism) of a reference domain to describe the computational domain.",
        "strengths": "The problem is well defined and the author proposes a clear formulation in solving the problem.",
        "weaknesses": "Unfortunately,  it appears that the problem tackled in the paper is somewhat incremental, and the proposed solution lacks a surprising or profound aspect. In the context of an ICLR paper, I'm seeking a novel problem that has not previously been successfully addressed, made attainable through this approach, or a novel method to solve a well-established problem that has been extensively explored. Unfortunately, neither of these elements seems to be present in the paper.\n\nFurthermore, the examples provided mainly consist of small-scale 2D toy examples. To comprehensively assess the efficacy of this approach, it would be necessary for the authors to set up larger-scale problems that are well-documented in CFD/JCP/CMAME papers.",
        "questions": "How does this work compare with Bonev+ ICML 2023? These authors propose a neural PDE approach using spherical coordinate. Your paper seems to be more general. Can you reproduce some of the examples in their paper so we can have an apple to apple comparison?",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "In this paper, it is argued that the existing approaches to physics-informed neural networks are not apt for complex and transforming geometries. To this end, the paper presents an approach to introduce geometric transformation within the physics-informed neural network design. Concretely, it enforces the Dirichlet boundary condition using distance function to account for complex geometries. Experimental results on four different examples are shown to demonstrate the suitability of the method.",
        "strengths": "* It is a well-written paper. \n* The use of Dirichlet boundary conditions is promising.\n* An initial approach to explore a new direction for more promising neural network design.",
        "weaknesses": "* Some of the technical notations are not fully exposed and detailed.\n* Experiments are limited on toy-example and missing on the manifolds which are widely used in science and engineering application.\n* The paper misses to highlight the limitations of the proposed approach.\n\n\nKindly refer to the Questions section for more comments.",
        "questions": "## Domain and Transformation\n\nIt\u2019s better to include the dimension of the variables on the side of the Eq(1). \n\n## 2.2.1 Manifold: $m < n$\n\n$\\mathcal{L}_x$ and $\\mathcal{L}_y$ need more explanation. The subscripts have not been explained. Diagram conveys that one is in the reference domain and other is in the computational domain yet it's better to write near the equation (4)-(5) and following equation.\n\n## 3.1 Exact boundary condition with output transform\n\nKindly help me understand the approximation of $\\hat{u}$, given that the inverse must hold and the proposed approximation is not linear.\n\n## 4.4 Shape Optimization with Laplace Operator\nI am not entirely convinced with the imposed boundary condition. What could be considered a weak boundary condition is not fully exposed in the paper. Furthermore, I request the authors to perform some experiments and analysis of the proposed theory on negative curvature surfaces with the introduced local approach. Also, the use of Laplace-Beltrami operator for shapes.\n\nIn addition to the above, experiment on Low-Dimensional manifolds is simple and not convincing to me for real application. I request the authors to provide some analysis and results on popular manifolds such as low-dimensional SPD, Grassmannian manifolds, etc.",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper intends to improve the performance of PINN on domains of complex geometries. The method is to  use smooth transformations to transform a complex geometry to less complex one which is a called reference domain. If the transformations are differentiable, the training of modified PINNs is the same as training vanilla PINNs.",
        "strengths": "**Originality:** The paper implements diffeomorphisms to the problem of PINN on complex geometries.\n\n**Quality:** The paper explores the proposed methods on some typical examples to demonstrate the effectiveness of the method.\n\n**Clarity:** The idea is conveyed directly and straightforward.\n\n**Significance:** Combining diffeomorphism with training of neural network is somewhat interesting and natural, due to the differentiability of transformations.",
        "weaknesses": "One of the major weakness is that the paper does not include experiments of comparison between modified PINN and vanilla PINN. In order to show the effectiveness of the proposed method, the author should also test the performance of PINN on all the problems in section 4.",
        "questions": "If the original problems $L(u)=f$ in $\\Omega$ is transformed to $L_x(u \\circ \\phi) = f$ on reference domain $\\Omega_{ref}$, then $L_x$ should not equal $L$. The calculation of $L_x$ should use chain rule. In your paper, this part is hardly touched. How did you actually implement your method in experiments?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "eepoE7iLpL",
    "title": "Enhancing Neural Subset Selection: Integrating Background Information into Set Representations",
    "reviews": [
      {
        "summary": "The authors propose an optimal subset selection method based on neural networks, which is designed to learn a permutation invariant representation of both the subset of interest $S$ and the ground superset $V$. The authors highlight that prior works for neural subset selection (e.g., DeepSet) do not account for the superset $V$, and both theoretically and empirically demonstrate that jointly modeling the interactions between $S$ and $V$ leads to improved performance.",
        "strengths": "- The writing is generally easy to follow, and the paper includes a sufficiently comprehensive discussion of relevant prior works. Experimental results are presented well.\n- The proposed method achieves strong empirical performance in terms of mean Jaccard coefficient (often with a fairly large gap) when compared against several optimal subset selection baselines (e.g., DeepSet, EquiVSet).",
        "weaknesses": "- The presentation of some of the mathematical details needs improvement. In particular, it seems that some of the notations are overloaded (i.e., the same notation is used with different interpretations) or not clearly defined. For example, the notation $S$ appears as a *subset* of the ground set $V$ in the Introduction, but in Section 3.1 (Background), the notation $S$ appears as an *element* of $V$ that takes a matrix form. The relationship between elements $x_i \\in \\mathcal{X}$ and $S_i$ is not clearly defined either. On another note, it is not entirely clear to me what the function value $Y \\in \\mathcal{Y}$ is really referring to, which also appears without an explicit discussion of its meaning in the Introduction as part of the variational distribution $q(Y|S,V)$. Is $Y \\in \\mathcal{Y}$ supposed to be the utility function value (which was also introduced with the notation $U = F_{\\theta}(S,V)$ in the Introduction)? The confusion arising from notational ambiguity makes the paper less readable.",
        "questions": "- Can the authors clearly define what $Y$ is? The footnote mentions that $Y_i$ is the \"probability of element $i$ being selected\", but this description is ambiguous.\n- It looks like learning the neural network approximation in Eq. (4) is done via variational inference as in Ou et al. (2022). As I am not familiar with the cited work, it is unclear to me how $q(Y|S,V)$ is serves as an approximation for the subset likelihood $p(S|V)$ when the former is a distribution over $Y$ and the latter is a distribution over $S$. Can the authors provide clarifications on this?\n- How is the neural network construction in Eq. (4) explicitly related to $p_{\\theta}(S,V)$ (or $F_{\\theta}(S,V)$)?",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "The paper tackles neural subset selection. In particular, they tackle the issue that current methods do not consider the properties of the superset while constructing subsets. Their theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an invariant sufficient statistic of the superset into the subset of interest for effective learning.",
        "strengths": "- The paper is clearly written.\n- The related work covers enough ground for a new researcher to understand a high level idea of this field.\n- The experiments include multiple baselines.",
        "weaknesses": "- Lack of ablation studies.\n- The proposed method is not evaluated on a wide distribution of datasets.\n- Will similar findings hold if the dataset contains imbalance? If so, what degree of imbalance do the guarantees still hold?",
        "questions": "- Baselines do not consider the information from superset, but these baselines be improved by adding the invariant sufficient statistic of the superset?",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "This paper proposes a neural subset selection method based on deep sets. This model is inspired by a theoretical perspective to include information from supersets to achieve better performance. Experiments on common benchmarks show SOTA performance compared to several recent baselines.",
        "strengths": "1. The idea to include information from superset is simple and effective as shown by the experiment results\n2. Theoretical discussions are provided.",
        "weaknesses": "1. Equation 4 describes the neural network construction. However, I am unclear about the objective function to optimize the neural network. Also, after optimization, how do you use this neural network to select a subset?\n\n2. In equation 4, how do you divide a superset into several subsets? There are an exponential number of combinations.\n\n3. What is the number of learnable parameters for each baseline method and the proposed method?",
        "questions": "None",
        "rating": "6: marginally above the acceptance threshold",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": "Accept"
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "hLT9cW4Afz",
    "title": "Causal Impact Index: A Causal Formulation of Citations",
    "reviews": [
      {
        "summary": "In this paper, the author proposed a framework for understanding the citation of a paper by analyzing the citation graph from a causal perspective.",
        "strengths": "1. The paper is well-written and easy to follow.\n\n2. The problem setting is solid and definitely interesting, that is to understand the counterfactual effect of a paper not being published.",
        "weaknesses": "1. The evaluation counts on the construction of the synthetic dataset, and the reliability of the counterfactual data is not measured or analyzed. \n\n2. The assumption that the confounders are \" a paper's publication year, research area, research question, and storyline\" is limited. These can be part of the confounder and the storyline is a concept that is hard to measure.\n\n 3. To measure the impact of people's work, there might be a need to provide a more rigorous justification, especially when using the LLM for synthetic data generation.",
        "questions": "See weakness.",
        "rating": "3: reject, not good enough",
        "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
      },
      {
        "summary": "In this work, authors devised an alternative index to citation count, namely CAUSALCITE, through a causal lens. The goal is to handle the limitations and weakness of the current index and ultimately measure the true impact of academic paper. In action, authors used LLM to extract the representation of papers. Then, for each paper, they generated a counterfactual paper via weighted KNN, and then calculate the causal effect. Intersting case studies have been conducted to evaluate the efficacy of the proposed approach.",
        "strengths": "1. The research problem is important and challenging: how to measure the true impact of academic paper?\n2. It is innovative to formulate this research problem as a causal inference problem. It is also interesting to leverage causal graph to analyze the roles of each factor, identify the potential bias and devise adjustment-empowered estimators. \n3. The paper is easy to follow, with impressive coherence and narrative.",
        "weaknesses": "The concerned limitation of citation count is not very clear. The terminology used, such as \"failing to accurately reflect a paper\u2019s true impact,\" offers intuitive but vague criticisms of the existing citation-count system. Moreover, the authors do not adequately address how CAUSALCITE overcomes these issues. Explicitly, questions like \"Is it feasible to formulate the limitations (especially the bias) of citation count in a causal graph?\" and \"How does CAUSALCITE solve the claimed limitations?\" remain unanswered. Providing such information would help clarify the scope and the innovative aspect of the CAUSALCITE model.\n\nLack of limitation. Dicussion on limitation is very important especially for a new metric since each metric as its pros and cons. Although the authors did not involve this point in the main text, after rethinking I suggest some easy but common cases where CAUSALCITE could fail. Authors could formulate them as assumptions or reflect them in causal graphs, to clarify the scope of this work. Authors are highly encouraged to debate for their completeness, but an index could not be excellent in every aspect. Identifying and formulating the limitations could largely improve the quality of the paper.\n\n- Data sparsity in high-dimensional spaces. Even though cosine similarity is effective in such spaces, if there are not enough 'near neighbors' for a given paper, the method could fail to find adequate matches. This would result in counterfactual samples that are not truly representative, affecting the validity of the causal inference. Imagine trying to synthesize a counterfactual for a groundbreaking paper on a niche subject; the lack of similar papers would make this task challenging.\n\n- Temporal dynamics. Academic papers are not static entities; they gain citations over time, undergo revisions, and may be commented upon. If the method does not account for these temporal changes, the synthesized counterfactual may be not accurate. For instance, a paper published ten years ago that has been highly cited will have different characteristics than a similar paper published recently, and simply averaging the two could produce misleading results.\n\n- Dimension reduction bias when encoding papers using text embeddings. Although LLMs can capture some textual features, the embeddings are still a reduced representation of the original text. Thus, they might not capture all nuances or specialized details, and **numerical results** present in the paper, which could be key factors for accessing the paper quality.\nFor example, two papers focusing on a topic, with the same experimental pipeline, could derive different and even contractory results (which is the usual case in some subjects...). Can such difference be reflected by LLM embeddings?\n\n\nLack of theoretical backup. The core technical point seems a weighted KNN. Since there are many causal inference methods, such as re-weighting-based, matching-based and representation-based methods, the motivation to select weighted KNN to adjust data should be formulated.  As a causality-inspired paper, theoretical formulation and backup is a critical aspect. Is there any theoretical formulation of the advantages of CAUSALCITE over citation count? In which conditions? Moreover, identifiability is a crucial aspect in causality empowered methods. Is CAUSALCITE identifiable? Is there any conditions to support the identifiability of CAUSALCITE?",
        "questions": "Please see the questions in the weaknesses section.\n\n---\n\n**My rating only reflects the current status of this manuscript. Since the research question is honestly impressive, at least for me, I am willing to rethink my rating if the authors could mitigate my main concerns (weaknesses 2,3).** The authors are highly encouraged to refute any inaccuracies in my comments directly.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The authors propose a causal impact index which measures how influential a paper is via counterfactual estimation.",
        "strengths": "Thanks to the authors for the hard work on this paper.",
        "weaknesses": "- I don't really understand the method. A lot of specific questions are in the next section, but I am missing the big picture. Paper $b$ cites paper $a$. When you find nearest neighbors of paper $b$, do you make sure that none of them *also* cite paper $a$? Do you make sure they are from the same year? Also how can you tell that they are truly similar enough for the estimation to be legitimate? Is there some theoretical requirement that these nearest neighbors to $b$ are close enough? \n\n- Unfortunately \"average 20-30 minutes for each PCI(a, b)\" is too slow to be adopted at scale as a substitute for citations or influential citations or other metrics\n\n- Also, it makes sense to compare to other alternatives besides the ones you have already, e.g. https://arxiv.org/abs/2102.03234\nand https://arxiv.org/abs/2105.08089\n\nMinor:\n- \"we consider LLM variants pretrained on large-scale scientific text, such as SciBERT (Beltagy et al., 2019b), SPECTER (Cohan et al., 2020), and MPNet (Song et al., 2020).\" These are too small to be called LLMs. Safe to call them LMs.\n- Figure 3 should have a log y-axis",
        "questions": "- \"we first exclude expressions about the quality or performance of the paper, such as the notion \u201cstate-of-the-art\u201d and the exact performance numbers in arabic numbers\" - how? How good is this procedure? Please evaluate this step, even with a small scale manual evaluation.\n- \"we bin the large set of follow-up papers into n equally-sized intervals\" - bins of what? Citation counts?\n- Algorithm 1: \"non-follow-up papers C\" - what are these? How do you get them? The `getPCI` method uses them. What is this method?\n- Algorithm 1: as far as I can tell this is just \"iterative averaging over a random subset sampled from bins\". Right? If so, it doesn't need its own algorithm box. And it doesn't seem \"novel\" enough to warrant that label.\n- \"For the set of matched papers, we consider papers with cosine similarity scores higher than 0.93\" - How did you arrive at this value? Was it tuned to increase the score in Table 1? I am worried about overfitting.\n- What if none of the nearest neighbors are closer than 0.93?\n- What about citations of citations? If paper $a$ was cited first, and then paper $b$ cited it, and then paper $c$ can either cite $a$ or $b$ but often not both. Does this need to be controlled for?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "iQHL76NqJT",
    "title": "Node-CwR: Node Classification with Reject Option",
    "reviews": [
      {
        "summary": "This paper addresses the problem of node classification with a reject option. The authors base their framework on the foundational Graph Attention Network (GAT), a prevalent graph neural network for graph embedding. To enable the reject option, they introduce a model called Node-CwR, which comprises two key modules: a cost-based model and a coverage-based model. Through a series of experiments conducted on various benchmark datasets, the authors showcase the effectiveness of their proposed model.",
        "strengths": "1. The paper explores an intriguing perspective \u2013 the reject option \u2013 which represents an interesting approach to node classification on graphs utilizing graph neural networks.",
        "weaknesses": "1. In the Introduction, the authors assert that \"i) To the best of our knowledge, we are the first to learn node embeddings using the abstention-based GAT architecture.\" This claim seems overstated.\n\n2. In Section 3.1, the authors introduce NodeCwR-Cov and mention that \"There are two more fully connected layers after the softmax layer (with 512 nodes and one node) to model the selection function g.\" The meaning of \"having 512 nodes and one node\" is unclear in this context. \nAdditionally, the selection function threshold is set to 0.5, but the rationale behind choosing this value and its impact on the model or performance is not explained. \nThis threshold serves to filter eligible candidates. It is essential to consider the accuracy of these candidates for each threshold, as they significantly impact the overall performance.\n\n3. The presentation of results in tables and figures is unclear. For instance, in Table 1, the meanings of Cov and LS are not explained. \nThe experimental analysis lacks depth and clarity.\n\n4. GAT is chosen as the backbone for the proposed model. How does it compare to other graph neural network models?\n\n5. In my opinion, the contribution of this paper appears somewhat limited, and the proposed model seems incremental in its approach.",
        "questions": "Please see the Weaknesses.",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The authors proposed two methods for node classification with reject option that can be applied to the graph attention networks. The coverage-based model takes the coverage as input and finds the optimal model for a given coverage rate. The cost-based model finds the optimal classifier for a given cost of rejection value. The authors then demonstrate the performance of the methods in multiple datasets under several hyperparameter settings, including label smoothing parameters.",
        "strengths": "Strengths:\n- Interesting application of classification with reject option on GAT architecture.\n- The paper is easy to understand.\n- The author provides a detailed description of the experiment results.\n- The authors also study the effect of label smoothing on the experiments.",
        "weaknesses": "Weakness:\n1) Both methods presented in the paper are heavily influenced by previous research. The coverage model is based on SelectiveNet (Geifman & El-Yaniv, 2019), whereas the cost-based model is based on (Cao et al., 2022). The authors applied the previous research to the GAT learning setting.\n2) The authors did not provide baselines for comparison in the experiments sections.\n3) In summary, I think the authors provide a nice study on the application of classification with reject option to node classification with graph attention networks. However, I think ICLR may not be the best venue for this work.",
        "questions": "Questions:\n1) The authors mentioned that the approaches work on GAT. However, I don't see any limitation that restricts the application of the proposed approach to other architectures. How do the approaches extend to other architectures?\n2) The authors specifically mentioned the number of nodes in the architecture design. Why this specific number?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper proposed a new approach called Node-CwR, which models node classification with a reject option using GAT. Two different models are proposed, cost-based and coverage-based. Empirically, the paper shows the effectiveness of the proposed models in learning efficient reject option models for node classification tasks.",
        "strengths": "1. The idea of investigating integrating reject option in node classification task is interesting.\n2. Reproducible as the source code is attached.\n3. Writing is clear and easy to follow.",
        "weaknesses": "1. The first sentence of abstract \u2013 \u201cGraph attention networks (GAT) have been state-of-the-art GNN architecture used as the backbone for various graph learning problems\u201d is not convinced. As far as I know, most of SOTA GNNs in node classification are not based on GAT.\n2. The novelty is limited: just simply combine reject option and GAT. It is unclear why only use GAT as backbone. And it is unclear what is the specific design for graph data.\n3. Although there are some related works of reject option classification in Section 2.1, there is no comparison between the proposed method and existing method.\n4. The experiment is conducted on only three small datasets, which is not enough.\n5. The notation is not well clarified. For example, the first equation in Section 3.1, I can't find any explanation to what is $S_n$.\n6. The typesetting needs improvement for better readability. Lots of tables and figures are overfull.\n7.  Figures 1 and 2 are notably blurry and similar to each other. Consequently, it is advisable to consolidate these two figures and make it clearer.",
        "questions": "1. Why only use GAT as the architecture? Can the proposed method benefit other GNN architecture?\n2. What is the difference of the proposed reject option node classification compared to existing reject option classification?\n3. Why experiment is only conducted on three datasets? How effective is the proposed method when applied to larger graphs or heterophilic graphs?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      },
      {
        "summary": "The paper addresses the node classification task and extends it to consider classification-with-reject. The paper provides both cost-based and coverage-based models. Experiments on three small datasets provide insights into the behaviour of the proposed approaches. The experiments also investigate the impact of label noise and show that label smoothing is effective for the derived cost-based model.",
        "strengths": "S1.\tThe node classification with reject task has received little if any prior attention in the literature. \nS2.\tThe experiments show that the proposed techniques offer promising performance and provide insights into their behaviour.",
        "weaknesses": "W1.\tThe technical contribution seems limited. The approaches are very close to existing CwR methods (developed for the non-graph setting); it\u2019s difficult to see how the graph has posed an additional, meaningful challenge. \nW2.\tThe experiments are conducted for three small graphs; papers on graph learning really need to go beyond Cora, Citeseer, and Pubmed \u2013 there are many benchmark datasets available now. The expectation is that experiments would be conducted with 6-8 datasets, with several being medium- to large- scale. One might also expect experiments in both supervised and semi-supervised settings, and both transductive and inductive. \nW3.\tThe experiments do not compare to any baseline methods. While there may not be prior work that directly addresses this problem, I think it is relatively easy to construct a na\u00efve baseline. A simple baseline would be training a standard node-classifier (ignoring the regret option) to derive embeddings and then using those embeddings in the standard non-graph CwR framework to train an MLP architecture. Another basic baselines would involve rejecting nodes according to a threshold on softmax entropy. \n\nW1 (cont.): The main weakness of the paper is that there is a limited technical contribution. It\u2019s hard to see how the coverage-based classifier differs from SelectiveNet beyond introducing a GAT, which is not a substantial technical innovation. The cost-based approach follows Cao et al. 2022 closely; the only extension seems to be the introduction of label smoothing. The paper needs to make it much clearer what technical challenge arises because of the presence of a graph and how that has led to design differences and innovations. The replacement of a non-graph classifier with a GAT is not enough.",
        "questions": "Q1.\tPlease provide a clearer explanation of how the presence of the graph has a significant impact on the CwR methodology and identify the main technical contributions and innovations of the paper. Please explain why they are important, novel, and substantial. \nQ2.\tWhy is it sufficient to conduct experiments on only three small graphs? How do we know that the observations extend to graphs from different domains? How do we know that the same observations apply for larger scale graphs? Do the results also apply to supervised settings? What about the inductive setting?\nQ3.\tWhy is it not possible to construct a na\u00efve baseline for comparison, using any graph-learning technique to derive embeddings and then treating the problem using the standard CwR approach?",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  },
  {
    "venue": "ICLR.cc",
    "year": "2024",
    "paper_id": "ISq7Hnln0t",
    "title": "Segment Anything Meets Universal Adversarial Perturbation",
    "reviews": [
      {
        "summary": "This paper explores the problem of creating Universal Adversarial Perturbation (UAPs) for SAM in-order to disrupt its mask prediction ability.",
        "strengths": "The idea of creating UAPs for SAM is interesting.",
        "weaknesses": "- Table 1 is a known phenomenon (Moosavi-Dezfooli et al. (2017a)). I do not see the relevance of this in the paper.\n\n- The idea to increase the strength of the perturbations using contrastive loss has also been explored in works like [A, B]. The only difference I observe is the positive pair chosen in the proposed method. \n\n- With the above point, this also explains the phenomenon of using unrelated natural images yield better results, also observed in [B] (where unrelated natural image patches are compared in the CL).\n\n- The proposed method is severely lacking in terms of comparisons to prior works that attack dense predictions tasks.\n\n[A] GAMA: Generative Adversarial Multi-Object Scene Attacks, NeurIPS 2022\n\n[B] Leveraging Local Patch Differences in Multi-Object Scenes for Generative Adversarial Attacks, WACV 2023",
        "questions": "None.",
        "rating": "1: strong reject",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "This paper presents a universal adversarial attack against the SAM model. The underlying motivation of this paper is straightforward. However, by simply extending the image-dependent attacks for universal adversarial perturbation, the results are not as good as reported. Instead, this paper presents a new method for the UAP problem against SAM using the contrastive learning perspective. The proposed method is more effective than the baseline method.",
        "strengths": "1.Fortunately, this paper is not simply extending traditional UAP methods to SAM. The newly proposed method based on contrastive learning is more effective than a direct extension of existing methods. This helps a lot in assessing the novelty of the paper.",
        "weaknesses": "1.[minor] There are some typesetting issues in the \\cite formats. Please carefully read the template instructions and use \\citep or \\citet instead. The formatting issue makes the paper difficult to read when printed, especially the paragraphs with dense citations.\n\n2.[minor, defense, ethics] Discussion on how to improve SAM robustness is missing. Although not required, I still want to see some discussions on how we can improve the adversarial robustness of SAM, especially from the unique experience of the proposed UAP. I think there are a couple of references when discussing this. For reference, \"On the Robustness of Segment Anything\" (https://arxiv.org/pdf/2305.16220.pdf) analyzes the adversarial robustness of SAM. \"Enhancing Adversarial Robustness for Deep Metric Learning\" (https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.html) presents defense methods for deep metric learning, which is the supervised version of contrastive learning and also involve anchor, positive, negative samples. Moreover, the proposed method resembles \"finding a universal visual prompt (perturbation) that can reduce the mIoU\". Is it possible to find a \"universal visual prompt (perturbation)\" that makes SAM more adversarially robust? Those discussions are suggested because, after all, attacks will become robustness evaluation metrics eventually.\n\n3.[important, transferability across prompt type] According to last paragraph in section 3, during evaluation, point prompts are used by default for quantitative evaluations. Is the UAP created under point prompts still effective under other types of SAM prompts? We can never assume the user to stick at one single prompt type. Visualizations for box prompts in section 5.2 without quantitative results are insufficient and not convincing enough at this point. A true \"universal\" perturbation should not build any correlation with a prompt type. Namely, in the context of SAM, image-agnostic is no longer sufficient for being \"universal\". It has to be prompt-agnostic as well.\n\n4.[evaluation dataset size] According to the last paragraph in section 3, only 100 images are used for evaluating the proposed method, which does not seem sufficient. UAP evaluation should not be slow as it is merely applying UAP to the image and doing the forward pass. It is suggested to increase the number of test images and additionally report the error bar to make sure the performance is less affected by the bias of the sampled dataset. SA-1B consists of 11M dimages and 1.1B high-quality segmentation masks. The 100 subset is really too small.\n\n5.[clarify, figure] The core formulation of this paper is Eq. 3. To ease reading and understanding, please consider adding the mathematical notations in Figure 1.\n\n6.[important, cost] It would be good to know how much the computational cost is for the proposed method, compared to image-dependent ones. This is because, the higher the attack cost is, the less likely an attacker in practice will adopt it. Hence, attacks with higher costs imply lower practical security risk. This is one of the reasons why I said attacks will eventually serve as robustness metrics. If the authors tend to write the paper from the attack side, then attack cost is important information. If the authors tend to write the paper from the defense side, the robustness discussion should not be absent. The current draft contains neither of them.",
        "questions": "See weaknesses. I'll consider changing my rating based on the author's response on weaknesses marked as \"important\".",
        "rating": "5: marginally below the acceptance threshold",
        "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
      },
      {
        "summary": "This paper focuses on the adversarial robustness of the Segment Anything Model (SAM) in the context of computer vision. The authors investigate the possibility of attacking SAM using a single image-agnostic Universal Adversarial Perturbation (UAP), which can mislead SAM into predicting invalid masks for most, if not all, images. They propose a novel perturbation-centric framework that leverages self-supervised contrastive learning (CL) to generate UAPs effectively.",
        "strengths": "1. The authors are working on a very cutting-edge problem, exploring whether generalized adversarial attacks can be made against segmented large model SAMs.",
        "weaknesses": "1. The authors' approach is not general enough for SAM only in my opinion, especially nowadays there are a lot of variants of SAM and similar generalized segmentation large models like HQ-SAM [1], Semantic-SAM [2], and SEEM [3]. The authors should study attacking segmentation large models, not only SAM.\n2. The author didn't quote the reference correctly, all of them are \\citet, while some places should be \\citep. \n3. Multi-modal prompts are not only point and bbox but also text. Both SAM and SEEM [3] can accept text prompts and the author did not address this aspect of the attack.\n\nReferences\n\n[1] Ke, L., Ye, M., Danelljan, M., Liu, Y., Tai, Y. W., Tang, C. K., & Yu, F. (2023). Segment Anything in High Quality. NeurIPS 2023.\n\n[2] Li, Feng and Zhang, Hao and Sun, Peize and Zou, Xueyan and Liu, Shilong and Yang, Jianwei and Li, Chunyuan and Zhang, Lei and Gao, Jianfeng. Semantic-SAM: Segment and Recognize Anything at Any Granularity. arXiv preprint arXiv:2307.04767.\n\n[3] Xueyan Zou*, Jianwei Yang*, Hao Zhang*, Feng Li*, Linjie Li, Jianfeng Wang, Lijuan Wang, Jianfeng Gao^, Yong Jae Lee. SEEM: Segment Everything Everywhere All at Once. NeurIPS 2023.",
        "questions": "The author's experimental section is very inadequate. Why are there no comparisons with other attack methods and against previous classical segmentation models\uff1f",
        "rating": "3: reject, not good enough",
        "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
      }
    ],
    "decision": null
  }
]